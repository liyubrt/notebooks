{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta, date\n",
    "# from geopy.geocoders import Nominatim\n",
    "# from geopy.extra.rate_limiter import RateLimiter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import normalize_image, get_sequences\n",
    "from dust_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = '/data2/jupiter/datasets'\n",
    "unlabeled_datasets = [\"halo_vehicles_driving_through_dust_images_nodust_reserved_stereo\"]\n",
    "labeled_datasets = [\"halo_vehicles_driving_through_dust_images_nodust_reserved_labeled\"]\n",
    "pred_root_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "model = '20676_r2_rgb_bigdecay_biglr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11139, 137) (4764, 238) (4764, 11) (4764, 7)\n"
     ]
    }
   ],
   "source": [
    "di = 0\n",
    "raw_df = pd.read_csv(os.path.join(data_root_dir, unlabeled_datasets[di], 'master_annotations.csv'))\n",
    "raw_df['camera_pair'] = raw_df.unique_id.apply(lambda s: s[-7:])\n",
    "stereo_df = pd.read_csv(os.path.join(data_root_dir, labeled_datasets[di], 'master_annotations.csv'))\n",
    "stereo_df['camera_pair'] = stereo_df.unique_id.apply(lambda s: s[-7:])\n",
    "pred_df = pd.read_csv(os.path.join(pred_root_dir, model, labeled_datasets[di], 'output.csv'))\n",
    "dust_df = pd.read_csv(os.path.join(pred_root_dir, model, labeled_datasets[di], 'dust_ratio.csv'))\n",
    "print(raw_df.shape, stereo_df.shape, pred_df.shape, dust_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>id</th>\n      <th>gt_dust_ratio</th>\n      <th>total_averaged_dust_conf</th>\n      <th>total_thresholded_dust_ratio</th>\n      <th>masked_avg_dust_conf</th>\n      <th>masked_dust_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>65e98b4a6af3b51a246857d2_T06_T07</td>\n      <td>65e98b4a6af3b51a246857d2</td>\n      <td>0.0</td>\n      <td>0.070795</td>\n      <td>0.033789</td>\n      <td>0.011985</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>65e98b89cafc4e811b02178e_T06_T07</td>\n      <td>65e98b89cafc4e811b02178e</td>\n      <td>0.0</td>\n      <td>0.054587</td>\n      <td>0.029883</td>\n      <td>0.009240</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                          unique_id                        id  gt_dust_ratio  \\\n0  65e98b4a6af3b51a246857d2_T06_T07  65e98b4a6af3b51a246857d2            0.0   \n1  65e98b89cafc4e811b02178e_T06_T07  65e98b89cafc4e811b02178e            0.0   \n\n   total_averaged_dust_conf  total_thresholded_dust_ratio  \\\n0                  0.070795                      0.033789   \n1                  0.054587                      0.029883   \n\n   masked_avg_dust_conf  masked_dust_ratio  \n0              0.011985                0.0  \n1              0.009240                0.0  "
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dust_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "seq_dfs = get_sequences(stereo_df, interval=60, per_camera=False)\n",
    "print(len(seq_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_cameras = ['T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14', 'I01', 'I02']\n",
    "camera_pairs = [['T01', 'T02'], ['T05', 'T06'], ['T09', 'T10'], ['T13', 'T14'], ['I01', 'I02']]\n",
    "left_pass_pairs = ['T09_T11', 'T14_T16', 'T14_T15', 'T13_T15']\n",
    "right_pass_pairs = ['T05_T07', 'T10_T12', 'T06_T08', 'T06_T07']\n",
    "\n",
    "def read_raw_image(root_dir, dataset, row):\n",
    "    return imageio.imread(os.path.join(root_dir, dataset, row.artifact_debayeredrgb_0_save_path))\n",
    "\n",
    "def read_rectified_image(root_dir, dataset, row):\n",
    "    data_path = os.path.join(root_dir, dataset, row.stereo_pipeline_npz_save_path)\n",
    "    img = np.load(data_path)['left']\n",
    "    return (normalize_image(img, True)*255).astype(np.uint8)\n",
    "\n",
    "def add_text(frame, raw_row, pred_df, dust_df):\n",
    "    frame = cv2.putText(frame, f'{raw_row.camera_pair}, {raw_row.collected_on}', \n",
    "                        (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    pred_rows = pred_df[pred_df.unique_id == raw_row.unique_id]\n",
    "    if len(pred_rows) > 0:\n",
    "        s = f'Pred state: {pred_rows.iloc[0].state}'\n",
    "        frame = cv2.putText(frame, s, \n",
    "                            (40,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    dust_rows = dust_df[dust_df.unique_id == raw_row.unique_id]\n",
    "    if len(dust_rows) > 0:\n",
    "        s = f'Pred dust ratio: {dust_rows.iloc[0].total_averaged_dust_conf}'\n",
    "        frame = cv2.putText(frame, s, \n",
    "                            (40,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 10th sequence (30, 239) (30, 137)\n",
      "['T09', 'T10'] ['T09_T11', 'T10_T11', 'T10_T12']\n",
      "1 1\n",
      "[10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "def create_video_from_rectified_rgb(seq_dfs, si, raw_df, pred_root_dir, model, labeled_datasets, di, data_root_dir, unlabeled_datasets, pred_df, dust_df):\n",
    "    seq_df = seq_dfs[si]\n",
    "\n",
    "    # get raw sequence\n",
    "    start, end = seq_df.iloc[0].collected_on, seq_df.iloc[-1].collected_on\n",
    "    seq_raw_df = raw_df[(raw_df.collected_on >= start) & (raw_df.collected_on <= end)]\n",
    "    print(f'process {si}th sequence', seq_df.shape, seq_raw_df.shape)\n",
    "\n",
    "    # get pair-wise cameras\n",
    "    cameras = list(seq_df.camera_location.unique())\n",
    "    cameras.sort()\n",
    "    camera_pairs = list(seq_df.camera_pair.unique())\n",
    "    camera_pairs.sort()\n",
    "    print(cameras, camera_pairs)\n",
    "\n",
    "    # check if should use left pass or right pass or both\n",
    "    in_left = set(camera_pairs).intersection(left_pass_pairs)\n",
    "    in_right = set(camera_pairs).intersection(right_pass_pairs)\n",
    "    print(len(in_left), len(in_right))\n",
    "    if len(in_left) > len(in_right):\n",
    "        camera_pairs = left_pass_pairs\n",
    "        pass_key = 'left_pass'\n",
    "    elif len(in_left) < len(in_right):\n",
    "        camera_pairs = right_pass_pairs\n",
    "        pass_key = 'right_pass'\n",
    "    else:\n",
    "        pass_key = 'short_pass'\n",
    "\n",
    "    # get per-camera dfs and truncate to same length\n",
    "    camera_dfs = [seq_raw_df[seq_raw_df.unique_id.str.endswith(c)] for c in camera_pairs]\n",
    "    camera_dfs = [cdf.sort_values('collected_on', ignore_index=True) for cdf in camera_dfs]\n",
    "    min_len = min(len(cdf) for cdf in camera_dfs)\n",
    "    camera_dfs = [cdf.iloc[:min_len] for cdf in camera_dfs]\n",
    "    print([len(cdf) for cdf in camera_dfs])\n",
    "\n",
    "    # create video\n",
    "    video_dir = os.path.join(pred_root_dir, model, labeled_datasets[di], 'videos')\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "    video_name = os.path.join(video_dir, f'{start}_{pass_key}_{si}.mp4')\n",
    "    height, width = 512, 768\n",
    "    # print(width*2,height*math.ceil(len(camera_dfs)/2))\n",
    "\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), 3, (width*2,height*math.ceil(len(camera_dfs)/2)), isColor=True)\n",
    "    for fi in range(min_len):\n",
    "        frames = []\n",
    "        for pair_i in range(math.ceil(len(camera_dfs)/2)):\n",
    "            pair_frame = []\n",
    "            for _fi in range(2):\n",
    "                if pair_i*2+_fi == len(camera_dfs):\n",
    "                    frame = np.zeros((512, 768, 3), dtype=np.uint8)\n",
    "                else:\n",
    "                    frame = read_rectified_image(data_root_dir, unlabeled_datasets[di], camera_dfs[pair_i*2+_fi].iloc[fi])\n",
    "                    if frame.shape[1] == 640:\n",
    "                        zeros = np.zeros((512, 768, 3), dtype=frame.dtype)\n",
    "                        zeros[:,:640,:] = frame\n",
    "                        frame = zeros\n",
    "                    frame = add_text(frame, camera_dfs[pair_i*2+_fi].iloc[fi], pred_df, dust_df)\n",
    "                pair_frame.append(frame)\n",
    "            pair_frame = np.concatenate(pair_frame, axis=1)\n",
    "            frames.append(pair_frame)\n",
    "        frame = np.concatenate(frames, axis=0)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        video.write(frame)\n",
    "    # cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "for si in range(len(seq_dfs)):\n",
    "    si = 10\n",
    "    create_video_from_rectified_rgb(seq_dfs, si, raw_df, pred_root_dir, model, labeled_datasets, di, data_root_dir, unlabeled_datasets, pred_df, dust_df)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot gt dust vs. pre dust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sort_values(by='gt_dust_ratio')\n",
    "gt_ratios = df2.gt_dust_ratio.to_list()\n",
    "pred_ratios = df2.total_thresholded_dust_ratio.to_list()\n",
    "\n",
    "plt.figure(1, figsize=(12, 6))\n",
    "plt.plot(range(len(gt_ratios)), gt_ratios, c='b', marker=\".\", label='gt dust level')\n",
    "plt.scatter(range(len(gt_ratios)), pred_ratios, s=15, c='r', marker=\"o\", label='pred dust level')\n",
    "plot_human_state = False\n",
    "if plot_human_state:\n",
    "    tp_ids, fn_ids = [], []\n",
    "    for i,row in df.iterrows():\n",
    "        if row.state_y == 'true_positive':\n",
    "            tp_ids.append(i)\n",
    "        if row.state_y == 'false_negative':\n",
    "            fn_ids.append(i)\n",
    "    plt.scatter(tp_ids, [0.4] * len(tp_ids), s=20, c='g', marker=\"o\", label='pred human TP')\n",
    "    plt.scatter(fn_ids, [0.6] * len(fn_ids), s=20, c='purple', marker=\"o\", label='pred human FN')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim([-0.02, 1.0])\n",
    "plt.xlabel('images in ascending gt dust level order')\n",
    "plt.ylabel('dust level')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 64-bit",
   "name": "python3918jvsc74a57bd0c8cced58dbff2798e473c5ca6eca1100bfa72eead58bcdfb1b17e02c86ac111a"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "c8cced58dbff2798e473c5ca6eca1100bfa72eead58bcdfb1b17e02c86ac111a"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}