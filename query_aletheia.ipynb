{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.16.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.yu/anaconda3/envs/brtdevkit/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# need to use updated master JupiterCVML code\n",
    "import sys\n",
    "# sys.path.append('/home/li.yu/code/JupiterCVML/europa/base/src/europa')\n",
    "\n",
    "import os\n",
    "os.environ[\"BRT_ENV\"] = 'prod'\n",
    "import json\n",
    "import random\n",
    "import brtdevkit\n",
    "print(brtdevkit.__version__)\n",
    "brtdevkit.log = 'info'\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = 'default'\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from brtdevkit.core.db.athena import AthenaClient, Table\n",
    "from brtdevkit.data import Image, Dataset\n",
    "\n",
    "# from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import *\n",
    "# from aletheia_dataset_creator.config.dataset_config import *\n",
    "\n",
    "from jupiterdata.config.dataset_config import *\n",
    "from jupiterdata.utils.dataset import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'brtdevkit.data.core.dataset' from '/home/li.yu/anaconda3/envs/brtdevkit/lib/python3.9/site-packages/brtdevkit/data/core/dataset.py'>\n",
      "['front-center-left', 'front-left-left', 'front-right-left', 'side-left-left', 'side-right-left', 'rear-left', 'T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14', 'I01', 'I02']\n",
      "[{'front-center-left': 'front-center-right', 'front-left-left': 'front-left-right', 'front-right-left': 'front-right-right', 'side-left-left': 'side-left-right', 'side-right-left': 'side-right-right', 'rear-left': 'rear-right', 'front-center-right': 'front-center-left', 'front-left-right': 'front-left-left', 'front-right-right': 'front-right-left', 'side-left-right': 'side-left-left', 'side-right-right': 'side-right-left', 'rear-right': 'rear-left'}, {'T01': 'T03', 'T02': 'T04', 'T05': 'T07', 'T06': 'T08', 'T09': 'T11', 'T10': 'T12', 'T13': 'T15', 'T14': 'T16', 'I01': 'I03', 'I02': 'I04'}, {'T02': 'T03', 'T06': 'T07', 'T10': 'T11', 'T14': 'T15', 'I02': 'I03'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "eval \"$(/home/li.yu/anaconda3/bin/conda shell.bash hook)\"\n",
    "conda activate brtdevkit\n",
    "run this on cmd: brt-devkit-auth\n",
    "\"\"\"\n",
    "import inspect\n",
    "print(inspect.getmodule(Dataset))\n",
    "print(LEFT_CAMERAS)\n",
    "print(ALL_CAMERA_PAIRS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65f36b81573bb58210686892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m2024-04-02 13:05:46,813 - APIRequestor - ERROR - API error received | error_code : 403, error_message : {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n",
      "\u001b[0mWARNING:root:Failed to refresh AWS Credential\n",
      "WARNING:root:Some functionalities (S3, Athena, etc) not useable {'extra': {'role_name': 'token_exchange'}, 'message': 'Role token_exchange is required to make this API call'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "(177, 158)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset = Dataset.retrieve(id='64ed2657926aefcd654e8269')\n",
    "test_dataset = Dataset.retrieve(name='Jupiter_airborne_debris_night')\n",
    "print(test_dataset.id)\n",
    "test_df = test_dataset.to_dataframe()\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n    <tr>\n      <th>camera_location</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>T01</th>\n      <td>913</td>\n    </tr>\n    <tr>\n      <th>T02</th>\n      <td>413</td>\n    </tr>\n    <tr>\n      <th>T05</th>\n      <td>1218</td>\n    </tr>\n    <tr>\n      <th>T06</th>\n      <td>654</td>\n    </tr>\n    <tr>\n      <th>T09</th>\n      <td>1428</td>\n    </tr>\n    <tr>\n      <th>T10</th>\n      <td>1157</td>\n    </tr>\n    <tr>\n      <th>T13</th>\n      <td>501</td>\n    </tr>\n    <tr>\n      <th>T14</th>\n      <td>986</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                   id\ncamera_location      \nT01               913\nT02               413\nT05              1218\nT06               654\nT09              1428\nT10              1157\nT13               501\nT14               986"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['id', 'camera_location']].groupby('camera_location').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240119_halo_rgb_left_day_less_night_al_to_label (7457, 146)\n",
      "20240119_halo_rgb_diversity_left_daytime (4128, 146)\n",
      "20231219_halo_rgb_al_to_label (7552, 147)\n",
      "20231219_halo_rgb_diversity_to_label (1375, 144)\n",
      "20231206_halo_rgb_diversity_train_to_label_pt1 (4955, 157)\n",
      "20231206_halo_rgb_al_train_to_label_pt1 (17049, 157)\n",
      "20231206_halo_rgb_stereo_fps_dedup (15319, 158)\n",
      "20231219_halo_rgb_stereo_fps_dedup (5584, 147)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    '20240119_halo_rgb_left_day_less_night_al_to_label',\n",
    "    '20240119_halo_rgb_diversity_left_daytime',\n",
    "    '20231219_halo_rgb_al_to_label',\n",
    "    '20231219_halo_rgb_diversity_to_label',\n",
    "    '20231206_halo_rgb_diversity_train_to_label_pt1',\n",
    "    '20231206_halo_rgb_al_train_to_label_pt1',\n",
    "    '20231206_halo_rgb_stereo_fps_dedup',\n",
    "    '20231219_halo_rgb_stereo_fps_dedup',\n",
    "]\n",
    "test_dfs = []\n",
    "for dataset in datasets:\n",
    "    test_dataset = Dataset.retrieve(name=dataset)\n",
    "    test_df = test_dataset.to_dataframe()\n",
    "    print(dataset, test_df.shape)\n",
    "    test_dfs.append(test_df)\n",
    "pd.concat(test_dfs, ignore_index=True).to_csv('/data/jupiter/li.yu/data/halo_hard_cases/20231206_20231219_sent_for_labeling.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Athena Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard_drive_name = 'JUPD-048_2022-09-27'\n",
    "start_datetime  = datetime(2021, 12, 16, hour=22, minute=14, second=0) #, tzinfo=timezone.utc)\n",
    "end_datetime  = datetime(2021, 12, 16, hour=22, minute=14, second=35) #, tzinfo=timezone.utc)\n",
    "# start_datetime  = datetime(2022, 9, 28, tzinfo=timezone.utc) #, hour=3, minute=33, second=33) #, tzinfo=timezone.utc)\n",
    "# start_datetime  = datetime(2023, 8, 28, hour=0, minute=0)   #, tzinfo=timezone.utc)\n",
    "# end_datetime    = datetime(2023, 8, 30, hour=23, minute=59)  # this is EXclusive\n",
    "\n",
    "database = \"mesa-data-catalog-prod\"\n",
    "table = \"image_jupiter\"\n",
    "\n",
    "# query = \\\n",
    "# f\"\"\"\n",
    "# SELECT *\n",
    "# FROM {table} T\n",
    "# WHERE \n",
    "#     T.collected_on >= cast('{start_datetime}' as timestamp)\n",
    "#     AND T.collected_on < cast('{end_datetime}' as timestamp)\n",
    "#     AND T.robot_name = 'loamy_733'\n",
    "# \"\"\"\n",
    "\n",
    "query = \\\n",
    "f\"\"\"\n",
    "SELECT *\n",
    "FROM {table} T\n",
    "WHERE \n",
    "    T.hard_drive_name = 'JUPD-0306_2024-2-28'\n",
    "\"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT id, image, properties__json FROM annotation_jupiter\n",
    "WHERE style = 'categorical'\n",
    "AND created_at > date('2024-01-01')\n",
    "AND state in ('review', 'ok')\n",
    "AND (properties__json LIKE '%\"title\": \"Pose\"%' OR properties__json LIKE '%\"title\": \"Human Clothing\"%' OR properties__json LIKE '%\"title\": \"Human Occlusion\"%') \n",
    "AND kind = 'labelbox'\n",
    "\"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "# SELECT\n",
    "#         *\n",
    "#     FROM annotation_jupiter\n",
    "#     WHERE\n",
    "#      annotation_jupiter.image IN ('642607df1620247e2285d6ac')\n",
    "# \"\"\"\n",
    "\n",
    "# \"\"\"\n",
    "# SELECT id, camera_location, operation_time, collected_on, state, county, operating_field_name, hdr_mode, robot_name, special_notes\n",
    "# T.collected_on >= cast('{start_datetime}' as timestamp)\n",
    "#     AND T.collected_on < cast('{end_datetime}' as timestamp)\n",
    "#     AND T.camera_location LIKE 'front-%'\n",
    "#     AND T.camera_location LIKE '%-left'\n",
    "#     AND T.hard_drive_name = 'JUPD-154_2023-01-14'\n",
    "#     AND T.robot_name LIKE 'loamy%'\n",
    "#     AND T.operation_time != 'daytime'\n",
    "#     AND T.has_nearby_stop_event = true\n",
    "# ORDER BY RAND()\n",
    "# LIMIT 40000\n",
    "# \"\"\"\n",
    "\n",
    "start = time.time()\n",
    "athena = AthenaClient()\n",
    "df = athena.get_df(query)\n",
    "end = time.time()\n",
    "print(end - start, 's')\n",
    "df.shape, len(df) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Databricks Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520189, 28) 260094\n"
     ]
    }
   ],
   "source": [
    "# from jupiterdata.db import databricks_connector\n",
    "# databricks = databricks_connector.Databricks()\n",
    "# # note on json extraction https://docs.databricks.com/en/sql/language-manual/sql-ref-json-path-expression.html\n",
    "# df = databricks.execute(query)\n",
    "# print(df.shape, len(df)//2)\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.id AS id,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.has_human_annotation AS has_human_annotation,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.operation_time AS operation_time,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.camera_location AS camera_location,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.robot_name AS robot_name,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.has_nearby_stop_event AS has_nearby_stop_event,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.operating_field_name AS operating_field_name,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.farm AS farm,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.bag_name AS bag_name,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.closest_object_info__json AS closest_object_info__json,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.collected_on AS collected_on,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.hard_drive_name AS hard_drive_name,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.state AS state,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.special_notes AS special_notes,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.hdr_mode AS hdr_mode,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.group_id AS group_id,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.jdb_s3_path AS jdb_s3_path,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.ros_s3_path AS ros_s3_path,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.bundle AS bundle,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.gps_can_data__json AS gps_can_data__json,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.implement_angle_data__json AS implement_angle_data__json,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.category AS category,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.description AS description,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.autonomy_state__json AS autonomy_state__json,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.sensor_type AS sensor_type,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.geohash AS geohash,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.calibration_data__json AS calibration_data__json,\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter.tractor_type AS tractor_type\n",
    "FROM\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter\n",
    "WHERE\n",
    "  hard_drive_name = 'JUPD-0325_2024-3-19'\n",
    "  AND gps_can_data__json IS NOT NULL\n",
    "  AND special_notes IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# hard_drive_name = 'JUPD-0306_2024-2-28'  # first dust collection\n",
    "# hard_drive_name = 'JUPD-0325_2024-3-19'  # vehicle collection, not necessarily dust\n",
    "# https://bluerivertechnology.slack.com/archives/C04UNEQ190W/p1711143867529459?thread_ts=1711142618.986079&cid=C04UNEQ190W\n",
    "# https://bluerivertechnology.slack.com/archives/C06MB47MWUE/p1711145579254259\n",
    "\n",
    "# query = f\"\"\"\n",
    "# SELECT ANJ.id as id, ANJ.image as image, ANJ.properties__json as properties__json, ANJ.created_at as created_at\n",
    "# FROM mesa_prod.mesa_lake_prod.annotation_jupiter as ANJ\n",
    "# WHERE ANJ.style = 'categorical'\n",
    "# AND ANJ.created_at > date('2024-01-01')\n",
    "# AND ANJ.state in ('review', 'ok')\n",
    "# AND (properties__json LIKE '%\"title\": \"Pose\"%' OR properties__json LIKE '%\"title\": \"Human Clothing\"%' OR properties__json LIKE '%\"title\": \"Human Occlusion\"%') \n",
    "# AND ANJ.kind = 'labelbox'\n",
    "# \"\"\"\n",
    "\n",
    "# query = f\"\"\"\n",
    "#   SELECT img.id, img.collected_on\n",
    "#   FROM mesa_prod.mesa_lake_prod.image_jupiter as img\n",
    "#   JOIN mesa_prod.mesa_lake_prod.image_artifact_jupiter AS A\n",
    "#       ON A.image = img.id\n",
    "#   WHERE img.teleop_request__json IS NOT NULL\n",
    "#   AND img.teleop_request__json:original_roi IS NOT NULL\n",
    "#   AND NOT EXISTS(\n",
    "#           SELECT * from mesa_prod.mesa_lake_prod.annotation_jupiter as ann WHERE ann.image = img.id\n",
    "#           AND ann._cls = 'Annotation.CategoricalAnnotation'\n",
    "#           AND ann.is_active_version = true\n",
    "#       )\n",
    "#   LIMIT 10\n",
    "#   ;\"\"\"\n",
    "\n",
    "\n",
    "from jupiterdata.utils.dataset import query_db\n",
    "df = query_db(query)\n",
    "print(df.shape, len(df)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/data/jupiter/li.yu/data/halo_rgb_stereo_train_test/all_human_pose_0326_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1362, 361) 9xjg9cde9btm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103657/3024971100.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bird_df[\"geohash_6\"] = bird_df[\"geohash\"].apply(lambda x: x[:6])\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "root_dir = '/data2/jupiter/datasets/'\n",
    "# dataset = 'halo_rgb_stereo_train_v6_2'\n",
    "dataset = 'halo_rgb_stereo_train_v8_1'\n",
    "csv = os.path.join(root_dir, dataset, 'master_annotations.csv')\n",
    "converters = {\"label_map\": ast.literal_eval, \"label_counts\": ast.literal_eval}\n",
    "# converters = {}\n",
    "df = pd.read_csv(csv, converters=converters)\n",
    "\n",
    "# ab_df = df[df.has_airborne == True]\n",
    "# print(ab_df.shape, ab_df.iloc[0].geohash)\n",
    "# ab_df[\"geohash_6\"] = ab_df[\"geohash\"].apply(lambda x: x[:6])\n",
    "\n",
    "df['Birds'] = df['label_counts'].apply(lambda d: d.get('Birds', 0))\n",
    "df['has_birds'] = df['Birds'] > 0\n",
    "bird_df = df[df.has_birds == True]\n",
    "print(bird_df.shape, bird_df.iloc[0].geohash)\n",
    "bird_df[\"geohash_6\"] = bird_df[\"geohash\"].apply(lambda x: x[:6])\n",
    "\n",
    "from jupiterdata.utils.dataset import query_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9xjg9c 2023-08-04 13 57\n",
      "9v5ks7 2023-08-02 153 50\n",
      "9v5kwy 2023-08-05 2 375\n",
      "9v5kxj 2023-08-07 20 50\n",
      "9v5kse 2023-08-02 67 50\n",
      "9xjg3z 2023-08-05 4 187\n",
      "9v5kss 2023-08-02 32 50\n",
      "dp03h5 2023-09-08 3 250\n",
      "9v5ksk 2023-08-02 22 50\n",
      "9xjgd0 2023-08-04 4 187\n",
      "9xjgd0 2023-08-05 1 500\n",
      "9xjgy5 2023-08-15 8 93\n",
      "9v5kwu 2023-08-05 9 83\n",
      "dp03ht 2023-09-09 1 500\n",
      "9xjg9b 2023-08-04 5 150\n",
      "9xjg9b 2023-08-05 2 375\n",
      "9xjg92 2023-07-28 8 93\n",
      "9xjepp 2023-08-09 2 375\n",
      "dju21r 2023-08-18 2 375\n",
      "9v5kxn 2023-08-07 7 107\n",
      "9xjg3f 2023-08-07 5 150\n",
      "9xjgy7 2023-08-15 2 375\n",
      "9xjg8b 2023-08-17 4 187\n",
      "dju21p 2023-08-18 4 187\n",
      "9xjg98 2023-07-28 2 375\n",
      "dp03k9 2023-09-13 3 250\n",
      "9xjg64 2023-08-07 1 500\n",
      "9xjg3d 2023-08-07 2 375\n",
      "9xjgvu 2023-08-15 3 31\n",
      "9v5kws 2023-08-07 2 375\n",
      "9v5kwv 2023-08-05 19 50\n",
      "9xjg9m 2023-08-16 5 150\n",
      "dp03hx 2023-09-12 4 187\n",
      "9xjg3r 2023-08-04 1 500\n",
      "9xjg3r 2023-08-16 1 500\n",
      "9v5ksd 2023-08-02 5 150\n",
      "9xjer0 2023-08-09 1 500\n",
      "dp03k0 2023-09-11 3 250\n",
      "9v5ks6 2023-08-01 2 375\n",
      "9v5ks6 2023-08-02 18 50\n",
      "9xjg6p 2023-08-05 1 500\n",
      "9xjg3g 2023-08-07 1 500\n",
      "9xjg5j 2023-08-11 1 500\n",
      "dp03k3 2023-09-13 4 187\n",
      "dju21n 2023-08-18 9 83\n",
      "9v5kw7 2023-08-03 3 250\n",
      "9v5kw7 2023-08-04 1 500\n",
      "9xjg93 2023-08-03 4 187\n",
      "9xjg68 2023-08-14 1 500\n",
      "dp03hr 2023-09-11 2 375\n",
      "dp03hr 2023-09-12 2 375\n",
      "dp03hm 2023-09-09 2 375\n",
      "9xjeqb 2023-08-09 1 500\n",
      "9xjg3x 2023-07-27 1 500\n",
      "dju21q 2023-08-18 3 250\n",
      "9xjg4x 2023-08-14 1 500\n",
      "9v6tnw 2023-09-28 1 500\n",
      "dp4urh 2023-10-02 1 500\n",
      "dp08s0 2023-10-09 2 375\n",
      "dp03h7 2023-09-10 2 375\n",
      "dp0d9x 2023-09-28 5 150\n",
      "9v5kw5 2023-08-04 2 375\n",
      "9v5kxh 2023-08-07 3 250\n",
      "dp4uqu 2023-10-02 1 500\n",
      "9v5kx5 2023-08-07 1 500\n",
      "dp0dud 2023-10-08 1 500\n",
      "dp06zm 2023-10-03 2 375\n",
      "dp0dug 2023-10-07 1 500\n",
      "dp0dug 2023-10-05 1 500\n",
      "dp0dgk 2023-10-09 2 375\n",
      "dp03hp 2023-09-11 8 93\n",
      "9v6tx1 2023-09-26 2 375\n",
      "9v5kwg 2023-08-05 2 375\n",
      "dp035z 2023-09-11 5 150\n",
      "dp0duf 2023-10-08 3 250\n",
      "dp06zs 2023-09-28 3 250\n",
      "dp0dus 2023-10-07 1 500\n",
      "dp0dgs 2023-10-09 2 375\n",
      "dp03k2 2023-09-12 1 500\n",
      "dp03k2 2023-09-11 2 375\n",
      "dp03k8 2023-09-12 1 500\n",
      "dp03k1 2023-09-14 1 500\n",
      "dp03k1 2023-09-19 2 375\n",
      "dp0dgm 2023-10-09 3 250\n",
      "dp06zk 2023-09-28 1 500\n",
      "dp03h3 2023-09-10 1 500\n",
      "dp0dgt 2023-10-09 3 250\n",
      "dp0dut 2023-10-07 2 375\n",
      "dp0dcb 2023-09-28 1 500\n",
      "dp03h2 2023-09-10 1 500\n",
      "9xjgd1 2023-08-04 1 500\n",
      "9xjgyk 2023-08-14 2 375\n",
      "9v5kw6 2023-08-03 2 375\n",
      "dp08tt 2023-10-09 2 375\n",
      "9v6t5g 2023-09-29 1 500\n",
      "dp03k6 2023-09-13 1 500\n",
      "dp03k6 2023-09-14 2 375\n",
      "9v6tjz 2023-09-26 1 500\n",
      "dp0due 2023-10-07 1 500\n",
      "9zkxqd 2023-10-20 2 375\n",
      "cbhw1z 2023-10-30 1 500\n",
      "9zsxqq 2023-10-31 25 50\n",
      "9zkzt5 2023-10-23 1 500\n",
      "9zkzt5 2023-10-22 1 500\n",
      "dp5hdu 2023-10-27 1 500\n",
      "9zkxkw 2023-10-21 1 500\n",
      "9zsxqn 2023-10-31 20 50\n",
      "9xjgc6 2023-08-16 1 500\n",
      "9zmt8e 2023-10-20 2 375\n",
      "9xjg5r 2023-08-12 1 500\n",
      "dp5he3 2023-10-31 1 500\n",
      "9zsxqr 2023-10-31 1 500\n",
      "9zkxqg 2023-10-20 1 500\n",
      "9zsxp4 2023-11-11 2 375\n",
      "cbhw6w 2023-10-06 1 500\n",
      "9zswyn 2023-11-09 1 500\n",
      "9zpuuk 2023-11-06 1 500\n",
      "9zsxp5 2023-11-11 1 500\n",
      "9zsxqk 2023-10-19 4 187\n",
      "9zsxqj 2023-10-20 2 375\n",
      "9zv2se 2023-10-23 1 500\n",
      "9zsxst 2023-11-13 1 500\n",
      "9zv2m9 2023-11-06 1 500\n",
      "9zpuuv 2023-11-04 2 375\n",
      "9zqsmj 2023-11-09 2 375\n",
      "9zscv7 2023-11-08 1 500\n",
      "9zqu01 2023-11-14 1 500\n",
      "9zpuuu 2023-11-18 1 500\n",
      "9zpuuu 2023-11-03 2 375\n",
      "dp5hen 2023-10-27 1 500\n",
      "9zswyp 2023-11-11 1 500\n",
      "9zpuug 2023-11-07 2 375\n",
      "9zmjnp 2023-11-28 4 187\n",
      "9zmn7g 2023-11-16 1 500\n",
      "9zmjtb 2023-12-02 1 500\n",
      "dp72dv 2023-11-13 1 500\n",
      "9zpuuf 2023-11-07 1 500\n",
      "9zkzkj 2023-11-01 2 375\n",
      "9zkz36 2023-11-14 3 250\n",
      "9zpt0n 2023-11-02 2 375\n",
      "9zptue 2023-10-24 1 500\n",
      "9zqskv 2023-11-09 1 500\n",
      "9zscv6 2023-11-08 2 375\n",
      "dnd25z 2023-12-13 1 500\n",
      "dp4uqt 2023-10-02 1 500\n",
      "9v6tee 2023-09-21 2 375\n",
      "9zn2nb 2023-12-20 1 500\n",
      "9ufs6w 2024-02-07 105 50\n",
      "9ufs6y 2024-02-07 60 50\n",
      "9ufs6x 2024-02-07 33 50\n",
      "9ufs6v 2024-02-08 43 50\n",
      "9z1pgk 2024-03-13 232 50\n",
      "9z1pg7 2024-03-13 113 50\n",
      "9z1pgh 2024-03-13 22 50\n",
      "9q9d4z 2024-02-07 2 375\n",
      "9ufs6t 2024-02-08 49 50\n",
      "9zn2n3 2023-12-18 1 500\n",
      "9ufs6z 2024-02-07 1 500\n",
      "dp0378 2023-09-22 1 500\n",
      "9z1pgj 2024-03-12 2 375\n",
      "9z1pg5 2024-03-13 2 375\n",
      "dp08ts 2023-10-01 3 250\n",
      "9q9d4w 2024-02-14 1 500\n",
      "dp087z 2023-10-10 1 500\n",
      "9v6tmb 2023-09-26 2 375\n",
      "dp08gt 2023-10-12 1 500\n",
      "9zmjjb 2023-12-04 2 375\n",
      "9zpx3b 2023-09-24 1 500\n",
      "dp4ux8 2023-10-11 1 500\n",
      "9zv83h 2023-11-14 1 500\n"
     ]
    },
    {
     "data": {
      "text/plain": "60573"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEFT_CAMERAS = ('T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14', 'I01', 'I02')\n",
    "geohash_6_limit = 500\n",
    "geohash_6_expand = 1.5\n",
    "surround_ids = []\n",
    "for geohash_6 in bird_df.geohash_6.unique():\n",
    "    collected_on_days = bird_df[(bird_df.geohash_6 == geohash_6)].collected_on_day.unique()\n",
    "    for collected_on_day in collected_on_days:\n",
    "        current = len(bird_df[(bird_df.geohash_6 == geohash_6) & (bird_df.collected_on_day == collected_on_day)].unique_id.unique())\n",
    "        expand = int(geohash_6_limit / current * geohash_6_expand)\n",
    "        if expand < 50:\n",
    "            expand = 50\n",
    "        elif expand > 500:\n",
    "            expand = 500\n",
    "\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "          IMJ.id AS id,\n",
    "          IMJ.robot_name AS robot_name,\n",
    "          IMJ.camera_location AS camera_location,\n",
    "          IMJ.operating_field_name AS operating_field_name,\n",
    "          IMJ.bag_name AS bag_name,\n",
    "          IMJ.collected_on AS collected_on,\n",
    "          IMJ.hard_drive_name AS hard_drive_name,\n",
    "          IMJ.geohash AS geohash\n",
    "        FROM\n",
    "          mesa_prod.mesa_lake_prod.image_jupiter AS IMJ\n",
    "        WHERE\n",
    "          collected_on LIKE '{collected_on_day[:10]}%'\n",
    "          AND geohash LIKE '{geohash_6}%'\n",
    "          AND camera_location IN {LEFT_CAMERAS}\n",
    "        LIMIT {expand};\n",
    "        \"\"\"\n",
    "        df = query_db(query)\n",
    "        surround_ids += df.id.to_list()\n",
    "        print(geohash_6, collected_on_day, current, len(df))\n",
    "    #     break\n",
    "    # break\n",
    "    # print('queried geohash_6', geohash_6)\n",
    "\n",
    "len(surround_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60073\n"
     ]
    },
    {
     "data": {
      "text/plain": "'654658b46c228e535a897327'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remain_ids = list(set(surround_ids) - set(df.id.to_list()))\n",
    "print(len(remain_ids))\n",
    "remain_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12837, 1) True False\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('./dust_threshold/human_vehicle_in_dust_for_train_total.csv')\n",
    "# df = pd.read_csv('./dust_threshold/dust_productivity.csv')\n",
    "# df = pd.read_csv('/data/jupiter/datasets/Jupiter_train_v5_11/driveable_not_labeled.csv')\n",
    "# df = pd.read_csv('/data/jupiter/datasets/Jupiter_train_v5_11/less_than_half_labeled.csv')\n",
    "# df = pd.read_csv('/data/jupiter/datasets/Jupiter_train_v5_11/less_than_half_or_driveable_not_labeled_for_relabeling.csv')\n",
    "# df = pd.read_csv('/data/jupiter/li.yu/exps/driveable_terrain_model/rgb_baseline_sample_a_v3_2/20230925_halo_rgb_stereo_train_v3_epoch0/pruned_ids.csv')\n",
    "# df = pd.read_csv('/data/jupiter/li.yu/data/Jupiter_train_v6_2/train_v6_2_categorical_count.csv')\n",
    "# df = pd.read_csv('/data/jupiter/li.yu/data/halo_hard_cases/20231219_20240119_halo_rgb_left_airborne.csv')\n",
    "# df = pd.read_csv('/data/jupiter/li.yu/data/halo_rgb_stereo_train_test/rev1_test_missing_human_pose.csv')\n",
    "# df = pd.read_csv('/data/jupiter/li.yu/data/halo_rgb_stereo_train_test/rev1_test_missing_human_clothing.csv')\n",
    "# df = pd.read_csv('/data/jupiter/li.yu/data/halo_rgb_stereo_train_test/rev1_test_humanv15_day_front_standing_ids.csv')\n",
    "# df = pd.read_csv('/data/jupiter/li.yu/data/halo_rgb_stereo_train_test/train_v8_0_miss_human_pose.csv')\n",
    "df = pd.read_csv('/data/jupiter/li.yu/data/halo_rgb_stereo_train_test/test_v8_0_miss_human_pose.csv')\n",
    "print(df.shape, 'id' in df, 'unique_id' in df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unlabeled dataset\n",
    "Dataset.create(\n",
    "    name=\"halo_potential_birds_from_train_8_1\",\n",
    "    description=\"60073 images potentially contain birds from same geohash6 halo train v8.1\",\n",
    "    kind='image',  # annotation or image\n",
    "    image_ids=remain_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageids_to_dataset(\n",
    "#     image_ids=test_df[test_df.camera_location.str.endswith('left')].id.to_list(),\n",
    "#     dataset_name=\"20230823_labeled_right_images_12k_left_images_labels\",\n",
    "#     dataset_description=\"left images and labels of 20230823_labeled_right_images_12k\",\n",
    "#     dataset_kind='annotation',  # annotation or image\n",
    "#     mode='mono',  # stereo or mono\n",
    "#     camera_location=CORE_LEFT_CAMERAS,  # CORE_LEFT_CAMERAS or CORE_RIGHT_CAMERAS or ALL_CORE_CAMERAS\n",
    "# )\n",
    "# imageids_to_dataset(\n",
    "#     image_ids=test_df[test_df.camera_location.str.endswith('right')].id.to_list(),\n",
    "#     dataset_name=\"20230823_labeled_right_images_12k_right_images_labels\",\n",
    "#     dataset_description=\"right images and labels of 20230823_labeled_right_images_12k\",\n",
    "#     dataset_kind='annotation',  # annotation or image\n",
    "#     mode='mono',  # stereo or mono\n",
    "#     camera_location=CORE_RIGHT_CAMERAS,  # CORE_LEFT_CAMERAS or CORE_RIGHT_CAMERAS or ALL_CORE_CAMERAS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 0 annotations with non-production label map.\n",
      "Warning 3345 images do not have a corresponding annotation.\n",
      "Preparing stereo dataframe for {'T01': 'T03', 'T02': 'T04', 'T05': 'T07', 'T06': 'T08', 'T09': 'T11', 'T10': 'T12', 'T13': 'T15', 'T14': 'T16', 'I01': 'I03', 'I02': 'I04'}...\n",
      "Size of left dataframe: 3925\n",
      "Size of stereo dataframe: 3919\n",
      "Preparing stereo dataframe for {'T02': 'T03', 'T06': 'T07', 'T10': 'T11', 'T14': 'T15', 'I02': 'I03'}...\n",
      "Size of left dataframe: 1697\n",
      "Size of stereo dataframe: 1692\n",
      "Sending 3919 annotated_ids for creating dataset\n",
      "Time taken to prepare data for dataset creation job: 0.83 mins\n"
     ]
    }
   ],
   "source": [
    "# # in master branch halo datasets\n",
    "# annotations = imageids_to_annotation_df(\n",
    "#     image_ids=df.id.to_list(),\n",
    "# )\n",
    "\n",
    "imageids_to_dataset(\n",
    "    image_ids=test_df.id.to_list(),\n",
    "    dataset_name=\"halo_potential_airborne_debris_from_train_6_2_labeled\",\n",
    "    dataset_description=\"labeled airborne debris images in the same geohash as in train set v6.2, from 7270 images\",\n",
    "    dataset_kind='annotation',  # annotation or image\n",
    "    mode='stereo',  # stereo or mono\n",
    "    production_dataset=True,\n",
    ")\n",
    "# Dataset.create(\n",
    "#     name=\"20230925_halo_rgb_stereo_train_v3_pruned\",\n",
    "#     description=\"180 images with >0.5 focal loss from dataset 20230925_halo_rgb_stereo_train_v3\",\n",
    "#     kind=Dataset.KIND_ANNOTATION,\n",
    "#     image_ids=df.id.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to download large image dataset and save in jpg format, change the following files\n",
    "# note original files are ending with .bk, and changed files are ending with .save_jpg\n",
    "# /home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/brtdevkit/data/core/dataset.py\n",
    "# /home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/brtdevkit/util/aws/s3.py\n",
    "# /home/li.yu/anaconda3/envs/brtdevkit/lib/python3.9/site-packages/brtdevkit/data/core/dataset.py  # save only one png file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = '20240301_5_million_for_self_supervised_part_0'\n",
    "dataset_name = 'halo_potential_birds_from_train_8_1'\n",
    "dataset_dir = os.path.join('/data/jupiter/datasets', dataset_name)\n",
    "# dataset_dir = os.path.join('/data2/jupiter/datasets', dataset_name)\n",
    "# dataset_dir = os.path.join('/data/jupiter/li.yu/data', dataset_name)\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "test_dataset = Dataset.retrieve(name=dataset_name)\n",
    "test_df = test_dataset.to_dataframe()\n",
    "test_dataset.download(dataset_dir, df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (10,20,21,22,23,24,26,27,29,30,31,32,33,34,35,36,46,57,70,84,85,87,91,93,103,106,107,115,132,137,138,140,142,145,146,158,192,193) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999999, 197)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'images/64bef342438af9b8c7971547.jpg'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = '20240301_5_million_for_self_supervised_part_0'\n",
    "df = pd.read_csv(os.path.join('/data/jupiter/datasets', dataset_name, 'annotations.csv'))\n",
    "# df = pd.read_csv(os.path.join('/data/jupiter/li.yu/data', dataset_name, 'annotations.csv'))\n",
    "print(df.shape)\n",
    "df.iloc[0].artifact_debayeredrgb_0_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "999940"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(os.path.join('/data/jupiter/datasets', dataset_name, 'images'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999940/999940 [18:36<00:00, 895.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "29"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "corrupted = []\n",
    "for f in tqdm(files, total=len(files)):\n",
    "    try:\n",
    "        img = Image.open(os.path.join('/data/jupiter/datasets', dataset_name, 'images', f))\n",
    "        img.close()\n",
    "    except:\n",
    "        corrupted.append(f)\n",
    "len(corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999799\n"
     ]
    }
   ],
   "source": [
    "good = list(set(files) - set(corrupted))\n",
    "good = [f[:-4] for f in good if f.endswith('.jpg')]\n",
    "print(len(good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999799, 1)\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame(data={'id': good})\n",
    "print(df3.shape)\n",
    "df3.to_csv(os.path.join('/data/jupiter/datasets', dataset_name, 'saved_ids.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 64-bit ('brtdevkit': conda)",
   "name": "python3918jvsc74a57bd0c8cced58dbff2798e473c5ca6eca1100bfa72eead58bcdfb1b17e02c86ac111a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "metadata": {
   "interpreter": {
    "hash": "c8cced58dbff2798e473c5ca6eca1100bfa72eead58bcdfb1b17e02c86ac111a"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}