{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "from utils import normalize_image, get_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from collections import namedtuple\n",
    "\n",
    "class ModelType(Enum):\n",
    "    CLASSIFICATION = 0\n",
    "    SEGMENTATION = 1\n",
    "\n",
    "classlabels_viz_colors = ['black', 'green', 'yellow', 'blue', 'red', 'magenta', 'cyan',\n",
    "                          'lightseagreen', 'brown', 'magenta', 'olive', 'wheat', 'white', 'black']\n",
    "classlabels_viz_bounds = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 100]\n",
    "\n",
    "classlabels_viz_cmap = mpl.colors.ListedColormap(classlabels_viz_colors)\n",
    "classlabels_viz_norm = mpl.colors.BoundaryNorm(classlabels_viz_bounds, classlabels_viz_cmap.N)\n",
    "\n",
    "confidence_heatmap_viz_colors = ['black', 'blue', 'red', 'orange', 'yellow', 'lightgreen', 'lightseagreen']\n",
    "confidence_heatmap_viz_bounds = [-1, 0,0.5,0.6,0.7,0.8,0.9,1]\n",
    "confidence_heatmap_viz_cmap = mpl.colors.ListedColormap(confidence_heatmap_viz_colors)\n",
    "confidence_heatmap_viz_norm = mpl.colors.BoundaryNorm(confidence_heatmap_viz_bounds, confidence_heatmap_viz_cmap.N)\n",
    "\n",
    "\n",
    "LabelColor = namedtuple('LabelColor', ['name', 'id', 'trainid', 'color', 'category'])\n",
    "\n",
    "LABEL_COLORS = [\n",
    "    LabelColor('class1', 1, 0, (128, 0, 128), 'driveableterrain'),\n",
    "    LabelColor('class2', 2, 1, (255, 0, 0), 'non-driveableterrain'),\n",
    "    LabelColor('class3', 3, 2, (0, 0, 255), 'sky'),\n",
    "    LabelColor('class4', 4, 3, (0, 255, 0), 'trees'),\n",
    "    LabelColor('class5', 5, 4, (255, 0, 255), 'implement'),\n",
    "    LabelColor('class6', 6, 5, (255, 255, 0), 'basket markers')\n",
    "]\n",
    "\n",
    "LABEL_COLORS_4CLASS = LABEL_COLORS[0:4]\n",
    "LABEL_COLORS_5CLASS = LABEL_COLORS[0:5]\n",
    "LABEL_COLORS_6CLASS = LABEL_COLORS[0:6]\n",
    "LABEL_COLORS_SKY_DET = [LABEL_COLORS[0], LABEL_COLORS[2]]\n",
    "\n",
    "LABEL_COLORS_IMPL = [\n",
    "    LabelColor('class1', 1, 1, (128, 0, 128), 'implement'),\n",
    "    LabelColor('class2', 2, 2, (255, 0, 0), 'sweep'),\n",
    "    LabelColor('class3', 3, 3, (0, 0, 255), 'harrow_tine'),\n",
    "    LabelColor('class4', 4, 4, (0, 255, 0), 'basket'),\n",
    "    LabelColor('class5', 5, 5, (0, 255, 0), 'basket_marker'),\n",
    "    LabelColor('class6', 0, 255, (0, 0, 0), 'ignore')\n",
    "]\n",
    "\n",
    "LABEL_COLORS_IMPL_REDUCED = [\n",
    "    LabelColor('class0', 1, 0, (0, 0, 0), 'background'),\n",
    "    LabelColor('class1', 2, 1, (0, 255, 0), 'implement'),\n",
    "    LabelColor('class2', 3, 2, (255, 0, 0), 'sweep'),\n",
    "    LabelColor('class3', 4, 3, (0, 255, 0), 'basket_marker'),\n",
    "    LabelColor('class6', 0, 255, (0, 0, 0), 'ignore')\n",
    "]\n",
    "\n",
    "PLUG_LABEL_MAP ={0: 'no-plug', 1: 'plug'}\n",
    "IMPL_SEGMENT_LABEL_MAP = {0: 'background', 1: 'implement', 2: 'sweep', 3:'basket_marker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mpl_viz_outputs(output_path,\n",
    "                           image,\n",
    "                           prediction_labels,\n",
    "                           confidences,\n",
    "                           depth_img, \n",
    "                           image_title='Image', \n",
    "                           pred_title='Prediction', \n",
    "                           conf_title='Confidence', \n",
    "                           depth_title='Depth',\n",
    "                           bbox_coords=[]):\n",
    "    \"\"\"\n",
    "    Utility function to plot results based on order of input provided.\n",
    "\n",
    "    Axes index can have different values based on input provided.\n",
    "\n",
    "    For example: If image, prediction and groundtruth_label is provided, A three axes plot will be generated with\n",
    "    image(ax1), ground_truth(ax2), prediction(ax3).\n",
    "\n",
    "    Order of plot if all the inputs are provided will be in same order as arguments listed above.\n",
    "    \"\"\"\n",
    "    axis_index = list(range(len(list(filter(lambda x: x is not None, [image,\n",
    "                                                                      prediction_labels, confidences,\n",
    "                                                                      depth_img])))))\n",
    "    axis_curr_index = 0\n",
    "    fig, axes = mpl.pyplot.subplots(1, len(axis_index), figsize=((60, 30)))\n",
    "    if bbox_coords:\n",
    "#         xmin, ymin, xmax, ymax = bbox_coords\n",
    "        xmin, xmax, ymin, ymax = bbox_coords\n",
    "        if (xmin < 0) or (ymin < 0):\n",
    "            raise ValueError(f'Either {xmin} or {ymin} are negative')\n",
    "        else:\n",
    "            rect = mpl.patches.Rectangle((ymin, xmin), (ymax - ymin), (xmax - xmin), linewidth=3, edgecolor='k',\n",
    "                                     facecolor='none')\n",
    "    else:\n",
    "        rect = None\n",
    "\n",
    "    if axis_curr_index < len(axes):\n",
    "        # Grab only RGB channels from image, otherwise depth with distort the image when it is displayed\n",
    "        axes[axis_curr_index].imshow(image)\n",
    "        axes[axis_curr_index].set_title(image_title, fontsize=30)\n",
    "        axes[axis_curr_index].axis('off')\n",
    "        axis_curr_index += 1\n",
    "\n",
    "    if axis_curr_index < len(axes):\n",
    "        axes[axis_curr_index].imshow(depth_img, cmap='turbo')\n",
    "        axes[axis_curr_index].set_title(depth_title, fontsize=30)\n",
    "        axes[axis_curr_index].axis('off')\n",
    "        axis_curr_index += 1\n",
    "\n",
    "    if axis_curr_index < len(axes):\n",
    "        axes[axis_curr_index].imshow(prediction_labels, classlabels_viz_cmap, classlabels_viz_norm, interpolation='nearest')\n",
    "        if rect is not None:\n",
    "            rect1 = mpl.patches.Rectangle((ymin, xmin), (ymax - ymin), (xmax - xmin), linewidth=3, edgecolor='k',facecolor='none')\n",
    "            axes[axis_curr_index].add_patch(rect1)\n",
    "        axes[axis_curr_index].set_title(pred_title, fontsize=30)\n",
    "        axes[axis_curr_index].axis('off')\n",
    "        axis_curr_index += 1\n",
    "\n",
    "    if axis_curr_index < len(axes):\n",
    "        c = np.max(confidences, axis=2)\n",
    "        axes[axis_curr_index].imshow(c, confidence_heatmap_viz_cmap, confidence_heatmap_viz_norm, interpolation='nearest')\n",
    "#         if rect is not None:\n",
    "#             rect2 = mpl.patches.Rectangle((ymin, xmin), (ymax - ymin), (xmax - xmin), linewidth=3, edgecolor='k',\n",
    "#                                           facecolor='none')\n",
    "#             axes[axis_curr_index].add_patch(rect2)\n",
    "        axes[axis_curr_index].set_title(conf_title, fontsize=30)\n",
    "        axes[axis_curr_index].axis('off')\n",
    "        axis_curr_index += 1\n",
    "\n",
    "    mpl.pyplot.savefig(output_path, pad_inches=0, bbox_inches='tight', dpi=150)\n",
    "    mpl.pyplot.close('all')\n",
    "\n",
    "def read_image(image_path):\n",
    "    image = (np.load(image_path) * 255).astype(np.uint8)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def read_saved_frame(pred_dir, image_id):\n",
    "    states_to_save = ['', 'false_positive', 'false_negative', 'large_object_false_negative', 'true_positive', 'true_negative']\n",
    "    frame = None\n",
    "    for state in states_to_save:\n",
    "        if os.path.isfile(os.path.join(pred_dir, state, image_id+'.png')):\n",
    "            frame = cv2.imread(os.path.join(pred_dir, state, image_id+'.png'))\n",
    "            break\n",
    "        if os.path.isfile(os.path.join(pred_dir, state, image_id+'.jpg')):\n",
    "            frame = cv2.imread(os.path.join(pred_dir, state, image_id+'.jpg'))\n",
    "            break\n",
    "    return frame\n",
    "\n",
    "def read_images(pred_dir, _id):\n",
    "    if not os.path.isfile(os.path.join(pred_dir, _id+'_image.npy')):\n",
    "        return None, None, None, None\n",
    "    image = np.load(os.path.join(pred_dir, _id+'_image.npy'))\n",
    "    \n",
    "    # 100m capped depth\n",
    "    depth = np.load(os.path.join(pred_dir, _id+'_depth.npy'))\n",
    "#     # raw depth\n",
    "#     raw_depth_dir = '/raum_raid/li.yu/data/Jupiter_rock_demo_2021/Jupiter_rock_demo_loamy06_Oct20_2021/model_processed_v4.1_sky_2e-3_lr_1e-3_color_aug_full_model_LR_consistency_regularization_0.2_epoch_23/images/'\n",
    "#     stereo_data = np.load(os.path.join(raw_depth_dir, _id, 'stereo_output.npz'))\n",
    "#     depth = stereo_data['point_cloud'][:,:,-1]\n",
    "#     depth = normalize_and_clip_depth(depth, 200)\n",
    "    \n",
    "    pred_label = np.load(os.path.join(pred_dir, _id+'_pred_label.npy'))\n",
    "    confidence = np.load(os.path.join(pred_dir, _id+'_confidence.npy'))\n",
    "    return image, depth, pred_label, confidence\n",
    "\n",
    "# def create_frame(pred_dir, pred_merged_dir, _id, recreate=False):\n",
    "#     canvas_path = os.path.join(pred_merged_dir, _id+'.png')\n",
    "#     if recreate:\n",
    "#         image, depth, pred_label, confidence = read_images(pred_dir, _id)\n",
    "#         if image is None:\n",
    "#             return None\n",
    "#         create_mpl_viz_outputs(canvas_path, image, pred_label, confidence, depth)\n",
    "#     frame = cv2.imread(canvas_path)\n",
    "#     return frame\n",
    "\n",
    "def get_bbox_coords(i=-1, bbox_range_list=[], bbox_coord_list=[]):\n",
    "    for bi in range(len(bbox_range_list)):\n",
    "        bbox_range = bbox_range_list[bi]\n",
    "        if bbox_range[0] <= i <= bbox_range[1]:\n",
    "            return bbox_coord_list[bi]\n",
    "    return []\n",
    "\n",
    "def process_frame(pred_dir, pred_merged_dir, _id, recreate=False, bbox_coords=[]):\n",
    "    image, depth, pred_label, confidence = None, None, None, None\n",
    "    l = 0.0\n",
    "    avg_pixel = 0.0\n",
    "    bbox_conf = None\n",
    "    if recreate:\n",
    "        image, depth, pred_label, confidence = read_images(pred_dir, _id)\n",
    "        if image is None:\n",
    "            return image, depth, pred_label, confidence, l, avg_pixel, bbox_conf\n",
    "        # calculate brightness\n",
    "        hlsImg = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        l = np.average(hlsImg[:,:,1])\n",
    "        image_title = 'Image (brightness: {:.4f})'.format(l)\n",
    "        # calculate average pixel value at bbox area\n",
    "        if bbox_coords:\n",
    "            ymin, ymax, xmin, xmax = bbox_coords\n",
    "            bbox_pred = pred_label[ymin:ymax+1, xmin:xmax+1]\n",
    "            bbox_conf = confidence[ymin:ymax+1, xmin:xmax+1]\n",
    "            avg_pixel = np.count_nonzero(bbox_pred == 1)\n",
    "    return image, depth, pred_label, confidence, l, avg_pixel, bbox_conf\n",
    "\n",
    "def create_frame(pred_dir, pred_merged_dir, _id, recreate=False, bbox_coords=[]):\n",
    "    canvas_path = os.path.join(pred_merged_dir, _id+'.png')\n",
    "    image, depth, pred_label, confidence = None, None, None, None\n",
    "    l = 0.0\n",
    "    avg_pixel = 0.0\n",
    "    bbox_conf = None\n",
    "    if recreate:\n",
    "        image, depth, pred_label, confidence = read_images(pred_dir, _id)\n",
    "        if image is None:\n",
    "            return None, None, None, None, None, None, None, None\n",
    "        # calculate brightness\n",
    "        hlsImg = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        l = np.average(hlsImg[:,:,1])\n",
    "        image_title = 'Image (brightness: {:.4f})'.format(l)\n",
    "        # calculate average pixel value at bbox area\n",
    "        if bbox_coords:\n",
    "            ymin, ymax, xmin, xmax = bbox_coords\n",
    "            bbox_pred = pred_label[ymin:ymax+1, xmin:xmax+1]\n",
    "            bbox_conf = confidence[ymin:ymax+1, xmin:xmax+1]\n",
    "            avg_pixel = np.count_nonzero(bbox_pred == 1)\n",
    "        create_mpl_viz_outputs(canvas_path, image, pred_label, confidence, depth, image_title=image_title, bbox_coords=bbox_coords)\n",
    "    frame = cv2.imread(canvas_path)\n",
    "    return frame, image, depth, pred_label, confidence, l, avg_pixel, bbox_conf\n",
    "\n",
    "def create_diff_frame(pred_merged_dir, _id, image1, depth1, pred_label1, confidence1, \n",
    "                      image2, depth2, pred_label2, confidence2, pred_title='prediction', conf_title='confidence'):\n",
    "    canvas_path = os.path.join(pred_merged_dir, _id+'_diff.png')\n",
    "    image = np.abs(image1 - image2)\n",
    "    depth = np.abs(depth1 - depth2)\n",
    "    pred_label = np.abs(pred_label1 - pred_label2)\n",
    "    confidence = np.abs(confidence1 - confidence2)\n",
    "    create_mpl_viz_outputs(canvas_path, image, pred_label, confidence, depth, conf_title=conf_title)\n",
    "    frame = cv2.imread(canvas_path)\n",
    "    return frame\n",
    "\n",
    "def read_raw_image_by_id(data_dir, _id):\n",
    "    image_path = os.path.join(data_dir, 'images', _id, 'artifact_debayeredrgb_0_'+_id+'.png')\n",
    "    image = cv2.imread(image_path)\n",
    "    return image\n",
    "\n",
    "def read_raw_image_by_row(data_dir, row):\n",
    "    image = cv2.imread(os.path.join(data_dir, row.artifact_debayeredrgb_0_save_path))\n",
    "    return image\n",
    "\n",
    "def read_rectified_image(data_dir, row):\n",
    "    data_path = os.path.join(data_dir, row.stereo_pipeline_npz_save_path)\n",
    "    img = np.load(data_path)['left']\n",
    "    img = normalize_image(img, hdr_mode=row.hdr_mode, return_8_bit=True)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def create_video(ids, pred_dir, video_name, read_func=read_saved_frame, fps=2):\n",
    "    frame = read_func(pred_dir, ids[10])\n",
    "    height, width, layers = frame.shape\n",
    "    print(height, width, layers)\n",
    "\n",
    "    # .avi MJPG,  .mp4 MP4V\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width,height), isColor=True)\n",
    "    \n",
    "    good = 0\n",
    "    for _id in tqdm(ids):\n",
    "        frame = read_func(pred_dir, _id)\n",
    "        if frame is not None:\n",
    "            video.write(frame)\n",
    "            good += 1\n",
    "    print('total', len(ids), 'used', good)\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create video from raw left images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13037, 112) 13\n"
     ]
    }
   ],
   "source": [
    "# create video from raw left images\n",
    "data_dir = '/data/jupiter/datasets/dust_datasets/halo_human_with_dust_on_lens_jf163'\n",
    "# data_dir = '/data/jupiter/datasets/safety_datasets/dust/halo_human_in_dust_day_v5'\n",
    "# data_dir = '/data3/jupiter/datasets/model_positive/halo_human_w_corn_stubble_0812_oct'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'annotations.csv'))\n",
    "# df = pd.read_csv(os.path.join(data_dir, 'master_annotations.csv'))\n",
    "\n",
    "seq_dfs = get_sequences(df, interval=60, per_camera=False, per_camera_pair=False)  # break the data by intervals between sequences\n",
    "print(df.shape, len(seq_dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select images for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halo_human_in_dust_day_collection_may29 (48102, 108) day\n",
      "halo_human_in_dust_night_collection_june03_2 (127568, 108) 20 {'dawn_dusk': [0, 1, 2, 3, 4, 5, 6, 7, 8], 'night': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]}\n",
      "halo_human_in_dust_day_collection_back_june05 (11675, 108) day\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2996009/4013714849.py:18: DtypeWarning: Columns (0,1,34,40,49,51,62,75,85,87,89,90,91,99,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(data_root_dir, dataset, 'annotations.csv'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halo_human_in_dust_dusk_collection_front_june07 (36338, 104) dawn_dusk\n",
      "halo_human_in_dust_night_collection_july29 (7956, 111) night\n",
      "(228247, 2)\n"
     ]
    }
   ],
   "source": [
    "# combine and create datasets for human in dust\n",
    "# data_root_dir = '/data/jupiter/datasets'\n",
    "data_root_dir = '/data/jupiter/li.yu/data/dust_data_colletion_for_july_1st'\n",
    "unlabeled_datasets = [\n",
    "    \"halo_human_in_dust_day_collection_may29\",\n",
    "    \"halo_human_in_dust_night_collection_june03\",  # for lying down humans\n",
    "    \"halo_human_in_dust_night_collection_june03_2\",\n",
    "    \"halo_human_in_dust_day_collection_back_june05\",\n",
    "    \"halo_human_in_dust_dusk_collection_front_june07\",\n",
    "    \"halo_human_in_dust_night_collection_july29\",\n",
    "]\n",
    "day_night_splits = ['day', 'dawn_dusk', {'dawn_dusk': list(range(0, 9)), 'night': list(range(9, 19))}, 'day', 'dawn_dusk', 'night']\n",
    "use_ds = [0, 2, 3, 4, 5]\n",
    "# split data by day time\n",
    "image_ids_by_time = {'id':[], 'day_night_split': []}\n",
    "for di in use_ds:\n",
    "    dataset = unlabeled_datasets[di]\n",
    "    df = pd.read_csv(os.path.join(data_root_dir, dataset, 'annotations.csv'))\n",
    "    df = df.sort_values('collected_on')\n",
    "    day_night_split = day_night_splits[di]\n",
    "    if isinstance(day_night_split, str):\n",
    "        print(dataset, df.shape, day_night_split)\n",
    "        image_ids_by_time['id'] += df.id.to_list()\n",
    "        image_ids_by_time['day_night_split'] += [day_night_split] * len(df)\n",
    "    else:\n",
    "        seq_dfs = get_sequences(df, interval=60)  # break the data by intervals between sequences\n",
    "        print(dataset, df.shape, len(seq_dfs), day_night_split)\n",
    "        for dn_split, seq_ids in day_night_split.items():\n",
    "            for seq_id in seq_ids:\n",
    "                seq_df = seq_dfs[seq_id]\n",
    "                image_ids_by_time['id'] += seq_df.id.to_list()\n",
    "                image_ids_by_time['day_night_split'] += [dn_split] * len(seq_df)\n",
    "# save to csv\n",
    "day_night_split_df = pd.DataFrame(data=image_ids_by_time)\n",
    "print(day_night_split_df.shape)\n",
    "day_night_split_df.to_csv('/data/jupiter/li.yu/data/halo_hard_cases/halo_human_in_dust_daynightsplit_for_july01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176217, 2)\n"
     ]
    }
   ],
   "source": [
    "# image_ids_by_time = {'id':[], 'day_night_split': []}\n",
    "# split data in day/dusk/night\n",
    "day_night_splits = [{'day': list(range(0,25)), 'dawn_dusk': list(range(25, 31)), 'night': list(range(31, 38))}, \n",
    "                   {'dawn_dusk': list(range(0, 14)), 'night': list(range(14, 29))},\n",
    "                   {'dawn_dusk': [0, 1, 2, 7, 8, 9], 'night': [3, 4, 5, 6, 10, 11, 12]}]\n",
    "day_night_split = day_night_splits[2]\n",
    "for dn_split, seq_ids in day_night_split.items():\n",
    "    for seq_id in seq_ids:\n",
    "        seq_df = seq_dfs[seq_id]\n",
    "        image_ids_by_time['id'] += seq_df.id.to_list()\n",
    "        image_ids_by_time['day_night_split'] += [dn_split] * len(seq_df)\n",
    "# save to csv\n",
    "day_night_split_df = pd.DataFrame(data=image_ids_by_time)\n",
    "print(day_night_split_df.shape)\n",
    "day_night_split_df.to_csv('/data/jupiter/li.yu/data/halo_hard_cases/halo_vehicle_in_dust_daynightsplit_excludebadnight_for_july01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{34: [['T10', 'less'], ['T09', 'no']], 35: [['T09', 'less'], ['T10', 'no']], 38: [['T10', 'normal'], ['T09', 'no']], 39: [['T09', 'normal'], ['T10', 'less']]}\n"
     ]
    }
   ],
   "source": [
    "def parse_camera_sample_desc(s):\n",
    "    def parse_camera_desc(cam):\n",
    "        ts = cam.split(' ')\n",
    "        if len(ts) == 1:\n",
    "            return [ts[0], 'normal']\n",
    "        else:\n",
    "            return ts\n",
    "    if not s.endswith(','):\n",
    "        s += ','\n",
    "    tokens = s.split('),')\n",
    "    camera_sample_desc = {}\n",
    "    for token in tokens:\n",
    "        token = token.strip()\n",
    "        if not token:\n",
    "            continue\n",
    "        seq_i, cam1_cam2 = token.split(' (')\n",
    "        cam1, cam2 = cam1_cam2.split(', ')\n",
    "        camera_sample_desc[int(seq_i)] = [parse_camera_desc(cam1), parse_camera_desc(cam2)]\n",
    "    return camera_sample_desc\n",
    "\n",
    "def select_by_camera_sample_ratio(seq_dfs, selected, camera_sample_ratio, save_csv=''):\n",
    "    parsed_selected = {pod: parse_camera_sample_desc(s) for pod,s in selected.items()}\n",
    "    selected_ids = []\n",
    "    for pod, camera_sample_desc in parsed_selected.items():\n",
    "        for seq_i, cam_desc_list in camera_sample_desc.items():\n",
    "            seq_df = seq_dfs[seq_i]\n",
    "            for cam, desc in cam_desc_list:\n",
    "                cam_df = seq_df[seq_df.camera_location == cam]\n",
    "                sample_ratio = camera_sample_ratio[desc]\n",
    "                if sample_ratio < 1:\n",
    "                    sample_df = cam_df.sample(frac=sample_ratio)\n",
    "                else:\n",
    "                    sample_df = cam_df.sample(n=int(sample_ratio))\n",
    "                print(pod, seq_i, cam, desc, len(cam_df), len(sample_df))\n",
    "                selected_ids += sample_df.id.to_list()\n",
    "    selected_ids = list(set(selected_ids))\n",
    "    selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "    print(selected_df.shape)\n",
    "    if save_csv:\n",
    "        selected_df.to_csv(save_csv, index=False)\n",
    "\n",
    "s = \"34 (T10 less, T09 no), 35 (T09 less, T10 no), 38 (T10, T09 no), 39 (T09, T10 less)\"\n",
    "print(parse_camera_sample_desc(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back 3 T10 less 188 28\n",
      "back 3 T09 no 188 2\n",
      "back 4 T09 less 111 17\n",
      "back 4 T10 no 111 2\n",
      "back 12 T09 fix 120 5\n",
      "back 12 T10 fix 120 5\n",
      "back 13 T09 fix 190 5\n",
      "back 13 T10 no 189 2\n",
      "back 14 T09 fix 112 5\n",
      "back 14 T10 no 111 2\n",
      "front 0 T01 less 111 17\n",
      "front 0 T02 no 111 2\n",
      "front 7 T02 less 113 17\n",
      "front 7 T01 no 113 2\n",
      "front 8 T02 less 111 17\n",
      "front 8 T01 no 111 2\n",
      "front 9 T01 less 185 28\n",
      "front 9 T02 no 186 2\n",
      "front 10 T01 less 111 17\n",
      "front 10 T02 no 111 2\n",
      "left 5 T14 fix 194 5\n",
      "left 5 T13 no 194 2\n",
      "left 6 T13 less 188 28\n",
      "left 6 T14 no 188 2\n",
      "left 15 T13 less 167 25\n",
      "left 15 T14 no 167 2\n",
      "right 1 T06 less 186 28\n",
      "right 1 T05 no 186 2\n",
      "right 2 T05 less 111 17\n",
      "right 2 T06 no 111 2\n",
      "right 11 T05 fix 186 5\n",
      "right 11 T06 no 186 2\n",
      "(299, 1)\n"
     ]
    }
   ],
   "source": [
    "# for selection of images for labeling - halo_human_in_dust_jf149\n",
    "selected = {'back': '3 (T10 less, T09 no), 4 (T09 less, T10 no), 12 (T09 fix, T10 fix), 13 (T09 fix, T10 no), 14 (T09 fix, T10 no)',\n",
    "            'front': '0 (T01 less, T02 no), 7 (T02 less, T01 no), 8 (T02 less, T01 no), 9 (T01 less, T02 no), 10 (T01 less, T02 no)',\n",
    "            'left': '5 (T14 fix, T13 no), 6 (T13 less, T14 no), 15 (T13 less, T14 no)',\n",
    "            'right': '1 (T06 less, T05 no), 2 (T05 less, T06 no), 11 (T05 fix, T06 no)',}\n",
    "camera_sample_ratio = {'normal': 0.33, 'less': 0.15, 'fix': 5, 'no': 2}\n",
    "save_csv = '/data/jupiter/datasets/dust_datasets/halo_human_in_dust_jf149/selected_for_label.csv'\n",
    "select_by_camera_sample_ratio(seq_dfs, selected, camera_sample_ratio, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back 4 T10 less 169 20\n",
      "back 4 T09 no 168 2\n",
      "back 5 T09 less 60 7\n",
      "back 5 T10 no 60 2\n",
      "back 10 T10 less 382 46\n",
      "back 10 T09 less 380 46\n",
      "front 0 T02 less 112 13\n",
      "front 0 T01 no 112 2\n",
      "front 1 T01 less 111 13\n",
      "front 1 T02 no 111 2\n",
      "front 8 T02 less 200 24\n",
      "front 8 T01 less 200 24\n",
      "front 12 T02 less 233 28\n",
      "front 12 T01 less 232 28\n",
      "left 6 T14 less 298 36\n",
      "left 6 T13 less 296 36\n",
      "left 7 T14 less 248 30\n",
      "left 7 T13 less 248 30\n",
      "left 11 T14 less 384 46\n",
      "left 11 T13 less 383 46\n",
      "right 2 T06 less 186 22\n",
      "right 2 T05 no 186 2\n",
      "right 3 T05 less 116 14\n",
      "right 3 T06 no 116 2\n",
      "right 9 T06 less 762 91\n",
      "right 9 T05 less 764 92\n",
      "(704, 1)\n"
     ]
    }
   ],
   "source": [
    "# for selection of images for labeling - halo_human_with_dust_on_lens_jf163\n",
    "selected = {'back': '4 (T10 less, T09 no), 5 (T09 less, T10 no), 10 (T10 less, T09 less)',\n",
    "            'front': '0 (T02 less, T01 no), 1 (T01 less, T02 no), 8 (T02 less, T01 less), 12 (T02 less, T01 less),',\n",
    "            'left': '6 (T14 less, T13 less), 7 (T14 less, T13 less), 11 (T14 less, T13 less)',\n",
    "            'right': '2 (T06 less, T05 no), 3 (T05 less, T06 no), 9 (T06 less, T05 less)',}\n",
    "camera_sample_ratio = {'normal': 0.33, 'less': 0.12, 'fix': 5, 'no': 2}\n",
    "save_csv = '/data/jupiter/datasets/dust_datasets/halo_human_with_dust_on_lens_jf163/selected_for_label.csv'\n",
    "select_by_camera_sample_ratio(seq_dfs, selected, camera_sample_ratio, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back 34 T10 less 185 28\n",
      "back 34 T09 no 184 1\n",
      "back 35 T09 less 187 28\n",
      "back 35 T10 no 187 1\n",
      "back 38 T10 normal 187 62\n",
      "back 38 T09 no 188 1\n",
      "back 39 T09 normal 18 6\n",
      "back 39 T10 less 18 3\n",
      "front 8 T01 less 102 15\n",
      "front 8 T02 no 102 1\n",
      "front 9 T02 less 102 15\n",
      "front 9 T01 no 101 1\n",
      "front 10 T01 no 186 1\n",
      "front 10 T02 no 186 1\n",
      "front 11 T01 no 99 1\n",
      "front 11 T02 less 101 15\n",
      "front 20 T01 no 101 1\n",
      "front 20 T02 less 102 15\n",
      "front 21 T01 no 101 1\n",
      "front 21 T02 no 100 1\n",
      "front 29 T02 less 187 28\n",
      "front 29 T01 no 187 1\n",
      "front 30 T01 less 99 15\n",
      "front 30 T02 no 100 1\n",
      "front 32 T01 no 118 1\n",
      "front 32 T02 less 118 18\n",
      "front 33 T01 less 187 28\n",
      "front 33 T02 no 187 1\n",
      "front 40 T02 normal 113 37\n",
      "front 40 T01 less 113 17\n",
      "front 41 T01 normal 112 37\n",
      "front 41 T02 less 112 17\n",
      "front 42 T01 less 111 17\n",
      "front 42 T02 no 112 1\n",
      "front 43 T01 no 204 1\n",
      "front 43 T02 no 205 1\n",
      "front 44 T02 normal 185 61\n",
      "front 44 T01 no 186 1\n",
      "front 45 T01 no 112 1\n",
      "front 45 T02 no 112 1\n",
      "front 46 T01 no 23 1\n",
      "front 46 T02 no 23 1\n",
      "left 0 T13 less 186 28\n",
      "left 0 T14 no 187 1\n",
      "left 1 T13 no 107 1\n",
      "left 1 T14 no 106 1\n",
      "left 2 T13 no 188 1\n",
      "left 2 T14 no 188 1\n",
      "left 4 T13 no 89 1\n",
      "left 4 T14 no 89 1\n",
      "left 5 T13 no 189 1\n",
      "left 5 T14 no 190 1\n",
      "left 6 T13 less 186 28\n",
      "left 6 T14 no 186 1\n",
      "left 7 T13 no 109 1\n",
      "left 7 T14 less 110 16\n",
      "left 8 T13 no 107 1\n",
      "left 8 T14 no 108 1\n",
      "left 10 T13 no 186 1\n",
      "left 10 T14 fix 186 10\n",
      "left 12 T13 less 185 28\n",
      "left 12 T14 no 186 1\n",
      "left 13 T13 fix 106 10\n",
      "left 13 T14 less 106 16\n",
      "left 15 T13 no 107 1\n",
      "left 15 T14 no 107 1\n",
      "left 16 T13 fix 105 10\n",
      "left 16 T14 fix 105 10\n",
      "left 18 T13 no 106 1\n",
      "left 18 T14 fix 107 10\n",
      "left 19 T13 fix 185 10\n",
      "left 19 T14 fix 186 10\n",
      "left 21 T13 no 184 1\n",
      "left 21 T14 no 185 1\n",
      "left 23 T13 no 186 1\n",
      "left 23 T14 no 186 1\n",
      "left 24 T13 fix 104 10\n",
      "left 24 T14 fix 105 10\n",
      "left 25 T13 fix 103 10\n",
      "left 25 T14 fix 104 10\n",
      "left 27 T13 no 105 1\n",
      "left 27 T14 less 105 16\n",
      "left 28 T13 normal 106 35\n",
      "left 28 T14 no 105 1\n",
      "left 30 T13 fix 103 10\n",
      "left 30 T14 fix 103 10\n",
      "left 36 T13 no 112 1\n",
      "left 36 T14 less 112 17\n",
      "left 37 T13 less 203 30\n",
      "left 37 T14 fix 203 10\n",
      "left 40 T13 normal 22 7\n",
      "left 40 T14 less 22 3\n",
      "right 0 T05 no 185 1\n",
      "right 0 T06 no 187 1\n",
      "right 1 T05 less 100 15\n",
      "right 1 T06 no 101 1\n",
      "right 2 T05 no 102 1\n",
      "right 2 T06 less 102 15\n",
      "right 3 T05 no 101 1\n",
      "right 3 T06 no 101 1\n",
      "right 7 T05 no 105 1\n",
      "right 7 T06 no 104 1\n",
      "right 9 T05 no 100 1\n",
      "right 9 T06 no 102 1\n",
      "right 11 T05 no 100 1\n",
      "right 11 T06 no 101 1\n",
      "right 13 T05 no 101 1\n",
      "right 13 T06 no 101 1\n",
      "right 14 T05 no 186 1\n",
      "right 14 T06 no 186 1\n",
      "right 17 T05 no 186 1\n",
      "right 17 T06 no 187 1\n",
      "right 22 T05 no 185 1\n",
      "right 22 T06 fix 185 10\n",
      "right 23 T05 no 186 1\n",
      "right 23 T06 no 186 1\n",
      "right 24 T05 less 184 28\n",
      "right 24 T06 fix 186 10\n",
      "right 26 T05 fix 103 10\n",
      "right 26 T06 no 102 1\n",
      "right 31 T05 no 101 1\n",
      "right 31 T06 less 101 15\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# for selection of images for labeling - halo_dust_smudge_JUPD-1105_2024-10-23\n",
    "selected = {'back': '34 (T10 less, T09 no), 35 (T09 less, T10 no), 38 (T10, T09 no), 39 (T09, T10 less),',\n",
    "            'front': '8 (T01 less, T02 no), 9 (T02 less, T01 no), 10 (T01 no, T02 no), 11 (T01 no, T02 less), 20 (T01 no, T02 less), 21 (T01 no, T02 no), 29 (T02 less, T01 no), 30 (T01 less, T02 no), 32 (T01 no, T02 less), 33 (T01 less, T02 no), 40 (T02, T01 less), 41 (T01, T02 less), 42 (T01 less, T02 no), 43 (T01 no, T02 no), 44 (T02, T01 no), 45 (T01 no, T02 no), 46 (T01 no, T02 no)',\n",
    "            'left': '0 (T13 less, T14 no), 1 (T13 no, T14 no), 2 (T13 no, T14 no), 4 (T13 no, T14 no), 5 (T13 no, T14 no), 6 (T13 less, T14 no), 7 (T13 no, T14 less), 8 (T13 no, T14 no), 10 (T13 no, T14 fix), 12 (T13 less, T14 no), 13 (T13 fix, T14 less), 15 (T13 no, T14 no), 16 (T13 fix, T14 fix), 18 (T13 no, T14 fix), 19 (T13 fix, T14 fix), 21 (T13 no, T14 no), 23 (T13 no, T14 no), 24 (T13 fix, T14 fix), 25 (T13 fix, T14 fix), 27 (T13 no, T14 less), 28 (T13, T14 no), 30 (T13 fix, T14 fix), 36 (T13 no, T14 less), 37 (T13 less, T14 fix), 40 (T13, T14 less)',\n",
    "            'right': '0 (T05 no, T06 no), 1 (T05 less, T06 no), 2 (T05 no, T06 less), 3 (T05 no, T06 no), 7 (T05 no, T06 no), 9 (T05 no, T06 no), 11 (T05 no, T06 no), 13 (T05 no, T06 no), 14 (T05 no, T06 no), 17 (T05 no, T06 no), 22 (T05 no, T06 fix), 23 (T05 no, T06 no), 24 (T05 less, T06 fix), 26 (T05 fix, T06 no), 31 (T05 no, T06 less),',}\n",
    "camera_sample_ratio = {'normal': 0.33, 'less': 0.15, 'fix': 10, 'no': 1}\n",
    "save_csv = '/data/jupiter/datasets/dust_datasets/halo_dust_smudge_JUPD-1105_2024-10-23/selected_for_label.csv'\n",
    "select_by_camera_sample_ratio(seq_dfs, selected, camera_sample_ratio, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2024-10-18T15:28:21.557000', '2024-10-18T15:28.46.865000']]\n"
     ]
    }
   ],
   "source": [
    "def parse_time_intervals(s):\n",
    "    interval_strs = s.split(', ')\n",
    "    intervals = []\n",
    "    for interval_str in interval_strs:\n",
    "        ts = interval_str.split(' - ')\n",
    "        intervals.append(ts)\n",
    "    return intervals\n",
    "\n",
    "print(parse_time_intervals('2024-10-18T15:28:21.557000 - 2024-10-18T15:28.46.865000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 516 516 26 moving_random_sample\n",
      "1 520 520 26 moving_random_sample\n",
      "2 520 520 26 moving_random_sample\n",
      "3 505 505 25 moving_random_sample\n",
      "4 509 509 25 moving_random_sample\n",
      "5 509 509 25 moving_random_sample\n",
      "6 505 505 25 moving_random_sample\n",
      "7 502 502 25 moving_random_sample\n",
      "8 502 502 25 moving_random_sample\n",
      "9 506 506 25 moving_random_sample\n",
      "10 507 507 25 moving_random_sample\n",
      "11 507 507 25 moving_random_sample\n",
      "12 250 44 2 static_w_human_easy\n",
      "13 251 251 1 static_wo_human\n",
      "14 251 251 2 static_w_human_short\n",
      "15 257 55 3 static_w_human_easy\n",
      "16 250 52 3 static_w_human_easy\n",
      "17 250 15 1 static_w_human_easy\n",
      "18 250 250 1 static_wo_human\n",
      "19 250 250 1 static_wo_human\n",
      "20 250 56 6 static_w_human_medium\n",
      "21 255 255 1 static_wo_human\n",
      "22 261 261 2 static_w_human_short\n",
      "23 261 261 2 static_w_human_short\n",
      "24 420 33 2 static_w_human_easy\n",
      "25 424 82 8 static_w_human_medium\n",
      "26 423 423 1 static_wo_human\n",
      "27 438 438 2 static_w_human_short\n",
      "28 436 436 1 static_wo_human\n",
      "29 436 30 15 static_w_human_hard\n",
      "30 424 424 1 static_wo_human\n",
      "31 432 432 1 static_wo_human\n",
      "32 432 25 1 static_w_human_easy\n",
      "33 437 67 3 static_w_human_easy\n",
      "34 427 83 4 static_w_human_easy\n",
      "35 427 41 2 static_w_human_easy\n",
      "36 268 268 2 static_w_human_short\n",
      "37 269 269 2 static_w_human_short\n",
      "38 268 268 2 static_w_human_short\n",
      "39 264 63 3 static_w_human_easy\n",
      "40 275 88 4 static_w_human_easy\n",
      "41 274 116 6 static_w_human_easy\n",
      "42 273 273 1 static_wo_human\n",
      "43 259 259 1 static_wo_human\n",
      "44 259 259 1 static_wo_human\n",
      "45 275 275 1 static_wo_human\n",
      "46 275 275 1 static_wo_human\n",
      "47 275 275 1 static_wo_human\n",
      "48 666 666 33 moving_random_sample\n",
      "49 678 678 34 moving_random_sample\n",
      "50 678 678 34 moving_random_sample\n",
      "51 693 693 35 moving_random_sample\n",
      "52 690 690 34 moving_random_sample\n",
      "53 690 690 34 moving_random_sample\n",
      "54 674 674 34 moving_random_sample\n",
      "55 666 666 33 moving_random_sample\n",
      "56 665 665 33 moving_random_sample\n",
      "57 682 682 34 moving_random_sample\n",
      "58 667 667 33 moving_random_sample\n",
      "59 668 668 33 moving_random_sample\n",
      "60 983 970 48 moving_random_sample_exclude_tps\n",
      "61 963 957 48 moving_random_sample_exclude_tps\n",
      "62 963 910 46 moving_random_sample_exclude_tps\n",
      "63 995 981 49 moving_random_sample_exclude_tps\n",
      "64 985 976 49 moving_random_sample_exclude_tps\n",
      "65 987 982 49 moving_random_sample_exclude_tps\n",
      "66 805 782 39 moving_random_sample_exclude_tps\n",
      "67 758 754 38 moving_random_sample_exclude_tps\n",
      "68 758 748 37 moving_random_sample_exclude_tps\n",
      "69 783 748 37 moving_random_sample_exclude_tps\n",
      "70 797 765 38 moving_random_sample_exclude_tps\n",
      "71 796 773 39 moving_random_sample_exclude_tps\n",
      "72 193 193 2 static_w_human_short\n",
      "73 196 196 2 static_w_human_short\n",
      "74 196 196 2 static_w_human_short\n",
      "75 205 205 2 static_w_human_short\n",
      "76 187 187 2 static_w_human_short\n",
      "77 187 187 2 static_w_human_short\n",
      "78 206 206 2 static_w_human_short\n",
      "79 194 30 2 static_w_human_easy\n",
      "80 193 49 24 static_w_human_hard\n",
      "81 185 185 1 static_wo_human\n",
      "82 194 194 1 static_wo_human\n",
      "83 194 194 1 static_wo_human\n",
      "84 149 47 5 static_w_human_medium\n",
      "85 151 36 18 static_w_human_hard\n",
      "86 151 151 2 static_w_human_short\n",
      "87 143 143 1 static_wo_human\n",
      "88 138 138 1 static_wo_human\n",
      "89 138 138 1 static_wo_human\n",
      "90 149 149 1 static_wo_human\n",
      "91 159 159 1 static_wo_human\n",
      "92 159 159 1 static_wo_human\n",
      "93 141 141 1 static_wo_human\n",
      "94 143 143 1 static_wo_human\n",
      "95 143 143 1 static_wo_human\n",
      "96 717 717 36 moving_random_sample\n",
      "97 688 688 34 moving_random_sample\n",
      "98 688 688 34 moving_random_sample\n",
      "99 720 720 36 moving_random_sample\n",
      "100 691 691 35 moving_random_sample\n",
      "101 690 690 34 moving_random_sample\n",
      "102 643 643 32 moving_random_sample\n",
      "103 644 644 32 moving_random_sample\n",
      "104 645 645 32 moving_random_sample\n",
      "105 634 634 32 moving_random_sample\n",
      "106 644 644 32 moving_random_sample\n",
      "107 644 644 32 moving_random_sample\n",
      "108 117 117 1 static_wo_human\n",
      "109 117 117 1 static_wo_human\n",
      "110 117 117 1 static_wo_human\n",
      "111 117 117 1 static_wo_human\n",
      "112 118 118 1 static_wo_human\n",
      "113 118 118 1 static_wo_human\n",
      "114 116 116 1 static_wo_human\n",
      "115 117 117 1 static_wo_human\n",
      "116 117 117 1 static_wo_human\n",
      "117 117 117 1 static_wo_human\n",
      "118 117 117 1 static_wo_human\n",
      "119 117 117 1 static_wo_human\n",
      "120 360 360 18 moving_random_sample\n",
      "121 369 369 18 moving_random_sample\n",
      "122 369 369 18 moving_random_sample\n",
      "123 373 373 19 moving_random_sample\n",
      "124 382 382 19 moving_random_sample\n",
      "125 382 382 19 moving_random_sample\n",
      "126 377 377 19 moving_random_sample\n",
      "127 375 375 19 moving_random_sample\n",
      "128 376 376 19 moving_random_sample\n",
      "129 383 383 19 moving_random_sample\n",
      "130 378 378 19 moving_random_sample\n",
      "131 378 378 19 moving_random_sample\n",
      "(2004, 1)\n"
     ]
    }
   ],
   "source": [
    "# for selection of images for labeling - halo_human_w_corn_stubble_0812_oct\n",
    "selected = {'moving_random_sample': list(range(0, 12)) + list(range(48, 60)) + list(range(96, 108)) + list(range(120, 132)),\n",
    "            'moving_random_sample_exclude_tps': list(range(60, 72)),\n",
    "            'static_w_human_easy': [12, 15, 16, 17, 24, 32, 33, 34, 35, 39, 40, 41, 79],\n",
    "            'static_w_human_medium': [20, 25, 84],\n",
    "            'static_w_human_hard': [29, 80, 85],\n",
    "            'static_w_human_short': [14, 22, 23, 27, 36, 37, 38, 72, 73, 74, 75, 76, 77, 78, 86],\n",
    "            'static_wo_human': [13, 18, 19, 21, 26, 28, 30, 31, 42, 43, 44, 45, 46, 47, 81, 82, 83] + list(range(87, 96)) + list(range(108, 120))}\n",
    "hard_selected = {29: ['2024-10-17T19:34:53.62700', '2024-10-17T19:35:22.265000'], \n",
    "                 80: ['2024-10-17T23:30:00.839000', '2024-10-17T23:30:30.143000'], \n",
    "                 85: ['2024-10-18T15:28:21.557000', '2024-10-18T15:28:46.865000']}\n",
    "sample_rates = {'moving_random_sample': 0.05, 'moving_random_sample_exclude_tps': 0.05, \n",
    "               'static_w_human_easy': 0.05, 'static_w_human_medium': 0.1, 'static_w_human_hard': 0.5, \n",
    "               'static_w_human_short': 2, 'static_wo_human': 1}\n",
    "selected_ids = []\n",
    "for i, seq_df in enumerate(seq_dfs):\n",
    "    # get collection category\n",
    "    collection = ''\n",
    "    for _collection, i_list in selected.items():\n",
    "        if i in i_list:\n",
    "            collection = _collection\n",
    "    # get sampling type\n",
    "    sample_rate = sample_rates[collection]\n",
    "    if 'moving' in collection:\n",
    "        # sample on all images except FPs (actually TPs)\n",
    "        if 'exclude_tps' in collection:\n",
    "            pred_seq_df = pred_df[pred_df['unique_id'].isin(seq_df['unique_id'])]\n",
    "            sub_df = pred_seq_df[pred_seq_df.state != 'false_positive']\n",
    "        # sample on all images\n",
    "        else:\n",
    "            sub_df = seq_df\n",
    "    else:\n",
    "        # sample on human images (FPs)\n",
    "        if collection == 'static_w_human_easy' or collection == 'static_w_human_medium':\n",
    "            pred_seq_df = pred_df[pred_df[id].isin(seq_df[id])]\n",
    "            sub_df = pred_seq_df[pred_seq_df.state == 'false_positive']\n",
    "        # sample on selected time window (with hard humans)\n",
    "        elif collection == 'static_w_human_hard':\n",
    "            assert i in hard_selected\n",
    "            t1, t2 = hard_selected[i]\n",
    "            sub_df = seq_df[(seq_df.collected_on >= t1) & (seq_df.collected_on <= t2)]\n",
    "        # sample on all images but with very low sample rate\n",
    "        else:\n",
    "            sub_df = seq_df\n",
    "    # do sampling\n",
    "    if sample_rate < 1:\n",
    "        sample_df = sub_df.sample(frac=sample_rate)\n",
    "    else:\n",
    "        sample_df = sub_df.sample(n=min(sample_rate, len(sub_df)))\n",
    "    selected_ids += sample_df.id.to_list()\n",
    "    print(i, len(seq_df), len(sub_df), len(sample_df), collection)\n",
    "selected_ids = list(set(selected_ids))\n",
    "selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "print(selected_df.shape)\n",
    "selected_df.to_csv('/data3/jupiter/datasets/model_positive/halo_human_w_corn_stubble_0812_oct/selected_for_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front 0 2024-10-22T22:03:58.427000 2024-10-22T22:04:12.080000 1739 65\n",
      "front 0 2024-10-22T22:05:23.009000 2024-10-22T22:05:34.664000 1739 63\n",
      "front 0 2024-10-22T22:06:29.942000 2024-10-22T22:06:45.926000 1739 75\n",
      "front 1 2024-10-22T22:10:23.708000 2024-10-22T22:10:36.695000 726 43\n",
      "front 1 2024-10-22T22:11:15.656000 2024-10-22T22:11:21.650000 726 38\n",
      "front 2 2024-10-22T22:19:16.841000 2024-10-22T22:19:24.167000 3037 23\n",
      "front 2 2024-10-22T22:21:23.048000 2024-10-22T22:21:31.706000 3037 24\n",
      "front 2 2024-10-22T22:24:19.538000 2024-10-22T22:24:35.522000 3037 48\n",
      "front 2 2024-10-22T22:30:03.527000 2024-10-22T22:30:12.851000 3037 51\n",
      "front 4 2024-10-23T19:02:59.497000 2024-10-23T19:03:09.154000 1597 53\n",
      "front 4 2024-10-23T19:08:41.155000 2024-10-23T19:09:17.119000 1597 112\n",
      "right 0 2024-10-22T21:59:24.035000 2024-10-22T21:59:27.365000 1749 7\n",
      "right 0 2024-10-22T22:04:10.415000 2024-10-22T22:04:16.076000 1749 36\n",
      "right 2 2024-10-22T22:20:55.409000 2024-10-22T22:20:58.739000 3031 21\n",
      "right 2 2024-10-22T22:21:08.396000 2024-10-22T22:21:18.053000 3031 41\n",
      "back 0 2024-10-22T22:03:05.480000 2024-10-22T22:03:20.132000 1863 56\n",
      "back 0 2024-10-22T22:03:54.764000 2024-10-22T22:04:10.082000 1863 83\n",
      "back 0 2024-10-22T22:04:15.743000 2024-10-22T22:04:23.069000 1863 46\n",
      "back 0 2024-10-22T22:04:27.731000 2024-10-22T22:04:40.385000 1863 59\n",
      "back 1 2024-10-22T22:11:57.614000 2024-10-22T22:12:02.276000 751 29\n",
      "back 2 2024-10-22T22:20:07.457000 2024-10-22T22:20:16.448000 2701 49\n",
      "back 2 2024-10-22T22:21:12.393000 2024-10-22T22:21:43.694000 2701 66\n",
      "back 2 2024-10-22T22:28:29.289000 2024-10-22T22:28:40.610000 2701 70\n",
      "back 4 2024-10-23T19:02:59.497000 2024-10-23T19:03:09.154000 1432 52\n",
      "back 4 2024-10-23T19:03:22.141000 2024-10-23T19:03:29.134000 1432 41\n",
      "back 4 2024-10-23T19:03:50.779000 2024-10-23T19:04:06.097000 1432 74\n",
      "back 4 2024-10-23T19:06:03.646000 2024-10-23T19:06:27.622000 1432 120\n",
      "left 0 2024-10-22T22:02:57.155000 2024-10-22T22:03:04.814000 1885 35\n",
      "left 0 2024-10-22T22:04:20.738000 2024-10-22T22:04:33.392000 1885 73\n",
      "left 2 2024-10-22T22:19:22.836000 2024-10-22T22:19:31.161000 2745 22\n",
      "left 2 2024-10-22T22:21:01.737000 2024-10-22T22:21:28.377000 2745 103\n",
      "left 2 2024-10-22T22:22:43.634000 2024-10-22T22:22:55.623000 2745 61\n",
      "left 2 2024-10-22T22:28:25.293000 2024-10-22T22:28:30.621000 2745 32\n",
      "left 4 2024-10-23T19:05:59.983000 2024-10-23T19:06:17.632000 1426 92\n",
      "left 4 2024-10-23T19:07:52.870000 2024-10-23T19:08:01.861000 1426 42\n",
      "left 4 2024-10-23T19:09:15.787000 2024-10-23T19:09:25.444000 1426 60\n",
      "(1965, 1)\n"
     ]
    }
   ],
   "source": [
    "# for selection of images for labeling - halo_manure_data_candidate\n",
    "selected = {'front': \n",
    "            {0: [['2024-10-22T22:03:58.427000', '2024-10-22T22:04:12.080000'], ['2024-10-22T22:05:23.009000', '2024-10-22T22:05:34.664000'], ['2024-10-22T22:06:29.942000', '2024-10-22T22:06:45.926000']], \n",
    "             1: [['2024-10-22T22:10:23.708000', '2024-10-22T22:10:36.695000'], ['2024-10-22T22:11:15.656000', '2024-10-22T22:11:21.650000']], \n",
    "             2: [['2024-10-22T22:19:16.841000', '2024-10-22T22:19:24.167000'], ['2024-10-22T22:21:23.048000', '2024-10-22T22:21:31.706000'], ['2024-10-22T22:24:19.538000', '2024-10-22T22:24:35.522000'], ['2024-10-22T22:30:03.527000', '2024-10-22T22:30:12.851000']], \n",
    "             4: [['begin', '2024-10-23T19:03:09.154000'], ['2024-10-23T19:08:41.155000', '2024-10-23T19:09:17.119000']]},\n",
    "            'right': {0: [['2024-10-22T21:59:24.035000', '2024-10-22T21:59:27.365000'], ['2024-10-22T22:04:10.415000', '2024-10-22T22:04:16.076000']], \n",
    "                      2: [['2024-10-22T22:20:55.409000', '2024-10-22T22:20:58.739000'], ['2024-10-22T22:21:08.396000', '2024-10-22T22:21:18.053000']]},\n",
    "            'back': {0: [['2024-10-22T22:03:05.480000', '2024-10-22T22:03:20.132000'], ['2024-10-22T22:03:54.764000', '2024-10-22T22:04:10.082000'], ['2024-10-22T22:04:15.743000', '2024-10-22T22:04:23.069000'], ['2024-10-22T22:04:27.731000', '2024-10-22T22:04:40.385000']], \n",
    "                     1: [['2024-10-22T22:11:57.614000', '2024-10-22T22:12:02.276000']], \n",
    "                     2: [['2024-10-22T22:20:07.457000', '2024-10-22T22:20:16.448000'], ['2024-10-22T22:21:12.393000', '2024-10-22T22:21:43.694000'], ['2024-10-22T22:28:29.289000', '2024-10-22T22:28:40.610000']], \n",
    "                     4: [['begin', '2024-10-23T19:03:09.154000'], ['2024-10-23T19:03:22.141000', '2024-10-23T19:03:29.134000'], ['2024-10-23T19:03:50.779000', '2024-10-23T19:04:06.097000'], ['2024-10-23T19:06:03.646000', '2024-10-23T19:06:27.622000']]},\n",
    "            'left': {0: [['2024-10-22T22:02:57.155000', '2024-10-22T22:03:04.814000'], ['2024-10-22T22:04:20.738000', '2024-10-22T22:04:33.392000']], \n",
    "                     2: [['2024-10-22T22:19:22.836000', '2024-10-22T22:19:31.161000'], ['2024-10-22T22:21:01.737000', '2024-10-22T22:21:28.377000'], ['2024-10-22T22:22:43.634000', '2024-10-22T22:22:55.623000'], ['2024-10-22T22:28:25.293000', '2024-10-22T22:28:30.621000']], \n",
    "                     4: [['2024-10-23T19:05:59.983000', '2024-10-23T19:06:17.632000'], ['2024-10-23T19:07:52.870000', '2024-10-23T19:08:01.861000'], ['2024-10-23T19:09:15.787000', '2024-10-23T19:09:25.444000']]}}\n",
    "all_left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "selected_ids = []\n",
    "for pod, cameras in all_left_cameras.items():\n",
    "    selected_times = selected[pod]\n",
    "    for seq_i, t1t2_list in selected_times.items():\n",
    "        for t1t2 in t1t2_list:\n",
    "            seq_df = seq_dfs[seq_i]\n",
    "            seq_df = seq_df[seq_df.camera_location.isin(cameras)]\n",
    "            if t1t2 == 'all':\n",
    "                t1, t2 = seq_df.iloc[0].collected_on, seq_df.iloc[-1].collected_on\n",
    "            else:\n",
    "                t1, t2 = t1t2\n",
    "                if t1 == 'begin':\n",
    "                    t1 = seq_df.iloc[0].collected_on\n",
    "                if t2 == 'end':\n",
    "                    t2 = seq_df.iloc[-1].collected_on\n",
    "            selected_df = seq_df[(seq_df.collected_on >= t1) & (seq_df.collected_on <= t2)]\n",
    "            selected_ids += selected_df.id.to_list()\n",
    "            print(pod, seq_i, t1, t2, len(seq_df), len(selected_df))\n",
    "selected_ids = list(set(selected_ids))\n",
    "selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "print(selected_df.shape)\n",
    "selected_df.to_csv('/data3/jupiter/datasets/model_positive/halo_manure_data_candidate/selected_for_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for selection of images for binary labeling - halo_failure_case_of_box_in_dust\n",
    "# selected = [3, 5, [9, 1/5], [10, 1/5], [11, 1/6], \n",
    "#     [12, [['2024-04-23T18:11:28', '2024-04-23T18:18:12'], ['2024-04-23T18:27:40', '2024-04-23T18:28:38'], ['2024-04-23T18:29:05', '2024-04-23T18:29:57'], \n",
    "#         ['2024-04-23T18:48:44', '2024-04-23T18:50:59'], ['2024-04-23T19:01:50', '2024-04-23T19:03:37']]], \n",
    "#     [13, [['2024-04-23T19:47:48', '2024-04-23T19:47:59']]], \n",
    "#     [14, [['2024-04-23T20:12:40', '2024-04-23T20:13:02'], ['2024-04-23T20:15:53', '2024-04-23T20:17:49'], ['2024-04-23T20:22:19', '2024-04-23T20:22:45'], \n",
    "#         ['2024-04-23T20:32:47', '2024-04-23T20:33:18'], ['2024-04-23T20:34:48', '2024-04-23T20:35:56'], ['2024-04-23T20:38:00', '2024-04-23T20:38:17'], \n",
    "#         ['2024-04-23T20:39:55', '2024-04-23T20:41:31'], ['2024-04-23T20:42:57', '2024-04-23T20:48:27']]], \n",
    "#     [16, 1/2]]\n",
    "# selected_ids = []\n",
    "# for s in selected:\n",
    "#     if isinstance(s, int):\n",
    "#         selected_ids += seq_dfs[s].id.to_list()\n",
    "#     else:\n",
    "#         si, sj = s\n",
    "#         if isinstance(sj, float):\n",
    "#             selected_ids += seq_dfs[si].iloc[:int(len(seq_dfs[si])*sj)].id.to_list()\n",
    "#         else:\n",
    "#             for t1, t2 in sj:\n",
    "#                 selected_ids += seq_dfs[si][(seq_dfs[si].collected_on >= t1) & (seq_dfs[si].collected_on <= t2)].id.to_list()\n",
    "#     # print(s, len(selected_ids))\n",
    "# selected_ids = list(set(selected_ids))\n",
    "# selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "# print(selected_df.shape)\n",
    "# selected_df.to_csv('/data/jupiter/datasets/halo_failure_case_of_box_in_dust/selected_for_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ids_for_label(seq_dfs, all_cameras, selected, save_csv):\n",
    "    selected_ids = []\n",
    "    for pod, cameras in all_cameras.items():\n",
    "        print(pod, cameras)\n",
    "        for i,seq_df in enumerate(seq_dfs):\n",
    "            if i in selected[pod]:\n",
    "                sub_df = seq_df[seq_df.camera_location.isin(cameras)]\n",
    "                selected_ids += sub_df.id.to_list()\n",
    "    selected_ids = list(set(selected_ids))\n",
    "    selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "    print(selected_df.shape)\n",
    "    if save_csv:\n",
    "        selected_df.to_csv(save_csv, index=False)\n",
    "        return None\n",
    "    return selected_df\n",
    "\n",
    "def recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence):\n",
    "    all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "\n",
    "    raw_ms_df = pd.read_csv(os.path.join(data_dir, 'master_annotations.csv'))\n",
    "    raw_ms_df['camera_pair'] = raw_ms_df['unique_id'].apply(lambda s: s[-7:])\n",
    "    raw_ms_df['rectified_label_save_path'] = ''\n",
    "    raw_ms_df['use_recovered_label_in_sequence'] = True\n",
    "    labeled_ms_df = pd.read_csv(os.path.join(data_dir+suffix, 'master_annotations.csv'))\n",
    "    labeled_ms_df.drop(columns=[\"label_counts\"], inplace=True)\n",
    "    labeled_ms_df['camera_pair'] = labeled_ms_df['unique_id'].apply(lambda s: s[-7:])\n",
    "    print(raw_ms_df.shape, labeled_ms_df.shape)\n",
    "\n",
    "    recovered_dfs = []\n",
    "    for pod, seq_ids in same_human_sequence.items():\n",
    "        for seq_id in seq_ids:\n",
    "            # get seq df in pod\n",
    "            seq_df = seq_dfs[seq_id]\n",
    "            seq_df = seq_df[seq_df.camera_location.isin(all_cameras[pod])]\n",
    "            # get corresponding raw seq df and labeled seq df\n",
    "            raw_seq_df = raw_ms_df[raw_ms_df.id.isin(seq_df.id)]\n",
    "            labeled_seq_df = labeled_ms_df[labeled_ms_df.id.isin(seq_df.id)]\n",
    "            labeled_seq_df = labeled_seq_df.sort_values('collected_on')\n",
    "            # get camera locations where there are human labels\n",
    "            labeled_camera_pairs = labeled_seq_df.camera_pair.unique()\n",
    "            for camera_pair in labeled_camera_pairs:\n",
    "                raw_seq_cp_df = raw_seq_df[raw_seq_df.camera_pair == camera_pair]\n",
    "                labeled_seq_cp_df = labeled_seq_df[labeled_seq_df.camera_pair == camera_pair]\n",
    "                # assign label path to raw df\n",
    "                for i, row in raw_seq_cp_df.iterrows():\n",
    "                    labeled_rows = labeled_seq_cp_df[labeled_seq_cp_df.unique_id == row.unique_id]\n",
    "                    if len(labeled_rows) > 0:\n",
    "                        raw_seq_cp_df.loc[i, 'rectified_label_save_path'] = labeled_rows.iloc[0].rectified_label_save_path\n",
    "                        raw_seq_cp_df.loc[i, 'use_recovered_label_in_sequence'] = False\n",
    "                    else:\n",
    "                        raw_seq_cp_df.loc[i, 'rectified_label_save_path'] = labeled_seq_cp_df.iloc[0].rectified_label_save_path\n",
    "                recovered_dfs.append(raw_seq_cp_df)\n",
    "            print(pod, seq_id, len(seq_df), len(raw_seq_df), len(labeled_seq_df), raw_seq_df.camera_pair.unique(), labeled_seq_df.camera_pair.unique())\n",
    "    recovered_df = pd.concat(recovered_dfs, ignore_index=True)\n",
    "    print(recovered_df.shape, labeled_ms_df.shape)\n",
    "\n",
    "    # remove duplicates and add in extra sequence images from labeled_ms_df\n",
    "    recovered_df = pd.concat([recovered_df.drop_duplicates(subset='unique_id'), labeled_ms_df[~labeled_ms_df.unique_id.isin(recovered_df.unique_id)]], ignore_index=True)\n",
    "    # change relative path to label path\n",
    "    recovered_df['rectified_label_save_path'] = recovered_df['rectified_label_save_path'].apply(lambda p: f'../{os.path.basename(data_dir)+suffix}/{p}')\n",
    "    recovered_df['label_map'] = labeled_ms_df.iloc[0].label_map\n",
    "    print(recovered_df.shape, labeled_ms_df.shape)\n",
    "    recovered_df.to_csv(os.path.join(data_dir, 'label_recovered_master_annotations.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front ['T01', 'T02']\n",
      "right ['T05', 'T06']\n",
      "back ['T09', 'T10']\n",
      "left ['T13', 'T14']\n",
      "(1048, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for partial human labeling - halo_human_in_dust_day_collection_may29\n",
    "# selected = {'front': {0: 'all', 1: ['begin', '2024-05-29T19:48:13'], 2: ['2024-05-29T20:28:50', 'end']},\n",
    "#             'right': {2: ['begin', '2024-05-29T20:28:53']},\n",
    "#             'back': {1: ['2024-05-29T20:02:08', 'end']},\n",
    "#             'left': {1: ['2024-05-29T19:48:10', '2024-05-29T20:02:08']}}\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "# left_cameras = ['front-center-left', 'front-left-left', 'front-right-left', 'side-left-left', 'side-right-left', 'rear-left', 'T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14', 'I01', 'I02']\n",
    "\n",
    "# selected_ids = []\n",
    "# for pod, cameras in all_cameras.items():\n",
    "#     cameras = set(cameras).intersection(left_cameras)\n",
    "#     selected_times = selected[pod]\n",
    "#     for seq_i, t1t2 in selected_times.items():\n",
    "#         seq_df = seq_dfs[seq_i]\n",
    "#         seq_df = seq_df[seq_df.camera_location.isin(cameras)]\n",
    "#         if t1t2 == 'all':\n",
    "#             t1, t2 = seq_df.iloc[0].collected_on, seq_df.iloc[-1].collected_on\n",
    "#         else:\n",
    "#             t1, t2 = t1t2\n",
    "#             if t1 == 'begin':\n",
    "#                 t1 = seq_df.iloc[0].collected_on\n",
    "#             if t2 == 'end':\n",
    "#                 t2 = seq_df.iloc[-1].collected_on\n",
    "#         print(pod, seq_i, t1, t2, len(seq_df))\n",
    "#         selected_ids += seq_df[(seq_df.collected_on >= t1) & (seq_df.collected_on <= t2)].id.to_list()\n",
    "# selected_ids = list(set(selected_ids))\n",
    "# selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "# print(selected_df.shape)\n",
    "# selected_df.to_csv('/data/jupiter/datasets/halo_human_in_dust_day_collection_may29/selected_for_label.csv', index=False)\n",
    "\n",
    "# # recover skipped human labels in heavy dust, by images in the same sequence\n",
    "# same_human_sequence = {'front': [0, 1, 3, 14], 'right': [11, 12, 13], 'back': [7, 8, 9, 10], 'left': [4, 5, 6]}\n",
    "# suffix = '_human_labeled_stereo'\n",
    "# recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence)\n",
    "\n",
    "# select images with dust on lens\n",
    "left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# selected = {'front': [1, 3, 5, 11, 14, 15], 'right': [15,], 'back': [], 'left': [6, 10]}  # all\n",
    "# selected = {'front': [1, 3, 14], 'right': [], 'back': [], 'left': [6]}  # with human\n",
    "selected = {'front': [5, 11], 'right': [15,], 'back': [], 'left': [10]}  # without human\n",
    "save_csv = '/data/jupiter/datasets/halo_human_in_dust_day_collection_may29/dust_on_lens_without_human.csv'\n",
    "select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_pass ['T09', 'T14', 'T13', 'T02']\n",
      "right_pass ['T10', 'T05', 'T06', 'T01']\n",
      "(13141, 1)\n",
      "(9893, 1)\n"
     ]
    }
   ],
   "source": [
    "# # load in labeled dataset\n",
    "# labeled_csv = '/data2/jupiter/datasets/halo_vehicles_driving_through_dust_images_nodust_reserved_labeled_maxfov_alleysson_depth0423/annotations.csv'\n",
    "# labeled_df = pd.read_csv(labeled_csv)\n",
    "# print(labeled_df.shape)\n",
    "# labeled_ids = set(labeled_df.id.to_list())\n",
    "# print(len(labeled_ids))\n",
    "\n",
    "# # for selection of images for missing partial vehicle labeling - halo_vehicles_in_dust_collection_march2024\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'left_pass': [2, 3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36], \n",
    "#             'right_pass': [3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 37]}\n",
    "# selected_df = select_ids_for_label(seq_dfs, left_cameras, selected, save_csv='')\n",
    "# print(selected_df.shape)\n",
    "# selected_df = selected_df[~selected_df.id.isin(labeled_ids)]\n",
    "# print(selected_df.shape)\n",
    "# selected_df.to_csv('/data/jupiter/datasets/halo_vehicles_in_dust_collection_march2024/selected_for_missing_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front ['T01', 'T02']\n",
      "right ['T05', 'T06']\n",
      "back ['T09', 'T10']\n",
      "left ['T13', 'T14']\n",
      "(674, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial human labeling - halo_human_in_dust_night_collection_june03\n",
    "# left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "# selected = {'front': [25, 26, 27, 30]}\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv='')\n",
    "\n",
    "# # for selection of images for missing partial human labeling - halo_human_in_dust_night_collection_june03_2\n",
    "# left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# selected = {'front': [0, 1, 2, 3, 15, 16, 17], 'right': [18,], 'back': [7, 8, 9, 10, 11], 'left': [4, 5, 6, 12, 13, 14]}\n",
    "# save_csv = '/data/jupiter/datasets/halo_human_in_dust_night_collection_june03_2/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)\n",
    "\n",
    "# # recover skipped human labels in heavy dust, by images in the same sequence\n",
    "# same_human_sequence = {'front': [15, 17], 'right': [18], 'back': [7, 8, 9, 10], 'left': [5, 6]}\n",
    "# suffix = '_human_labeled_stereo'\n",
    "# recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence)\n",
    "\n",
    "# select images with dust on lens\n",
    "left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# selected = {'front': [], 'right': [], 'back': [], 'left': [12, 13, 14]}  # with human\n",
    "selected = {'front': [16], 'right': [], 'back': [], 'left': []}  # without human\n",
    "save_csv = '/data/jupiter/datasets/halo_human_in_dust_night_collection_june03_2/dust_on_lens_without_human.csv'\n",
    "select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-9e5b735fb503>:5: DtypeWarning: Columns (25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  recovered_df, labeled_ms_df = recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence)\n",
      "/home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8740, 153) (3511, 277)\n",
      "back 0 752 562 184 ['T09_T11' 'T10_T12' 'T10_T11'] ['T09_T11']\n",
      "back 1 1216 911 114 ['T09_T11' 'T10_T12' 'T10_T11'] ['T09_T11']\n",
      "back 2 248 186 11 ['T09_T11' 'T10_T12' 'T10_T11'] ['T09_T11']\n",
      "back 3 1476 1102 196 ['T09_T11' 'T10_T12' 'T10_T11'] ['T09_T11']\n",
      "back 5 1688 1262 576 ['T09_T11' 'T10_T12' 'T10_T11'] ['T10_T12' 'T10_T11']\n",
      "back 6 2176 1631 967 ['T09_T11' 'T10_T12' 'T10_T11'] ['T10_T11' 'T10_T12']\n",
      "back 7 1380 1034 687 ['T09_T11' 'T10_T12' 'T10_T11'] ['T10_T12' 'T10_T11']\n",
      "(3538, 153) (3511, 277)\n",
      "(4314, 278) (3511, 277)\n"
     ]
    }
   ],
   "source": [
    "# for selection of images for missing partial human labeling - halo_human_in_dust_day_collection_back_june05\n",
    "# recover skipped human labels in heavy dust, by images in the same sequence\n",
    "same_human_sequence = {'back': [0, 1, 2, 3, 5, 6, 7]}\n",
    "suffix = '_human_labeled_stereo'\n",
    "recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front ['T01', 'T02']\n",
      "right ['T05', 'T06']\n",
      "back ['T09', 'T10']\n",
      "left ['T13', 'T14']\n",
      "(3354, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial human labeling - halo_human_in_dust_dusk_collection_front_june07\n",
    "# left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# selected = {'front': [5], 'right': [], 'back': [], 'left': []}\n",
    "# save_csv = '/data/jupiter/datasets/halo_human_in_dust_dusk_collection_front_june07/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_pass ['T09', 'T14', 'T13', 'T02']\n",
      "right_pass ['T10', 'T05', 'T06', 'T01']\n",
      "(4513, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial vehicle labeling - halo_vehicles_in_dust_collection_june06\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'left_pass': [11, 12, 15], \n",
    "#             'right_pass': [10, 13, 14]}\n",
    "# save_csv = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june06/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_pass ['T09', 'T14', 'T13', 'T02']\n",
      "right_pass ['T10', 'T05', 'T06', 'T01']\n",
      "(14354, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial vehicle labeling - halo_vehicles_in_dust_collection_june07\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'left_pass': [2, 6, 7, 10], \n",
    "#             'right_pass': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]}\n",
    "# save_csv = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june07/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_pass ['T09', 'T14', 'T13', 'T02']\n",
      "right_pass ['T10', 'T05', 'T06', 'T01']\n",
      "(26470, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial vehicle labeling - halo_vehicles_in_dust_collection_june04\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'left_pass': [1, 2, 3, 4, 5, 6, 7, 8, 9], \n",
    "#             'right_pass': [9]}\n",
    "# save_csv = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june04/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ids_for_label_v2(seq_dfs, selected, save_csv):\n",
    "    selected_ids = []\n",
    "    for i,seq_df in enumerate(seq_dfs):\n",
    "        for camera, slices in selected.items():\n",
    "            cam_df = seq_df[seq_df.camera_location == camera]\n",
    "            for slice in slices:\n",
    "                if isinstance(slice, list):\n",
    "                    if slice[0] != i:\n",
    "                        continue\n",
    "                    cam_df = cam_df.sort_values('collected_on')\n",
    "                    begin = end = ''\n",
    "                    if slice[1] == 'begin':\n",
    "                        begin = cam_df.iloc[0].collected_on\n",
    "                    elif slice[1] == 'middle':\n",
    "                        begin = cam_df.iloc[len(cam_df)//2].collected_on\n",
    "                    else:\n",
    "                        begin = slice[1]\n",
    "                    if slice[2] == 'middle':\n",
    "                        end = cam_df.iloc[len(cam_df)//2].collected_on\n",
    "                    elif slice[2] == 'end':\n",
    "                        end = cam_df.iloc[-1].collected_on\n",
    "                    else:\n",
    "                        end = slice[2]\n",
    "                    sub_df = cam_df[(cam_df.collected_on >= begin) & (cam_df.collected_on <= end)]\n",
    "                    selected_ids += sub_df.id.to_list()\n",
    "                    print(camera, i, len(sub_df))\n",
    "                else:\n",
    "                    if slice != i:\n",
    "                        continue\n",
    "                    selected_ids += cam_df.id.to_list()\n",
    "                    print(camera, i, len(cam_df))\n",
    "    selected_ids = list(set(selected_ids))\n",
    "    selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "    print(selected_df.shape)\n",
    "    if save_csv:\n",
    "        selected_df.to_csv(save_csv, index=False)\n",
    "        return None\n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T02 4 645\n",
      "T02 9 3\n",
      "(648, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for running PP and model inference - Jupiter_bedrock_40013_20240617_dust_sequences\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "# selected = {'front': [0, 1, 4, 8, 9], 'right': [], 'back': [], 'left': []}\n",
    "# save_csv = '/data/jupiter/datasets/dust_datasets/Jupiter_bedrock_40013_20240617_dust_sequences/selected_for_pp.csv'\n",
    "# select_ids_for_label(seq_dfs, all_cameras, selected, save_csv)\n",
    "# selected_ids_df = pd.read_csv(save_csv)\n",
    "# selected_ann_df = df[df.id.isin(selected_ids_df.id)]\n",
    "# print(selected_ann_df.shape)\n",
    "# selected_ann_df.to_csv('/data/jupiter/datasets/dust_datasets/Jupiter_bedrock_40013_20240617_dust_sequences/selected_for.csv', index=False)\n",
    "\n",
    "# select dust on lens only (no dust in air) sequences:\n",
    "selected_box = {'T02': [[1, '2024-06-17T21:24:51.901000', 'end'], 2, 3]}\n",
    "selected_human = {'T01': [[10, 'begin', '2024-06-17T21:53:49:495000']], \n",
    "            'T02': [[4, 'begin', '2024-06-17T21:32:18.787000'], [9, 'middle', 'end'], [10, 'begin', '2024-06-17T21:53:49:495000']]}\n",
    "selected_human_v2 = {'T02': [[4, '2024-06-17T21:28:44.335000', '2024-06-17T21:32:18.787000'], [9, '2024-06-17T21:45:47.644000', 'end']]}\n",
    "selected_box_csv = os.path.join(data_dir, 'dust_on_lens_with_box.csv')\n",
    "selected_human_csv = os.path.join(data_dir, 'dust_on_lens_with_human.csv')\n",
    "selected_human_v2_csv = os.path.join(data_dir, 'dust_on_lens_with_human_v3.csv')\n",
    "# select_ids_for_label_v2(seq_dfs, selected_box, selected_box_csv)\n",
    "# select_ids_for_label_v2(seq_dfs, selected_human, selected_human_csv)\n",
    "select_ids_for_label_v2(seq_dfs, selected_human_v2, selected_human_v2_csv)\n",
    "\n",
    "# # select dust on lens and dust in air with manny sequences\n",
    "# selected_human = {'T02': [[9, 'begin', 'middle']]}\n",
    "# selected_human_csv = os.path.join(data_dir, 'mixed_dust_with_human.csv')\n",
    "# select_ids_for_label_v2(seq_dfs, selected_human, selected_human_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1085, 1)\n",
      "(19813, 149) (8534, 150)\n"
     ]
    }
   ],
   "source": [
    "# for selection and triaging of dust on lens IQ test set - halo_dust_on_lens_blur_dataset_v3_20240807\n",
    "all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "dedup = {'front': {0:[1, 3], 1: [1, 3], 8: [1, 3, 4], 9: [1,2,3,4], 10: [1,2,3,4], 17:[1, 3], 18:[1, 3], 19:[1, 3], 20:[1, 3], 21:[1, 3], 22:[1, 3], 23:[1, 3], \n",
    "                   24:[1, 3], 25:[1, 3], 26:[1, 3], 32:[1, 3], 33:[1, 3], 36:[1,2,3,4], 37:[1,2,3,4], 38:[1,2,3,4], 39:[1,2,3,4], 40:[1,2,3,4], 41:[1,2], 43:[1,2]}, \n",
    "         'right': {2:[5,7], 3:[5,7], 4:[5,7], 11:[5,6,7,8], 12:[5,6,7,8], 28:[7], 29:[7], 36:[5,6,7,8], 37:[5,6,7,8], 38:[5,6,7,8], 39:[5,6,7,8], 40:[5,6,7,8]}, \n",
    "         'back': {13:[9,10,11,12], 14:[9,10,11,12], 36:[9,10,11,12], 37:[9,10,11,12], 38:[9,10,11,12], 39:[9,10,11,12], 40:[9,10,11,12]}, \n",
    "         'left': {5:[13,15], 8:[16], 9:[16], 10:[16], 11:[16], 12:[16], 13:[16], 14:[16], 15:[13,14,15,16], 16:[13,14,15,16], 27:[14,16], 36:[13,14,15,16], 37:[13,14,15,16], \n",
    "                  38:[13,14,15,16], 39:[13,14,15,16], 40:[13,14,15,16], 42:[13,14,15,16]}}\n",
    "remove = {'front': [4, 6, 14, 15, 45], 'right': [6, 13, 14, 15, 16, 34, 44], 'back': [8, 11, 15, 16, 26, 27, 30, 31, 32, 33, 34, 35], 'left': [6, 7, 24, 28, 31]}\n",
    "# load already triaged ids\n",
    "triage_df = pd.read_csv(os.path.join(data_dir, 'to_triage.csv'))\n",
    "print(triage_df.shape)\n",
    "# dedup images from each sequence, such that there is at most 30 images per minute per camera\n",
    "pods = ['front', 'left', 'right', 'back']\n",
    "limit = 30\n",
    "selected_dfs = []\n",
    "for i, seq_df in enumerate(seq_dfs):\n",
    "    for pod in pods:\n",
    "        # check for remove list\n",
    "        if i in remove[pod]:\n",
    "            continue\n",
    "        # dedup\n",
    "        if i in dedup[pod]:\n",
    "            cameras = [f'T{str(seq_i).zfill(2)}' for seq_i in dedup[pod][i]]\n",
    "            for cam in cameras:\n",
    "                cam_df = seq_df[seq_df.camera_location == cam]\n",
    "                cam_df = cam_df[~cam_df.id.isin(triage_df.id)]\n",
    "                if len(cam_df) == 0:\n",
    "                    continue\n",
    "                cam_df = cam_df.sort_values('collected_on')\n",
    "                time_span = (cam_df.iloc[-1].datetime - cam_df.iloc[0].datetime).total_seconds()\n",
    "                limit_ids = int(time_span / 60 * limit)\n",
    "                selected_dfs.append(cam_df.sample(min(len(cam_df), limit_ids)))\n",
    "                # print(i, pod, cam, time_span, len(cam_df), limit_ids)\n",
    "        # else:\n",
    "        #     pod_df = seq_df[seq_df.camera_location.isin(all_cameras[pod])]\n",
    "        #     selected_dfs.append(pod_df)\n",
    "        #     print(i, pod, cam, len(pod_df))\n",
    "selected_df = pd.concat(selected_dfs, ignore_index=True)\n",
    "print(df.shape, selected_df.shape)\n",
    "# save ids to csv\n",
    "selected_df[['id']].to_csv(os.path.join(data_dir, 'v4_dedup_triaged.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csvs(pred_root_dir, model, labeled_dataset):\n",
    "    pred_df = pd.read_csv(os.path.join(pred_root_dir, model, labeled_dataset, 'output.csv'))\n",
    "    if not 'state' in pred_df:\n",
    "        pred_df['state'] = pred_df['result_state']\n",
    "    if os.path.isfile(os.path.join(pred_root_dir, model, labeled_dataset, 'dust_ratio.csv')):\n",
    "        dust_df = pd.read_csv(os.path.join(pred_root_dir, model, labeled_dataset, 'dust_ratio.csv'))\n",
    "        print(labeled_dataset, pred_df.shape, dust_df.shape)\n",
    "        df = pred_df[['unique_id', 'state', 'camera_location', 'operation_time']].merge(dust_df, on='unique_id')\n",
    "    else:\n",
    "        df = pred_df[['unique_id', 'id', 'state', 'camera_location', 'operation_time']]\n",
    "    all_cameras = {'Front Pod': ['T01', 'T02', 'T03', 'T04'], 'Right Pod': ['T05', 'T06', 'T07', 'T08'], 'Rear Pod': ['T09', 'T10', 'T11', 'T12'], 'Left Pod': ['T13', 'T14', 'T15', 'T16']}\n",
    "    all_cameras = {c: pod for pod, cameras in all_cameras.items() for c in cameras}\n",
    "    df['pod'] = df.camera_location.apply(lambda c: all_cameras[c])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54273, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1370113/1295679184.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pod'] = df.camera_location.apply(lambda c: all_cameras[c])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>id</th>\n",
       "      <th>state</th>\n",
       "      <th>camera_location</th>\n",
       "      <th>operation_time</th>\n",
       "      <th>pod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67256da5a34269d616572b8b_T02_T03</td>\n",
       "      <td>67256da5a34269d616572b8b</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>T02</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Front Pod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67256ed799d4d973685d540f_T02_T03</td>\n",
       "      <td>67256ed799d4d973685d540f</td>\n",
       "      <td>false_positive</td>\n",
       "      <td>T02</td>\n",
       "      <td>daytime</td>\n",
       "      <td>Front Pod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          unique_id                        id           state  \\\n",
       "0  67256da5a34269d616572b8b_T02_T03  67256da5a34269d616572b8b   true_negative   \n",
       "1  67256ed799d4d973685d540f_T02_T03  67256ed799d4d973685d540f  false_positive   \n",
       "\n",
       "  camera_location operation_time        pod  \n",
       "0             T02        daytime  Front Pod  \n",
       "1             T02        daytime  Front Pod  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model predictions\n",
    "pred_root_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "# model = '9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_10_tr_br_dr_p2_v_p1_m_p1_u_dust_0624'\n",
    "# model = '9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_5_tr_br_dr_p2_v_p1_m_p05_u_2_dust_0626'\n",
    "model = 'kore_5_h'\n",
    "# unlabeled pred\n",
    "# pred_df = read_csvs(pred_root_dir, model, os.path.basename(data_dir))\n",
    "pred_df = read_csvs(pred_root_dir, model, 'model_positive/halo_human_w_corn_stubble_0812_oct')\n",
    "print(pred_df.shape)\n",
    "# # labeled pred\n",
    "# suffix = '_human_labeled_stereo'\n",
    "# labeled_pred_df = read_csvs(pred_root_dir, model, os.path.basename(data_dir)+suffix)\n",
    "# print(labeled_pred_df.shape)\n",
    "# # put labeled rows to raw, unlabeled df\n",
    "# pred_df.loc[pred_df.unique_id.isin(labeled_pred_df.unique_id), ['total_averaged_dust_conf', 'state']] = labeled_pred_df[['total_averaged_dust_conf', 'state']].values\n",
    "pred_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(505, 158) (505, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state\n",
       "false_positive      1\n",
       "true_negative     504\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_df = seq_dfs[6]\n",
    "pred_seq_df = pred_df[pred_df.id.isin(seq_df.id)]\n",
    "print(seq_df.shape, pred_seq_df.shape)\n",
    "pred_seq_df.groupby('state').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left8 ['T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14']\n",
      "0 [68, 68, 68, 68, 66, 66, 66, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:43<00:00,  1.51it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [203, 202, 203, 202, 202, 202, 201, 202]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 201/201 [02:14<00:00,  1.50it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [66, 66, 66, 66, 66, 66, 66, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:44<00:00,  1.50it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [66, 66, 66, 67, 66, 66, 66, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:43<00:00,  1.50it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [66, 66, 66, 66, 66, 66, 67, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:44<00:00,  1.49it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [33, 34, 34, 33, 33, 33, 33, 33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 33/33 [00:22<00:00,  1.48it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [66, 66, 66, 66, 66, 66, 66, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:44<00:00,  1.49it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [67, 65, 66, 66, 66, 66, 66, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 65/65 [00:43<00:00,  1.50it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [66, 66, 66, 66, 66, 66, 66, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:44<00:00,  1.49it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [66, 66, 66, 66, 66, 66, 66, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:44<00:00,  1.49it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [66, 66, 66, 66, 67, 66, 66, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 66/66 [00:44<00:00,  1.50it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 [121, 121, 121, 121, 121, 122, 121, 121]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 121/121 [01:21<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# read from multiple cameras and put in once frame\n",
    "# left_pass_pairs = ['T09_T11', 'T14_T16', 'T14_T15', 'T13_T15']\n",
    "# right_pass_pairs = ['T05_T07', 'T10_T12', 'T06_T08', 'T06_T07']\n",
    "# cameras = [f'T{str(i+1).zfill(2)}' for i in range(16)][12:]\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "# all_left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "plain_left_cameras = {'left8': ['T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14']}\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "for pod, cameras in plain_left_cameras.items():\n",
    "    # pod = 'all_left'\n",
    "    # cameras = left_cameras\n",
    "    print(pod, cameras)\n",
    "    H = 2  # number of camera rows\n",
    "    W = 4  # number of camera cols\n",
    "    for i,seq_df in enumerate(seq_dfs):\n",
    "        # # select sequence to create video\n",
    "        # if not i in selected[pod]:\n",
    "        #     continue\n",
    "        # # check model prediction and filter by dust/seg outputs\n",
    "        # pred_seq_df = pred_df[pred_df.id.isin(seq_df.id)]\n",
    "        # labeled_ids = pred_seq_df.id.to_list()\n",
    "\n",
    "        cam_dfs = [seq_df[seq_df.camera_location == c] for c in cameras]\n",
    "        print(i, [len(cdf) for cdf in cam_dfs])\n",
    "        min_len = min(len(cdf) for cdf in cam_dfs)\n",
    "        cam_dfs = [cdf.sort_values('collected_on').iloc[:min_len] for cdf in cam_dfs]\n",
    "        if min_len < 2:\n",
    "            continue\n",
    "        # print(i, [cdf.iloc[0].collected_on for cdf in cam_dfs])\n",
    "\n",
    "        frame = read_raw_image_by_row(data_dir, seq_df.iloc[0])\n",
    "        height, width, layers = frame.shape\n",
    "        # print(height, width, layers)\n",
    "\n",
    "        # .avi MJPG,  .mp4 MP4V\n",
    "        video_dir = os.path.join(data_dir, f'videos_{len(cameras)}cams')\n",
    "        os.makedirs(video_dir, exist_ok=True)\n",
    "        video_name = os.path.join(video_dir, f'{pod}_seq{str(i).zfill(2)}.mp4')\n",
    "        video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), 3, (width*W,height*H), isColor=True)\n",
    "\n",
    "        for ii in tqdm(range(min_len)):\n",
    "            try:\n",
    "                canvas = np.zeros((height*H, width*W, 3), dtype=np.uint8)\n",
    "                for ci in range(len(cam_dfs)):\n",
    "                    cam_df_row = cam_dfs[ci].iloc[ii]\n",
    "                    frame = read_raw_image_by_row(data_dir, cam_df_row)\n",
    "                    c = (255,0,0)\n",
    "                    s = f'{cam_df_row.camera_location} {cam_df_row.collected_on}'\n",
    "                    # if cam_df_row.id in labeled_ids:\n",
    "                    #     pred_row = pred_seq_df[pred_seq_df.id == cam_df_row.id].iloc[0]\n",
    "                    #     s += f' pred: {pred_row.state}, dust: {pred_row.total_averaged_dust_conf:.4f}'\n",
    "                    #     if pred_row.state == 'true_positive' or pred_row.state == 'false_positive':\n",
    "                    #         c = (0,0,255)\n",
    "                    frame = cv2.putText(frame, s, \n",
    "                            (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, c, 2, cv2.LINE_AA)\n",
    "                    fi, fj = ci // W, ci % W\n",
    "                    canvas[height*fi:height*(fi+1), width*fj:width*(fj+1)] = frame\n",
    "                video.write(canvas)\n",
    "            except:\n",
    "                print(f'{ii}th image read failed')\n",
    "\n",
    "        # cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 516/516 [00:26<00:00, 19.76it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 520/520 [00:19<00:00, 26.03it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 520/520 [00:29<00:00, 17.43it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 505/505 [00:29<00:00, 17.41it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 509/509 [00:20<00:00, 24.84it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 509/509 [00:28<00:00, 17.58it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 505/505 [00:29<00:00, 17.30it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 502/502 [00:19<00:00, 25.47it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 502/502 [00:28<00:00, 17.60it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 506/506 [00:29<00:00, 17.29it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 507/507 [00:20<00:00, 24.79it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 507/507 [00:29<00:00, 17.29it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 250/250 [00:14<00:00, 17.67it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 251/251 [00:09<00:00, 25.27it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 251/251 [00:14<00:00, 17.51it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 257/257 [00:14<00:00, 17.74it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 250/250 [00:09<00:00, 25.25it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 250/250 [00:14<00:00, 17.81it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 250/250 [00:14<00:00, 17.55it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 250/250 [00:09<00:00, 26.01it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 250/250 [00:13<00:00, 18.05it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 255/255 [00:14<00:00, 17.75it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 261/261 [00:10<00:00, 25.59it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 261/261 [00:14<00:00, 17.95it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 420/420 [00:23<00:00, 17.63it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 424/424 [00:16<00:00, 25.33it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 423/423 [00:24<00:00, 17.43it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 438/438 [00:24<00:00, 17.90it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 436/436 [00:17<00:00, 25.63it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 436/436 [00:24<00:00, 17.77it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 424/424 [00:23<00:00, 17.71it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 432/432 [00:16<00:00, 25.70it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 432/432 [00:23<00:00, 18.01it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 437/437 [00:24<00:00, 17.61it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 427/427 [00:16<00:00, 25.26it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 427/427 [00:24<00:00, 17.47it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 268/268 [00:15<00:00, 16.91it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 269/269 [00:10<00:00, 25.26it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 268/268 [00:15<00:00, 17.63it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 264/264 [00:15<00:00, 17.51it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 275/275 [00:10<00:00, 25.75it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 274/274 [00:15<00:00, 18.10it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 273/273 [00:15<00:00, 17.89it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 259/259 [00:09<00:00, 27.14it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 259/259 [00:14<00:00, 17.82it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 275/275 [00:15<00:00, 17.60it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 275/275 [00:10<00:00, 25.63it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 275/275 [00:14<00:00, 18.45it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 666/666 [00:39<00:00, 17.02it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 678/678 [00:26<00:00, 25.52it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 678/678 [00:39<00:00, 17.26it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 693/693 [00:40<00:00, 17.09it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 690/690 [00:28<00:00, 24.41it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 690/690 [00:40<00:00, 17.22it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 674/674 [00:39<00:00, 17.23it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 666/666 [00:25<00:00, 25.94it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 665/665 [00:37<00:00, 17.58it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 682/682 [00:39<00:00, 17.08it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 667/667 [00:27<00:00, 24.68it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 668/668 [00:39<00:00, 17.06it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 983/983 [00:52<00:00, 18.63it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 963/963 [00:36<00:00, 26.72it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 963/963 [00:51<00:00, 18.85it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 995/995 [00:52<00:00, 18.82it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 985/985 [00:36<00:00, 26.68it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 987/987 [00:52<00:00, 18.80it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 805/805 [00:43<00:00, 18.58it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 758/758 [00:28<00:00, 26.84it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 758/758 [00:40<00:00, 18.89it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 783/783 [00:42<00:00, 18.47it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 797/797 [00:29<00:00, 26.64it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 796/796 [00:43<00:00, 18.51it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 193/193 [00:09<00:00, 19.94it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 196/196 [00:07<00:00, 27.87it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 196/196 [00:09<00:00, 19.75it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 205/205 [00:10<00:00, 19.92it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 187/187 [00:06<00:00, 28.46it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 187/187 [00:09<00:00, 19.55it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 206/206 [00:10<00:00, 19.57it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 194/194 [00:06<00:00, 31.13it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 193/193 [00:09<00:00, 20.29it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 185/185 [00:09<00:00, 19.83it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 194/194 [00:07<00:00, 27.23it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 194/194 [00:09<00:00, 19.92it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 149/149 [00:07<00:00, 19.84it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 151/151 [00:05<00:00, 26.44it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 151/151 [00:08<00:00, 18.55it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 143/143 [00:07<00:00, 19.72it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 138/138 [00:05<00:00, 26.83it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 138/138 [00:06<00:00, 19.98it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 149/149 [00:07<00:00, 18.99it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 159/159 [00:06<00:00, 26.20it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 159/159 [00:08<00:00, 19.44it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 141/141 [00:07<00:00, 19.83it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 143/143 [00:05<00:00, 28.59it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 143/143 [00:07<00:00, 19.97it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 717/717 [00:41<00:00, 17.22it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 688/688 [00:27<00:00, 24.90it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 688/688 [00:40<00:00, 16.86it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 720/720 [00:43<00:00, 16.63it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 691/691 [00:27<00:00, 25.13it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 690/690 [00:42<00:00, 16.31it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 643/643 [00:38<00:00, 16.67it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 644/644 [00:24<00:00, 26.36it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 645/645 [00:37<00:00, 17.20it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 634/634 [00:37<00:00, 17.00it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 644/644 [00:25<00:00, 25.19it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 644/644 [00:37<00:00, 17.19it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:05<00:00, 20.26it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:04<00:00, 28.35it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:05<00:00, 19.98it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:05<00:00, 20.27it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 118/118 [00:04<00:00, 28.91it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 118/118 [00:06<00:00, 18.14it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 116/116 [00:06<00:00, 19.13it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:04<00:00, 25.06it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:05<00:00, 19.87it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:05<00:00, 20.17it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:04<00:00, 26.89it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 117/117 [00:05<00:00, 20.30it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 360/360 [00:15<00:00, 23.49it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 369/369 [00:11<00:00, 33.52it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 369/369 [00:16<00:00, 22.55it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 373/373 [00:16<00:00, 22.38it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 382/382 [00:11<00:00, 33.23it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 382/382 [00:16<00:00, 22.72it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 377/377 [00:16<00:00, 22.94it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 375/375 [00:11<00:00, 31.93it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 376/376 [00:16<00:00, 22.12it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 383/383 [00:16<00:00, 22.97it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 378/378 [00:10<00:00, 34.44it/s]\n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|| 378/378 [00:16<00:00, 23.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# read from rectified data\n",
    "id = 'unique_id'  # id or unique_id\n",
    "for i,seq_df in enumerate(seq_dfs):\n",
    "    # check model prediction and filter by dust/seg outputs\n",
    "    pred_seq_df = pred_df[pred_df[id].isin(seq_df[id])]\n",
    "    labeled_ids = pred_seq_df[id].to_list()\n",
    "\n",
    "    frame = read_rectified_image(data_dir, seq_df.iloc[0])\n",
    "    height, width, layers = frame.shape\n",
    "    # print(height, width, layers)\n",
    "\n",
    "    # .avi MJPG,  .mp4 MP4V\n",
    "    video_dir = os.path.join(data_dir, f'videos')\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "    video_name = os.path.join(video_dir, f'seq{str(i).zfill(3)}_{seq_df.iloc[0].camera_pair}.mp4')\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), 6, (width,height), isColor=True)\n",
    "\n",
    "    for ii in tqdm(range(len(seq_df))):\n",
    "        try:\n",
    "            cam_df_row = seq_df.iloc[ii]\n",
    "            frame = read_rectified_image(data_dir, cam_df_row)\n",
    "            c = (255,0,0)\n",
    "            s = f'{cam_df_row.collected_on}'\n",
    "            if cam_df_row[id] in labeled_ids:\n",
    "                pred_row = pred_seq_df[pred_seq_df[id] == cam_df_row[id]].iloc[0]\n",
    "                # s += f' pred: {pred_row.state}, dust: {pred_row.total_averaged_dust_conf:.4f}'\n",
    "                s += f' pred: {pred_row.state}'\n",
    "                if pred_row.state == 'true_positive' or pred_row.state == 'false_positive':\n",
    "                    c = (0,0,255) \n",
    "            frame = cv2.putText(frame, s, \n",
    "                    (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, c, 1, cv2.LINE_AA)\n",
    "            video.write(frame)\n",
    "        except:\n",
    "            print(f'{ii}th image read failed')\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['tall stalks with blowing residue'] (1, 6)\n",
      "1 ['tall stalks with blowing residue'] (0, 6)\n",
      "2 ['tall stalks with blowing residue'] (0, 6)\n",
      "3 ['tall stalks with blowing residue'] (0, 6)\n",
      "4 ['tall stalks with blowing residue'] (0, 6)\n",
      "5 ['tall stalks with blowing residue'] (0, 6)\n",
      "6 ['tall stalks with blowing residue'] (1, 6)\n",
      "7 ['tall stalks with blowing residue'] (0, 6)\n",
      "8 ['tall stalks with blowing residue'] (0, 6)\n",
      "9 ['tall stalks with blowing residue'] (0, 6)\n",
      "10 ['tall stalks with blowing residue'] (0, 6)\n",
      "11 ['tall stalks with blowing residue'] (0, 6)\n",
      "12 ['tall stalks with blowing residue'] (44, 6)\n",
      "13 ['tall stalks with blowing residue'] (15, 6)\n",
      "14 ['tall stalks with blowing residue'] (6, 6)\n",
      "15 ['tall stalks with blowing residue'] (55, 6)\n",
      "16 ['tall stalks with blowing residue'] (52, 6)\n",
      "17 ['tall stalks with blowing residue'] (15, 6)\n",
      "18 ['tall stalks with blowing residue'] (1, 6)\n",
      "19 ['tall stalks with blowing residue'] (0, 6)\n",
      "20 ['tall stalks with blowing residue'] (56, 6)\n",
      "21 ['tall stalks with blowing residue'] (0, 6)\n",
      "22 ['tall stalks with blowing residue'] (7, 6)\n",
      "23 ['tall stalks with blowing residue'] (11, 6)\n",
      "24 ['JF-183'] (33, 6)\n",
      "25 ['JF-183'] (82, 6)\n",
      "26 ['JF-183'] (0, 6)\n",
      "27 ['JF-183'] (22, 6)\n",
      "28 ['JF-183'] (10, 6)\n",
      "29 ['JF-183'] (27, 6)\n",
      "30 ['JF-183'] (15, 6)\n",
      "31 ['JF-183'] (14, 6)\n",
      "32 ['JF-183'] (25, 6)\n",
      "33 ['JF-183'] (67, 6)\n",
      "34 ['JF-183'] (83, 6)\n",
      "35 ['JF-183'] (41, 6)\n",
      "36 ['JF-183 human capture'] (16, 6)\n",
      "37 ['JF-183 human capture'] (15, 6)\n",
      "38 ['JF-183 human capture'] (7, 6)\n",
      "39 ['JF-183 human capture'] (63, 6)\n",
      "40 ['JF-183 human capture'] (88, 6)\n",
      "41 ['JF-183 human capture'] (116, 6)\n",
      "42 ['JF-183 human capture'] (0, 6)\n",
      "43 ['JF-183 human capture'] (0, 6)\n",
      "44 ['JF-183 human capture'] (0, 6)\n",
      "45 ['JF-183 human capture'] (3, 6)\n",
      "46 ['JF-183 human capture'] (0, 6)\n",
      "47 ['JF-183 human capture'] (0, 6)\n",
      "48 ['JF-183 human capture'] (6, 6)\n",
      "49 ['JF-183 human capture'] (4, 6)\n",
      "50 ['JF-183 human capture'] (2, 6)\n",
      "51 ['JF-183 human capture'] (8, 6)\n",
      "52 ['JF-183 human capture'] (9, 6)\n",
      "53 ['JF-183 human capture'] (7, 6)\n",
      "54 ['JF-183 human capture'] (8, 6)\n",
      "55 ['JF-183 human capture'] (14, 6)\n",
      "56 ['JF-183 human capture'] (13, 6)\n",
      "57 ['JF-183 human capture'] (0, 6)\n",
      "58 ['JF-183 human capture'] (0, 6)\n",
      "59 ['JF-183 human capture'] (0, 6)\n",
      "60 ['tall talks / high debris / high dust / hazy / sundown'] (13, 6)\n",
      "61 ['tall talks / high debris / high dust / hazy / sundown'] (6, 6)\n",
      "62 ['tall talks / high debris / high dust / hazy / sundown'] (53, 6)\n",
      "63 ['tall talks / high debris / high dust / hazy / sundown'] (14, 6)\n",
      "64 ['tall talks / high debris / high dust / hazy / sundown'] (9, 6)\n",
      "65 ['tall talks / high debris / high dust / hazy / sundown'] (5, 6)\n",
      "66 ['tall talks / high debris / high dust / hazy / sundown'] (23, 6)\n",
      "67 ['tall talks / high debris / high dust / hazy / sundown'] (4, 6)\n",
      "68 ['tall talks / high debris / high dust / hazy / sundown'] (10, 6)\n",
      "69 ['tall talks / high debris / high dust / hazy / sundown'] (35, 6)\n",
      "70 ['tall talks / high debris / high dust / hazy / sundown'] (32, 6)\n",
      "71 ['tall talks / high debris / high dust / hazy / sundown'] (23, 6)\n",
      "72 ['JF-183 human capture sundown / haze'] (3, 6)\n",
      "73 ['JF-183 human capture sundown / haze'] (1, 6)\n",
      "74 ['JF-183 human capture sundown / haze'] (1, 6)\n",
      "75 ['JF-183 human capture sundown / haze'] (10, 6)\n",
      "76 ['JF-183 human capture sundown / haze'] (6, 6)\n",
      "77 ['JF-183 human capture sundown / haze'] (2, 6)\n",
      "78 ['JF-183 human capture sundown / haze'] (11, 6)\n",
      "79 ['JF-183 human capture sundown / haze'] (30, 6)\n",
      "80 ['JF-183 human capture sundown / haze'] (126, 6)\n",
      "81 ['JF-183 human capture sundown / haze'] (0, 6)\n",
      "82 ['JF-183 human capture sundown / haze'] (0, 6)\n",
      "83 ['JF-183 human capture sundown / haze'] (0, 6)\n",
      "84 ['JF-183 Human Capture'] (47, 6)\n",
      "85 ['JF-183 Human Capture'] (78, 6)\n",
      "86 ['JF-183 Human Capture'] (18, 6)\n",
      "87 ['JF-183 Human Capture'] (0, 6)\n",
      "88 ['JF-183 Human Capture'] (0, 6)\n",
      "89 ['JF-183 Human Capture'] (0, 6)\n",
      "90 ['JF-183 Human Capture'] (0, 6)\n",
      "91 ['JF-183 Human Capture'] (0, 6)\n",
      "92 ['JF-183 Human Capture'] (0, 6)\n",
      "93 ['JF-183 Human Capture'] (0, 6)\n",
      "94 ['JF-183 Human Capture'] (0, 6)\n",
      "95 ['JF-183 Human Capture'] (0, 6)\n",
      "96 ['Continuous capture tall stalks'] (1, 6)\n",
      "97 ['Continuous capture tall stalks'] (0, 6)\n",
      "98 ['Continuous capture tall stalks'] (0, 6)\n",
      "99 ['Continuous capture tall stalks'] (0, 6)\n",
      "100 ['Continuous capture tall stalks'] (1, 6)\n",
      "101 ['Continuous capture tall stalks'] (1, 6)\n",
      "102 ['Continuous capture tall stalks'] (3, 6)\n",
      "103 ['Continuous capture tall stalks'] (1, 6)\n",
      "104 ['Continuous capture tall stalks'] (1, 6)\n",
      "105 ['Continuous capture tall stalks'] (1, 6)\n",
      "106 ['Continuous capture tall stalks'] (0, 6)\n",
      "107 ['Continuous capture tall stalks'] (0, 6)\n",
      "108 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "109 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "110 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (2, 6)\n",
      "111 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "112 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "113 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "114 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "115 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "116 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "117 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "118 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "119 ['weed spark said was human (8012 on 10/21 @3:53PM)'] (0, 6)\n",
      "120 ['soy stubble at night'] (0, 6)\n",
      "121 ['soy stubble at night'] (1, 6)\n",
      "122 ['soy stubble at night'] (1, 6)\n",
      "123 ['soy stubble at night'] (1, 6)\n",
      "124 ['soy stubble at night'] (0, 6)\n",
      "125 ['soy stubble at night'] (0, 6)\n",
      "126 ['soy stubble at night'] (5, 6)\n",
      "127 ['soy stubble at night'] (2, 6)\n",
      "128 ['soy stubble at night'] (6, 6)\n",
      "129 ['soy stubble at night'] (0, 6)\n",
      "130 ['soy stubble at night'] (2, 6)\n",
      "131 ['soy stubble at night'] (4, 6)\n"
     ]
    }
   ],
   "source": [
    "for i, seq_df in enumerate(seq_dfs):\n",
    "    pred_seq_df = pred_df[pred_df[id].isin(seq_df[id])]\n",
    "    print(i, seq_df.special_notes.unique(), pred_seq_df[pred_seq_df.state == 'false_positive'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create video from saved pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(ids, pred_dir, video_name, read_func=read_saved_frame, fps=2, txt_df=None):\n",
    "    frame = read_func(pred_dir, ids[0])\n",
    "    height, width, layers = frame.shape\n",
    "    print(height, width, layers)\n",
    "\n",
    "    # .avi MJPG,  .mp4 MP4V\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width,height), isColor=True)\n",
    "    \n",
    "    good = 0\n",
    "    for _id in tqdm(ids):\n",
    "        frame = read_func(pred_dir, _id)\n",
    "        if frame is not None:\n",
    "            if txt_df is not None:\n",
    "                txt_row = txt_df[txt_df.unique_id == _id].iloc[0]\n",
    "                c = (255,0,0)\n",
    "                s = f'{txt_row.collected_on} pred state: {txt_row.result_state}'\n",
    "                # s = f'{txt_row.collected_on} dust ratio: {txt_row.total_averaged_dust_conf:.4f}'\n",
    "                frame = cv2.putText(frame, s, \n",
    "                        (600,60), cv2.FONT_HERSHEY_SIMPLEX, 1, c, 2, cv2.LINE_AA)\n",
    "            video.write(frame)\n",
    "            good += 1\n",
    "    print('total', len(ids), 'used', good)\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/data/jupiter/datasets/'\n",
    "dataset = 'dust_datasets/halo_water_drops_on_lens_with_human_collection_0905'\n",
    "master_df = pd.read_csv(os.path.join(data_dir, dataset, 'master_annotations.csv'))\n",
    "master_df = master_df.sort_values('collected_on')\n",
    "\n",
    "pred_root_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "model = '11_1_rev1_train_human_test_dean_multires'\n",
    "pred_dir = os.path.join(pred_root_dir, model, dataset)\n",
    "pred_df = pd.read_csv(os.path.join(pred_dir, 'output.csv'))\n",
    "pred_df = master_df[['unique_id', 'collected_on']].merge(pred_df, on='unique_id')\n",
    "# dust_df = pd.read_csv(os.path.join(pred_dir, 'dust_ratio.csv'))\n",
    "# dust_df = master_df[['unique_id', 'collected_on']].merge(dust_df, on='unique_id')\n",
    "save_dir = pred_dir\n",
    "\n",
    "# # save as a single video\n",
    "# print(master_df.shape)\n",
    "# video_name = os.path.join(save_dir, 'pred.mp4')\n",
    "# ids = master_df.image_id.to_list()\n",
    "# create_video(ids, pred_dir, video_name, fps=3)\n",
    "\n",
    "# break into sequences\n",
    "seq_dfs = get_sequences(master_df, interval=60, per_camera=False, per_camera_pair=True)\n",
    "print(len(master_df), len(seq_dfs))\n",
    "video_dir = os.path.join(pred_dir, 'videos')\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "for si, seq_df in enumerate(seq_dfs):\n",
    "    if len(seq_df) < 10:\n",
    "        continue\n",
    "        \n",
    "    name = seq_df.iloc[0].collected_on\n",
    "    camera = seq_df.iloc[0].unique_id[-7:]\n",
    "    print(si, name, camera, len(seq_df))\n",
    "    \n",
    "    # video_name = os.path.join(video_dir, str(si).zfill(3)+'.mp4')\n",
    "    video_name = os.path.join(video_dir, f'{camera}_{si}.mp4')\n",
    "    ids = seq_df.unique_id.to_list()\n",
    "    create_video(ids, pred_dir, video_name, fps=3, txt_df=pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create video from PP artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pp_artifacts(data_dir, df_row):\n",
    "    data_path = os.path.join(data_dir, df_row.stereo_pipeline_npz_save_path)\n",
    "    img = np.load(data_path)['left']\n",
    "    img_norm = normalize_image(img, df_row.hdr_mode if 'hdr_mode' in df_row else True)\n",
    "    return cv2.cvtColor((img_norm * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# def add_text(frame, txt_row):\n",
    "#     frame = cv2.putText(frame, f'Collected on: {txt_row.collected_on}', \n",
    "#                         (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "#     return frame\n",
    "\n",
    "def add_text(frame, txt):\n",
    "    frame = cv2.putText(frame, txt, \n",
    "                        (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    return frame\n",
    "\n",
    "def add_texts(frame, txts: list):\n",
    "    txt_pw, txt_ph = 10, 25\n",
    "    for i, txt in enumerate(txts):\n",
    "        if 'false_positive' in txt:\n",
    "            frame = cv2.putText(frame, txt, \n",
    "                                (txt_pw, txt_ph+i*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            frame = cv2.putText(frame, txt, \n",
    "                                (txt_pw, txt_ph+i*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (37,46,58,60,74,86,101,103,106,116,118) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23023, 150) 432\n"
     ]
    }
   ],
   "source": [
    "# data_root_dir = '/data/jupiter/li.yu/data'\n",
    "data_root_dir = '/data/jupiter/datasets/'\n",
    "# dataset = 'mannequin_in_dust_v1'\n",
    "# dataset = 'Jupiter_human_on_path_3_fn_sequence'\n",
    "dataset = 'halo_missed_lo_rock_0509_stereo'\n",
    "data_dir = os.path.join(data_root_dir, dataset)\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, 'master_annotations.csv'))\n",
    "seq_dfs = get_sequences(df, interval=5, per_camera=True)\n",
    "print(df.shape, len(seq_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18:16:02', '18:17:02'] 606\n",
      "['18:17:01', '18:18:01'] 750\n",
      "['18:17:48', '18:18:48'] 498\n",
      "['18:18:45', '18:19:45'] 354\n",
      "['18:21:31', '18:22:31'] 732\n",
      "['18:22:26', '18:23:26'] 900\n",
      "['18:23:12', '18:24:12'] 426\n",
      "['18:24:15', '18:25:15'] 432\n",
      "['20:16:20', '20:17:20'] 930\n",
      "['20:18:38', '20:19:38'] 850\n",
      "['20:20:28', '20:21:28'] 1200\n",
      "(6568, 151)\n",
      "(6568, 151) 2\n"
     ]
    }
   ],
   "source": [
    "bags = [\n",
    "[\"05_09_2024_18_16_02\", \"05_09_2024_18_17_02\"],\n",
    "[\"05_09_2024_18_17_01\", \"05_09_2024_18_18_01\"],\n",
    "[\"05_09_2024_18_17_48\", \"05_09_2024_18_18_48\"],\n",
    "[\"05_09_2024_18_18_45\", \"05_09_2024_18_19_45\"],\n",
    "[\"05_09_2024_18_21_31\", \"05_09_2024_18_22_31\"],\n",
    "[\"05_09_2024_18_22_26\", \"05_09_2024_18_23_26\"],\n",
    "[\"05_09_2024_18_23_12\", \"05_09_2024_18_24_12\"],\n",
    "[\"05_09_2024_18_24_15\", \"05_09_2024_18_25_15\"],\n",
    "[\"05_09_2024_20_16_20\", \"05_09_2024_20_17_20\"],\n",
    "[\"05_09_2024_20_18_38\", \"05_09_2024_20_19_38\"],\n",
    "[\"05_09_2024_20_20_28\", \"05_09_2024_20_21_28\"],\n",
    "]\n",
    "bags = [[bag[0][11:].replace('_', ':'), bag[1][11:].replace('_', ':')] for bag in bags]\n",
    "df['collected_hms'] = df['collected_on'].apply(lambda t: t[11:])\n",
    "df_oi = []\n",
    "for bag in bags:\n",
    "    sub_df = df[(df.collected_hms >= bag[0]) & (df.collected_hms < bag[1])]\n",
    "    print(bag, len(sub_df))\n",
    "    df_oi.append(sub_df)\n",
    "df_oi = pd.concat(df_oi, ignore_index=True).drop_duplicates()\n",
    "print(df_oi.shape)\n",
    "\n",
    "seq_dfs = get_sequences(df_oi)\n",
    "print(df_oi.shape, len(seq_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>id</th>\n",
       "      <th>camera_location</th>\n",
       "      <th>operation_time</th>\n",
       "      <th>special_notes</th>\n",
       "      <th>jdb_s3_path</th>\n",
       "      <th>result_state</th>\n",
       "      <th>result_human_state</th>\n",
       "      <th>result_vehicle_state</th>\n",
       "      <th>min_pixels_threshold</th>\n",
       "      <th>features</th>\n",
       "      <th>n_gt_human_pixels</th>\n",
       "      <th>gt_human_depth</th>\n",
       "      <th>n_pred_human_pixels</th>\n",
       "      <th>pred_human_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663ec898321f043ed7ad8a62_T02_T03</td>\n",
       "      <td>663ec898321f043ed7ad8a62</td>\n",
       "      <td>T02</td>\n",
       "      <td>daytime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>108</td>\n",
       "      <td>{\"large_object_pixels\": 688, \"large_object_min...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          unique_id                        id camera_location  \\\n",
       "0  663ec898321f043ed7ad8a62_T02_T03  663ec898321f043ed7ad8a62             T02   \n",
       "\n",
       "  operation_time special_notes  jdb_s3_path   result_state result_human_state  \\\n",
       "0        daytime           NaN          NaN  true_negative      true_negative   \n",
       "\n",
       "  result_vehicle_state  min_pixels_threshold  \\\n",
       "0        true_negative                   108   \n",
       "\n",
       "                                            features  n_gt_human_pixels  \\\n",
       "0  {\"large_object_pixels\": 688, \"large_object_min...                  0   \n",
       "\n",
       "   gt_human_depth  n_pred_human_pixels  pred_human_depth  \n",
       "0            1000                    0              1000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model'\n",
    "models = [\n",
    "    'ds_v8_1_nextvit_small_openimages_with_rev1_train_human_test_using_random_val_mhc_20_epochs_finetune_rev1_lr',\n",
    "    'v81_80k_maxfov_wn_ft_kore_0430'\n",
    "]\n",
    "suffix_list = ['_mhc_depth0125', '']\n",
    "pred_dfs = [pd.read_csv(os.path.join(pred_dir, model, dataset+suffix, 'output.csv')) for model,suffix in zip(models, suffix_list)]\n",
    "pred_dfs[0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/248 [00:00<00:29,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248, 248, 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 248/248 [00:30<00:00,  8.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_pred_texts(pred_dfs, unique_id, text_prefix):\n",
    "    texts = []\n",
    "    for pred_df, prefix in zip(pred_dfs, text_prefix):\n",
    "        pred_row = pred_df[pred_df.unique_id == unique_id].iloc[0]\n",
    "        texts.append(f'{prefix}: {pred_row.result_state}')\n",
    "    return texts\n",
    "\n",
    "def create_video_from_pp_add_text(seq_df, camera_pairs, pred_dfs, H, W, data_dir, video_dir_name):\n",
    "    cam_dfs = [seq_df[seq_df.unique_id.str.endswith(c)] for c in camera_pairs]\n",
    "    cam_dfs = [cdf.sort_values('collected_on', ignore_index=True) for cdf in cam_dfs]\n",
    "    min_len = min(len(cdf) for cdf in cam_dfs)\n",
    "    cam_dfs = [cdf.iloc[:min_len] for cdf in cam_dfs]\n",
    "    print([len(cdf) for cdf in cam_dfs])\n",
    "\n",
    "    # .avi MJPG,  .mp4 MP4V\n",
    "    os.makedirs(os.path.join(data_dir, video_dir_name), exist_ok=True)\n",
    "    video_name = os.path.join(data_dir, f'{video_dir_name}/{seq_df.iloc[0].collected_on}.mp4')\n",
    "\n",
    "    # print(f'{H} rows, {W} cols out of {len(camera_pairs)} camera_pairs')\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), 3, (768*W,512*H), isColor=True)\n",
    "\n",
    "    for ii in tqdm(range(min_len)):\n",
    "        # try:\n",
    "        canvas = np.zeros((512*H, 768*W, 3), dtype=np.uint8)\n",
    "        for ci in range(len(cam_dfs)):\n",
    "            row = cam_dfs[ci].iloc[ii]\n",
    "            frame = read_from_pp_artifacts(data_dir, row)\n",
    "            texts = [f'{row.collected_on}'] + get_pred_texts(pred_dfs, row.unique_id, ['MHC pred', 'MAXFOV pred'])\n",
    "            # print(texts)\n",
    "            frame = add_texts(frame, texts)\n",
    "            fi, fj = ci // W, ci % W\n",
    "            canvas[512*fi:512*(fi+1), 768*fj:768*fj+frame.shape[1]] = frame\n",
    "        video.write(canvas)\n",
    "        # except:\n",
    "        #     print(f'{ii}th image read failed')\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "front_pairs = ['T02_T04', 'T02_T03', 'T01_T03']\n",
    "left_pass_pairs = ['T02_T04', 'T02_T03', 'T01_T03', 'T13_T15', 'T14_T15', 'T14_T16']\n",
    "right_pass_pairs = ['T02_T04', 'T02_T03', 'T01_T03', 'T06_T08', 'T05_T07', 'T06_T07']\n",
    "# left_pass_pairs = ['T09_T11', 'T14_T16', 'T14_T15', 'T13_T15']\n",
    "# right_pass_pairs = ['T05_T07', 'T10_T12', 'T06_T08', 'T06_T07']\n",
    "H = 1  # number of image rows\n",
    "W = 3  # number of image cols\n",
    "create_video_from_pp_add_text(seq_dfs[1], front_pairs, pred_dfs, H, W, data_dir, 'videos_front_pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T01_T03', 'T02_T03', 'T02_T04', 'T05_T07', 'T06_T07', 'T06_T08',\n",
       "       'T09_T11', 'T10_T12', 'T10_T11', 'T13_T15', 'T14_T16', 'T14_T15'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"camera_pair\"] = df[\"unique_id\"].apply(lambda t: t[-7:])\n",
    "df[\"camera_pair\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Read frame and add prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 11)\n"
     ]
    }
   ],
   "source": [
    "# compare BRT model pred and CenterTrack pred\n",
    "# pred_csv = '/data/jupiter/li.yu/exps/driveable_terrain_model/v188_58d_rak_local_fine_tversky11_sum_image_normT_prod5_airdyn_r3a8_s30/mannequin_in_dust_v1/output.csv'\n",
    "pred_csv = '/data/jupiter/li.yu/exps/driveable_terrain_model/v188_58d_rak_local_fine_tversky11_sum_image_normT_prod5_airdyn_r3a8_s30/Jupiter_human_on_path_3_fn_sequence/output.csv'\n",
    "pred_df = pd.read_csv(pred_csv)\n",
    "print(pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 2023-07-08T01:37:09.798000 153\n"
     ]
    }
   ],
   "source": [
    "video_with_pred_dir = os.path.join(data_root_dir, dataset, 'videos_with_pred')\n",
    "# pred_sequence_dir = '/home/li.yu/code/CenterTrack/results/2023-07-08T01:37:09.798000_front-center_15'\n",
    "pred_sequence_dir = '/home/li.yu/code/CenterTrack/results/brt50000/nopreimg_noprehm/2023-07-08T01:37:09.798000_front-center_15'\n",
    "os.makedirs(video_with_pred_dir, exist_ok=True)\n",
    "height, width = 512, 1024\n",
    "\n",
    "for si, seq_df in enumerate(seq_dfs):\n",
    "    if len(seq_df) < 10 or si != 15:\n",
    "        continue\n",
    "    name = seq_df.iloc[0].collected_on\n",
    "    camera = seq_df.iloc[0].camera_location[:-5]\n",
    "    print(si, name, len(seq_df))\n",
    "    \n",
    "    # merge pred from BRT model\n",
    "    seq_df = seq_df.drop(columns=['state']).merge(pred_df[['id', 'state', 'human_state']], on='id')\n",
    "\n",
    "    # create video\n",
    "    video_name = os.path.join(video_with_pred_dir, f'{name}_{camera}_{si}_nopreimg_noprehm.mp4')\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), 3, (width,height), isColor=True)\n",
    "    fi = 0\n",
    "    for _, df_row in seq_df.iterrows():\n",
    "        frame = cv2.imread(os.path.join(pred_sequence_dir, str(fi).zfill(3)+'_'+df_row.id+'.png'))\n",
    "        frame = cv2.putText(frame, f'BRT Seg Pred: {df_row.state}, Strict: {df_row.human_state}', \n",
    "                            (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "        video.write(frame)\n",
    "        fi += 1\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### read from video and prediction results to each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2022-11-10T23:19:10.901000 88\n"
     ]
    }
   ],
   "source": [
    "video_dir = '/home/li.yu/code/CenterTrack/results/'\n",
    "old_video_name = 'brt50000_2022-11-10T23:19:10.901000_side-right_2_preimg.mp4'\n",
    "new_video_name = 'brt50000_2022-11-10T23:19:10.901000_side-right_2_preimg_withbrtpred.mp4'\n",
    "height, width = 512, 1024\n",
    "\n",
    "for si, seq_df in enumerate(seq_dfs):\n",
    "    if len(seq_df) < 10 or si != 2:\n",
    "        continue\n",
    "    name = seq_df.iloc[0].collected_on\n",
    "    camera = seq_df.iloc[0].camera_location[:-5]\n",
    "    print(si, name, len(seq_df))\n",
    "    \n",
    "    # merge pred from BRT model\n",
    "    seq_df = seq_df.drop(columns=['state']).merge(pred_df[['id', 'state', 'human_state']], on='id')\n",
    "\n",
    "    # read video\n",
    "    cam = cv2.VideoCapture(os.path.join(video_dir, old_video_name))\n",
    "\n",
    "    # create video\n",
    "    video_name = os.path.join(video_dir, new_video_name)\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), 3, (width,height), isColor=True)\n",
    "    for _, df_row in seq_df.iterrows():\n",
    "        _, frame = cam.read()\n",
    "        frame = cv2.putText(frame, f'BRT Seg Pred: {df_row.state}, Strict: {df_row.human_state}', \n",
    "                            (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "        video.write(frame)\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:query] *",
   "language": "python",
   "name": "conda-env-query-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
