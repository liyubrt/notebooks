{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "from matplotlib.animation import FFMpegWriter\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "from utils import normalize_image, get_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from collections import namedtuple\n",
    "\n",
    "class ModelType(Enum):\n",
    "    CLASSIFICATION = 0\n",
    "    SEGMENTATION = 1\n",
    "\n",
    "classlabels_viz_colors = ['black', 'green', 'yellow', 'blue', 'red', 'magenta', 'cyan',\n",
    "                          'lightseagreen', 'brown', 'magenta', 'olive', 'wheat', 'white', 'black']\n",
    "classlabels_viz_bounds = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 100]\n",
    "\n",
    "classlabels_viz_cmap = mpl.colors.ListedColormap(classlabels_viz_colors)\n",
    "classlabels_viz_norm = mpl.colors.BoundaryNorm(classlabels_viz_bounds, classlabels_viz_cmap.N)\n",
    "\n",
    "confidence_heatmap_viz_colors = ['black', 'blue', 'red', 'orange', 'yellow', 'lightgreen', 'lightseagreen']\n",
    "confidence_heatmap_viz_bounds = [-1, 0,0.5,0.6,0.7,0.8,0.9,1]\n",
    "confidence_heatmap_viz_cmap = mpl.colors.ListedColormap(confidence_heatmap_viz_colors)\n",
    "confidence_heatmap_viz_norm = mpl.colors.BoundaryNorm(confidence_heatmap_viz_bounds, confidence_heatmap_viz_cmap.N)\n",
    "\n",
    "\n",
    "LabelColor = namedtuple('LabelColor', ['name', 'id', 'trainid', 'color', 'category'])\n",
    "\n",
    "LABEL_COLORS = [\n",
    "    LabelColor('class1', 1, 0, (128, 0, 128), 'driveableterrain'),\n",
    "    LabelColor('class2', 2, 1, (255, 0, 0), 'non-driveableterrain'),\n",
    "    LabelColor('class3', 3, 2, (0, 0, 255), 'sky'),\n",
    "    LabelColor('class4', 4, 3, (0, 255, 0), 'trees'),\n",
    "    LabelColor('class5', 5, 4, (255, 0, 255), 'implement'),\n",
    "    LabelColor('class6', 6, 5, (255, 255, 0), 'basket markers')\n",
    "]\n",
    "\n",
    "LABEL_COLORS_4CLASS = LABEL_COLORS[0:4]\n",
    "LABEL_COLORS_5CLASS = LABEL_COLORS[0:5]\n",
    "LABEL_COLORS_6CLASS = LABEL_COLORS[0:6]\n",
    "LABEL_COLORS_SKY_DET = [LABEL_COLORS[0], LABEL_COLORS[2]]\n",
    "\n",
    "LABEL_COLORS_IMPL = [\n",
    "    LabelColor('class1', 1, 1, (128, 0, 128), 'implement'),\n",
    "    LabelColor('class2', 2, 2, (255, 0, 0), 'sweep'),\n",
    "    LabelColor('class3', 3, 3, (0, 0, 255), 'harrow_tine'),\n",
    "    LabelColor('class4', 4, 4, (0, 255, 0), 'basket'),\n",
    "    LabelColor('class5', 5, 5, (0, 255, 0), 'basket_marker'),\n",
    "    LabelColor('class6', 0, 255, (0, 0, 0), 'ignore')\n",
    "]\n",
    "\n",
    "LABEL_COLORS_IMPL_REDUCED = [\n",
    "    LabelColor('class0', 1, 0, (0, 0, 0), 'background'),\n",
    "    LabelColor('class1', 2, 1, (0, 255, 0), 'implement'),\n",
    "    LabelColor('class2', 3, 2, (255, 0, 0), 'sweep'),\n",
    "    LabelColor('class3', 4, 3, (0, 255, 0), 'basket_marker'),\n",
    "    LabelColor('class6', 0, 255, (0, 0, 0), 'ignore')\n",
    "]\n",
    "\n",
    "PLUG_LABEL_MAP ={0: 'no-plug', 1: 'plug'}\n",
    "IMPL_SEGMENT_LABEL_MAP = {0: 'background', 1: 'implement', 2: 'sweep', 3:'basket_marker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mpl_viz_outputs(output_path,\n",
    "                           image,\n",
    "                           prediction_labels,\n",
    "                           confidences,\n",
    "                           depth_img, \n",
    "                           image_title='Image', \n",
    "                           pred_title='Prediction', \n",
    "                           conf_title='Confidence', \n",
    "                           depth_title='Depth',\n",
    "                           bbox_coords=[]):\n",
    "    \"\"\"\n",
    "    Utility function to plot results based on order of input provided.\n",
    "\n",
    "    Axes index can have different values based on input provided.\n",
    "\n",
    "    For example: If image, prediction and groundtruth_label is provided, A three axes plot will be generated with\n",
    "    image(ax1), ground_truth(ax2), prediction(ax3).\n",
    "\n",
    "    Order of plot if all the inputs are provided will be in same order as arguments listed above.\n",
    "    \"\"\"\n",
    "    axis_index = list(range(len(list(filter(lambda x: x is not None, [image,\n",
    "                                                                      prediction_labels, confidences,\n",
    "                                                                      depth_img])))))\n",
    "    axis_curr_index = 0\n",
    "    fig, axes = mpl.pyplot.subplots(1, len(axis_index), figsize=((60, 30)))\n",
    "    if bbox_coords:\n",
    "#         xmin, ymin, xmax, ymax = bbox_coords\n",
    "        xmin, xmax, ymin, ymax = bbox_coords\n",
    "        if (xmin < 0) or (ymin < 0):\n",
    "            raise ValueError(f'Either {xmin} or {ymin} are negative')\n",
    "        else:\n",
    "            rect = mpl.patches.Rectangle((ymin, xmin), (ymax - ymin), (xmax - xmin), linewidth=3, edgecolor='k',\n",
    "                                     facecolor='none')\n",
    "    else:\n",
    "        rect = None\n",
    "\n",
    "    if axis_curr_index < len(axes):\n",
    "        # Grab only RGB channels from image, otherwise depth with distort the image when it is displayed\n",
    "        axes[axis_curr_index].imshow(image)\n",
    "        axes[axis_curr_index].set_title(image_title, fontsize=30)\n",
    "        axes[axis_curr_index].axis('off')\n",
    "        axis_curr_index += 1\n",
    "\n",
    "    if axis_curr_index < len(axes):\n",
    "        axes[axis_curr_index].imshow(depth_img, cmap='turbo')\n",
    "        axes[axis_curr_index].set_title(depth_title, fontsize=30)\n",
    "        axes[axis_curr_index].axis('off')\n",
    "        axis_curr_index += 1\n",
    "\n",
    "    if axis_curr_index < len(axes):\n",
    "        axes[axis_curr_index].imshow(prediction_labels, classlabels_viz_cmap, classlabels_viz_norm, interpolation='nearest')\n",
    "        if rect is not None:\n",
    "            rect1 = mpl.patches.Rectangle((ymin, xmin), (ymax - ymin), (xmax - xmin), linewidth=3, edgecolor='k',facecolor='none')\n",
    "            axes[axis_curr_index].add_patch(rect1)\n",
    "        axes[axis_curr_index].set_title(pred_title, fontsize=30)\n",
    "        axes[axis_curr_index].axis('off')\n",
    "        axis_curr_index += 1\n",
    "\n",
    "    if axis_curr_index < len(axes):\n",
    "        c = np.max(confidences, axis=2)\n",
    "        axes[axis_curr_index].imshow(c, confidence_heatmap_viz_cmap, confidence_heatmap_viz_norm, interpolation='nearest')\n",
    "#         if rect is not None:\n",
    "#             rect2 = mpl.patches.Rectangle((ymin, xmin), (ymax - ymin), (xmax - xmin), linewidth=3, edgecolor='k',\n",
    "#                                           facecolor='none')\n",
    "#             axes[axis_curr_index].add_patch(rect2)\n",
    "        axes[axis_curr_index].set_title(conf_title, fontsize=30)\n",
    "        axes[axis_curr_index].axis('off')\n",
    "        axis_curr_index += 1\n",
    "\n",
    "    mpl.pyplot.savefig(output_path, pad_inches=0, bbox_inches='tight', dpi=150)\n",
    "    mpl.pyplot.close('all')\n",
    "\n",
    "def read_image(image_path):\n",
    "    image = (np.load(image_path) * 255).astype(np.uint8)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def read_saved_frame(pred_dir, image_id):\n",
    "    states_to_save = ['', 'false_positive', 'false_negative', 'large_object_false_negative', 'true_positive', 'true_negative']\n",
    "    frame = None\n",
    "    for state in states_to_save:\n",
    "        if os.path.isfile(os.path.join(pred_dir, state, image_id+'.png')):\n",
    "            frame = cv2.imread(os.path.join(pred_dir, state, image_id+'.png'))\n",
    "            break\n",
    "        if os.path.isfile(os.path.join(pred_dir, state, image_id+'.jpg')):\n",
    "            frame = cv2.imread(os.path.join(pred_dir, state, image_id+'.jpg'))\n",
    "            break\n",
    "    return frame\n",
    "\n",
    "def read_images(pred_dir, _id):\n",
    "    if not os.path.isfile(os.path.join(pred_dir, _id+'_image.npy')):\n",
    "        return None, None, None, None\n",
    "    image = np.load(os.path.join(pred_dir, _id+'_image.npy'))\n",
    "    \n",
    "    # 100m capped depth\n",
    "    depth = np.load(os.path.join(pred_dir, _id+'_depth.npy'))\n",
    "#     # raw depth\n",
    "#     raw_depth_dir = '/raum_raid/li.yu/data/Jupiter_rock_demo_2021/Jupiter_rock_demo_loamy06_Oct20_2021/model_processed_v4.1_sky_2e-3_lr_1e-3_color_aug_full_model_LR_consistency_regularization_0.2_epoch_23/images/'\n",
    "#     stereo_data = np.load(os.path.join(raw_depth_dir, _id, 'stereo_output.npz'))\n",
    "#     depth = stereo_data['point_cloud'][:,:,-1]\n",
    "#     depth = normalize_and_clip_depth(depth, 200)\n",
    "    \n",
    "    pred_label = np.load(os.path.join(pred_dir, _id+'_pred_label.npy'))\n",
    "    confidence = np.load(os.path.join(pred_dir, _id+'_confidence.npy'))\n",
    "    return image, depth, pred_label, confidence\n",
    "\n",
    "# def create_frame(pred_dir, pred_merged_dir, _id, recreate=False):\n",
    "#     canvas_path = os.path.join(pred_merged_dir, _id+'.png')\n",
    "#     if recreate:\n",
    "#         image, depth, pred_label, confidence = read_images(pred_dir, _id)\n",
    "#         if image is None:\n",
    "#             return None\n",
    "#         create_mpl_viz_outputs(canvas_path, image, pred_label, confidence, depth)\n",
    "#     frame = cv2.imread(canvas_path)\n",
    "#     return frame\n",
    "\n",
    "def get_bbox_coords(i=-1, bbox_range_list=[], bbox_coord_list=[]):\n",
    "    for bi in range(len(bbox_range_list)):\n",
    "        bbox_range = bbox_range_list[bi]\n",
    "        if bbox_range[0] <= i <= bbox_range[1]:\n",
    "            return bbox_coord_list[bi]\n",
    "    return []\n",
    "\n",
    "def process_frame(pred_dir, pred_merged_dir, _id, recreate=False, bbox_coords=[]):\n",
    "    image, depth, pred_label, confidence = None, None, None, None\n",
    "    l = 0.0\n",
    "    avg_pixel = 0.0\n",
    "    bbox_conf = None\n",
    "    if recreate:\n",
    "        image, depth, pred_label, confidence = read_images(pred_dir, _id)\n",
    "        if image is None:\n",
    "            return image, depth, pred_label, confidence, l, avg_pixel, bbox_conf\n",
    "        # calculate brightness\n",
    "        hlsImg = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        l = np.average(hlsImg[:,:,1])\n",
    "        image_title = 'Image (brightness: {:.4f})'.format(l)\n",
    "        # calculate average pixel value at bbox area\n",
    "        if bbox_coords:\n",
    "            ymin, ymax, xmin, xmax = bbox_coords\n",
    "            bbox_pred = pred_label[ymin:ymax+1, xmin:xmax+1]\n",
    "            bbox_conf = confidence[ymin:ymax+1, xmin:xmax+1]\n",
    "            avg_pixel = np.count_nonzero(bbox_pred == 1)\n",
    "    return image, depth, pred_label, confidence, l, avg_pixel, bbox_conf\n",
    "\n",
    "def create_frame(pred_dir, pred_merged_dir, _id, recreate=False, bbox_coords=[]):\n",
    "    canvas_path = os.path.join(pred_merged_dir, _id+'.png')\n",
    "    image, depth, pred_label, confidence = None, None, None, None\n",
    "    l = 0.0\n",
    "    avg_pixel = 0.0\n",
    "    bbox_conf = None\n",
    "    if recreate:\n",
    "        image, depth, pred_label, confidence = read_images(pred_dir, _id)\n",
    "        if image is None:\n",
    "            return None, None, None, None, None, None, None, None\n",
    "        # calculate brightness\n",
    "        hlsImg = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        l = np.average(hlsImg[:,:,1])\n",
    "        image_title = 'Image (brightness: {:.4f})'.format(l)\n",
    "        # calculate average pixel value at bbox area\n",
    "        if bbox_coords:\n",
    "            ymin, ymax, xmin, xmax = bbox_coords\n",
    "            bbox_pred = pred_label[ymin:ymax+1, xmin:xmax+1]\n",
    "            bbox_conf = confidence[ymin:ymax+1, xmin:xmax+1]\n",
    "            avg_pixel = np.count_nonzero(bbox_pred == 1)\n",
    "        create_mpl_viz_outputs(canvas_path, image, pred_label, confidence, depth, image_title=image_title, bbox_coords=bbox_coords)\n",
    "    frame = cv2.imread(canvas_path)\n",
    "    return frame, image, depth, pred_label, confidence, l, avg_pixel, bbox_conf\n",
    "\n",
    "def create_diff_frame(pred_merged_dir, _id, image1, depth1, pred_label1, confidence1, \n",
    "                      image2, depth2, pred_label2, confidence2, pred_title='prediction', conf_title='confidence'):\n",
    "    canvas_path = os.path.join(pred_merged_dir, _id+'_diff.png')\n",
    "    image = np.abs(image1 - image2)\n",
    "    depth = np.abs(depth1 - depth2)\n",
    "    pred_label = np.abs(pred_label1 - pred_label2)\n",
    "    confidence = np.abs(confidence1 - confidence2)\n",
    "    create_mpl_viz_outputs(canvas_path, image, pred_label, confidence, depth, conf_title=conf_title)\n",
    "    frame = cv2.imread(canvas_path)\n",
    "    return frame\n",
    "\n",
    "def read_raw_image_by_id(data_dir, _id):\n",
    "    image_path = os.path.join(data_dir, 'images', _id, 'artifact_debayeredrgb_0_'+_id+'.png')\n",
    "    image = cv2.imread(image_path)\n",
    "    return image\n",
    "\n",
    "def read_raw_image_by_row(data_dir, row):\n",
    "    image = cv2.imread(os.path.join(data_dir, row.artifact_debayeredrgb_0_save_path))\n",
    "    return image\n",
    "\n",
    "def create_video(ids, pred_dir, video_name, read_func=read_saved_frame, fps=2):\n",
    "    frame = read_func(pred_dir, ids[10])\n",
    "    height, width, layers = frame.shape\n",
    "    print(height, width, layers)\n",
    "\n",
    "    # .avi MJPG,  .mp4 MP4V\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width,height), isColor=True)\n",
    "    \n",
    "    good = 0\n",
    "    for _id in tqdm(ids):\n",
    "        frame = read_func(pred_dir, _id)\n",
    "        if frame is not None:\n",
    "            video.write(frame)\n",
    "            good += 1\n",
    "    print('total', len(ids), 'used', good)\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create video from raw left images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92493, 107) 11\n"
     ]
    }
   ],
   "source": [
    "# create video from raw left images\n",
    "# data_dir = '/data/jupiter/datasets/halo_failure_case_of_box_in_dust'\n",
    "# data_dir = '/data/jupiter/datasets/halo_missed_lo_rock_0509_stereo'\n",
    "# data_dir = '/data/jupiter/li.yu/data/halo_sample_terrains_15images'\n",
    "# data_dir = '/data/jupiter/li.yu/data/halo_sample_terrains_15images_all_camera_sequence'\n",
    "# data_dir = '/data/jupiter/datasets/halo_human_in_dust_day_collection_may29'\n",
    "# data_dir = '/data/jupiter/datasets/halo_human_in_dust_night_collection_june03'\n",
    "# data_dir = '/data/jupiter/datasets/halo_human_in_dust_night_collection_june03_2'\n",
    "# data_dir = '/data/jupiter/datasets/halo_human_in_dust_day_collection_back_june05'\n",
    "# data_dir = '/data/jupiter/datasets/halo_human_in_dust_dusk_collection_front_june07'\n",
    "# data_dir = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_march2024'\n",
    "# data_dir = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june06'\n",
    "# data_dir = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june07'\n",
    "# data_dir = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june04'\n",
    "# data_dir = '/data/jupiter/datasets/halo_dust_on_lens_blur_dataset_v3_20240807'\n",
    "# data_dir = '/data/jupiter/datasets/dust_datasets/halo_dust_on_lens_blur_dataset_v3_20240807'\n",
    "data_dir = '/data/jupiter/datasets/dust_datasets/Jupiter_bedrock_40013_20240617_dust_sequences'\n",
    "# data_dir = '/data/jupiter/datasets/dust_datasets/halo_human_in_dust_night_collection_july29'\n",
    "df = pd.read_csv(os.path.join(data_dir, 'annotations_full.csv'))\n",
    "# df = pd.read_csv(os.path.join(data_dir, 'master_annotations.csv'))\n",
    "\n",
    "seq_dfs = get_sequences(df, interval=10, per_camera_pair=False)  # break the data by intervals between sequences\n",
    "print(df.shape, len(seq_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2024-06-17T21:23:50.296000', '2024-06-17T21:24:49.903000')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].collected_on, df.iloc[-1].collected_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select images for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halo_human_in_dust_day_collection_may29 (48102, 108) day\n",
      "halo_human_in_dust_night_collection_june03_2 (30284, 109) 19 {'dawn_dusk': [0, 1, 2, 3, 4, 5, 6, 7, 8], 'night': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18]}\n",
      "halo_human_in_dust_day_collection_back_june05 (11675, 108) day\n",
      "halo_human_in_dust_dusk_collection_front_june07 (36338, 104) dawn_dusk\n",
      "(126399, 2)\n"
     ]
    }
   ],
   "source": [
    "# combine and create datasets for human in dust\n",
    "data_root_dir = '/data/jupiter/datasets'\n",
    "unlabeled_datasets = [\n",
    "    \"halo_human_in_dust_day_collection_may29\",\n",
    "    \"halo_human_in_dust_night_collection_june03\",  # for lying down humans\n",
    "    \"halo_human_in_dust_night_collection_june03_2\",\n",
    "    \"halo_human_in_dust_day_collection_back_june05\",\n",
    "    \"halo_human_in_dust_dusk_collection_front_june07\",\n",
    "]\n",
    "day_night_splits = ['day', 'dawn_dusk', {'dawn_dusk': list(range(0, 9)), 'night': list(range(9, 19))}, 'day', 'dawn_dusk']\n",
    "use_ds = [0, 2, 3, 4]\n",
    "# split data by day time\n",
    "image_ids_by_time = {'id':[], 'day_night_split': []}\n",
    "for di in use_ds:\n",
    "    dataset = unlabeled_datasets[di]\n",
    "    df = pd.read_csv(os.path.join(data_root_dir, dataset, 'annotations.csv'))\n",
    "    df = df.sort_values('collected_on')\n",
    "    day_night_split = day_night_splits[di]\n",
    "    if isinstance(day_night_split, str):\n",
    "        print(dataset, df.shape, day_night_split)\n",
    "        image_ids_by_time['id'] += df.id.to_list()\n",
    "        image_ids_by_time['day_night_split'] += [day_night_split] * len(df)\n",
    "    else:\n",
    "        seq_dfs = get_sequences(df, interval=60)  # break the data by intervals between sequences\n",
    "        print(dataset, df.shape, len(seq_dfs), day_night_split)\n",
    "        for dn_split, seq_ids in day_night_split.items():\n",
    "            for seq_id in seq_ids:\n",
    "                seq_df = seq_dfs[seq_id]\n",
    "                image_ids_by_time['id'] += seq_df.id.to_list()\n",
    "                image_ids_by_time['day_night_split'] += [dn_split] * len(seq_df)\n",
    "# save to csv\n",
    "day_night_split_df = pd.DataFrame(data=image_ids_by_time)\n",
    "print(day_night_split_df.shape)\n",
    "day_night_split_df.to_csv('/data/jupiter/li.yu/data/halo_hard_cases/halo_human_in_dust_daynightsplit_for_july01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176217, 2)\n"
     ]
    }
   ],
   "source": [
    "# image_ids_by_time = {'id':[], 'day_night_split': []}\n",
    "# split data in day/dusk/night\n",
    "day_night_splits = [{'day': list(range(0,25)), 'dawn_dusk': list(range(25, 31)), 'night': list(range(31, 38))}, \n",
    "                   {'dawn_dusk': list(range(0, 14)), 'night': list(range(14, 29))},\n",
    "                   {'dawn_dusk': [0, 1, 2, 7, 8, 9], 'night': [3, 4, 5, 6, 10, 11, 12]}]\n",
    "day_night_split = day_night_splits[2]\n",
    "for dn_split, seq_ids in day_night_split.items():\n",
    "    for seq_id in seq_ids:\n",
    "        seq_df = seq_dfs[seq_id]\n",
    "        image_ids_by_time['id'] += seq_df.id.to_list()\n",
    "        image_ids_by_time['day_night_split'] += [dn_split] * len(seq_df)\n",
    "# save to csv\n",
    "day_night_split_df = pd.DataFrame(data=image_ids_by_time)\n",
    "print(day_night_split_df.shape)\n",
    "day_night_split_df.to_csv('/data/jupiter/li.yu/data/halo_hard_cases/halo_vehicle_in_dust_daynightsplit_excludebadnight_for_july01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for selection of images for binary labeling - halo_failure_case_of_box_in_dust\n",
    "# selected = [3, 5, [9, 1/5], [10, 1/5], [11, 1/6], \n",
    "#     [12, [['2024-04-23T18:11:28', '2024-04-23T18:18:12'], ['2024-04-23T18:27:40', '2024-04-23T18:28:38'], ['2024-04-23T18:29:05', '2024-04-23T18:29:57'], \n",
    "#         ['2024-04-23T18:48:44', '2024-04-23T18:50:59'], ['2024-04-23T19:01:50', '2024-04-23T19:03:37']]], \n",
    "#     [13, [['2024-04-23T19:47:48', '2024-04-23T19:47:59']]], \n",
    "#     [14, [['2024-04-23T20:12:40', '2024-04-23T20:13:02'], ['2024-04-23T20:15:53', '2024-04-23T20:17:49'], ['2024-04-23T20:22:19', '2024-04-23T20:22:45'], \n",
    "#         ['2024-04-23T20:32:47', '2024-04-23T20:33:18'], ['2024-04-23T20:34:48', '2024-04-23T20:35:56'], ['2024-04-23T20:38:00', '2024-04-23T20:38:17'], \n",
    "#         ['2024-04-23T20:39:55', '2024-04-23T20:41:31'], ['2024-04-23T20:42:57', '2024-04-23T20:48:27']]], \n",
    "#     [16, 1/2]]\n",
    "# selected_ids = []\n",
    "# for s in selected:\n",
    "#     if isinstance(s, int):\n",
    "#         selected_ids += seq_dfs[s].id.to_list()\n",
    "#     else:\n",
    "#         si, sj = s\n",
    "#         if isinstance(sj, float):\n",
    "#             selected_ids += seq_dfs[si].iloc[:int(len(seq_dfs[si])*sj)].id.to_list()\n",
    "#         else:\n",
    "#             for t1, t2 in sj:\n",
    "#                 selected_ids += seq_dfs[si][(seq_dfs[si].collected_on >= t1) & (seq_dfs[si].collected_on <= t2)].id.to_list()\n",
    "#     # print(s, len(selected_ids))\n",
    "# selected_ids = list(set(selected_ids))\n",
    "# selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "# print(selected_df.shape)\n",
    "# selected_df.to_csv('/data/jupiter/datasets/halo_failure_case_of_box_in_dust/selected_for_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ids_for_label(seq_dfs, all_cameras, selected, save_csv):\n",
    "    selected_ids = []\n",
    "    for pod, cameras in all_cameras.items():\n",
    "        print(pod, cameras)\n",
    "        for i,seq_df in enumerate(seq_dfs):\n",
    "            if i in selected[pod]:\n",
    "                sub_df = seq_df[seq_df.camera_location.isin(cameras)]\n",
    "                selected_ids += sub_df.id.to_list()\n",
    "    selected_ids = list(set(selected_ids))\n",
    "    selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "    print(selected_df.shape)\n",
    "    if save_csv:\n",
    "        selected_df.to_csv(save_csv, index=False)\n",
    "        return None\n",
    "    return selected_df\n",
    "\n",
    "def recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence):\n",
    "    all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "\n",
    "    raw_ms_df = pd.read_csv(os.path.join(data_dir, 'master_annotations.csv'))\n",
    "    raw_ms_df['camera_pair'] = raw_ms_df['unique_id'].apply(lambda s: s[-7:])\n",
    "    raw_ms_df['rectified_label_save_path'] = ''\n",
    "    raw_ms_df['use_recovered_label_in_sequence'] = True\n",
    "    labeled_ms_df = pd.read_csv(os.path.join(data_dir+suffix, 'master_annotations.csv'))\n",
    "    labeled_ms_df.drop(columns=[\"label_counts\"], inplace=True)\n",
    "    labeled_ms_df['camera_pair'] = labeled_ms_df['unique_id'].apply(lambda s: s[-7:])\n",
    "    print(raw_ms_df.shape, labeled_ms_df.shape)\n",
    "\n",
    "    recovered_dfs = []\n",
    "    for pod, seq_ids in same_human_sequence.items():\n",
    "        for seq_id in seq_ids:\n",
    "            # get seq df in pod\n",
    "            seq_df = seq_dfs[seq_id]\n",
    "            seq_df = seq_df[seq_df.camera_location.isin(all_cameras[pod])]\n",
    "            # get corresponding raw seq df and labeled seq df\n",
    "            raw_seq_df = raw_ms_df[raw_ms_df.id.isin(seq_df.id)]\n",
    "            labeled_seq_df = labeled_ms_df[labeled_ms_df.id.isin(seq_df.id)]\n",
    "            labeled_seq_df = labeled_seq_df.sort_values('collected_on')\n",
    "            # get camera locations where there are human labels\n",
    "            labeled_camera_pairs = labeled_seq_df.camera_pair.unique()\n",
    "            for camera_pair in labeled_camera_pairs:\n",
    "                raw_seq_cp_df = raw_seq_df[raw_seq_df.camera_pair == camera_pair]\n",
    "                labeled_seq_cp_df = labeled_seq_df[labeled_seq_df.camera_pair == camera_pair]\n",
    "                # assign label path to raw df\n",
    "                for i, row in raw_seq_cp_df.iterrows():\n",
    "                    labeled_rows = labeled_seq_cp_df[labeled_seq_cp_df.unique_id == row.unique_id]\n",
    "                    if len(labeled_rows) > 0:\n",
    "                        raw_seq_cp_df.loc[i, 'rectified_label_save_path'] = labeled_rows.iloc[0].rectified_label_save_path\n",
    "                        raw_seq_cp_df.loc[i, 'use_recovered_label_in_sequence'] = False\n",
    "                    else:\n",
    "                        raw_seq_cp_df.loc[i, 'rectified_label_save_path'] = labeled_seq_cp_df.iloc[0].rectified_label_save_path\n",
    "                recovered_dfs.append(raw_seq_cp_df)\n",
    "            print(pod, seq_id, len(seq_df), len(raw_seq_df), len(labeled_seq_df), raw_seq_df.camera_pair.unique(), labeled_seq_df.camera_pair.unique())\n",
    "    recovered_df = pd.concat(recovered_dfs, ignore_index=True)\n",
    "    print(recovered_df.shape, labeled_ms_df.shape)\n",
    "\n",
    "    # remove duplicates and add in extra sequence images from labeled_ms_df\n",
    "    recovered_df = pd.concat([recovered_df.drop_duplicates(subset='unique_id'), labeled_ms_df[~labeled_ms_df.unique_id.isin(recovered_df.unique_id)]], ignore_index=True)\n",
    "    # change relative path to label path\n",
    "    recovered_df['rectified_label_save_path'] = recovered_df['rectified_label_save_path'].apply(lambda p: f'../{os.path.basename(data_dir)+suffix}/{p}')\n",
    "    recovered_df['label_map'] = labeled_ms_df.iloc[0].label_map\n",
    "    print(recovered_df.shape, labeled_ms_df.shape)\n",
    "    recovered_df.to_csv(os.path.join(data_dir, 'label_recovered_master_annotations.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front ['T01', 'T02']\n",
      "right ['T05', 'T06']\n",
      "back ['T09', 'T10']\n",
      "left ['T13', 'T14']\n",
      "(1048, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for partial human labeling - halo_human_in_dust_day_collection_may29\n",
    "# selected = {'front': {0: 'all', 1: ['begin', '2024-05-29T19:48:13'], 2: ['2024-05-29T20:28:50', 'end']},\n",
    "#             'right': {2: ['begin', '2024-05-29T20:28:53']},\n",
    "#             'back': {1: ['2024-05-29T20:02:08', 'end']},\n",
    "#             'left': {1: ['2024-05-29T19:48:10', '2024-05-29T20:02:08']}}\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "# left_cameras = ['front-center-left', 'front-left-left', 'front-right-left', 'side-left-left', 'side-right-left', 'rear-left', 'T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14', 'I01', 'I02']\n",
    "\n",
    "# selected_ids = []\n",
    "# for pod, cameras in all_cameras.items():\n",
    "#     cameras = set(cameras).intersection(left_cameras)\n",
    "#     selected_times = selected[pod]\n",
    "#     for seq_i, t1t2 in selected_times.items():\n",
    "#         seq_df = seq_dfs[seq_i]\n",
    "#         seq_df = seq_df[seq_df.camera_location.isin(cameras)]\n",
    "#         if t1t2 == 'all':\n",
    "#             t1, t2 = seq_df.iloc[0].collected_on, seq_df.iloc[-1].collected_on\n",
    "#         else:\n",
    "#             t1, t2 = t1t2\n",
    "#             if t1 == 'begin':\n",
    "#                 t1 = seq_df.iloc[0].collected_on\n",
    "#             if t2 == 'end':\n",
    "#                 t2 = seq_df.iloc[-1].collected_on\n",
    "#         print(pod, seq_i, t1, t2, len(seq_df))\n",
    "#         selected_ids += seq_df[(seq_df.collected_on >= t1) & (seq_df.collected_on <= t2)].id.to_list()\n",
    "# selected_ids = list(set(selected_ids))\n",
    "# selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "# print(selected_df.shape)\n",
    "# selected_df.to_csv('/data/jupiter/datasets/halo_human_in_dust_day_collection_may29/selected_for_label.csv', index=False)\n",
    "\n",
    "# # recover skipped human labels in heavy dust, by images in the same sequence\n",
    "# same_human_sequence = {'front': [0, 1, 3, 14], 'right': [11, 12, 13], 'back': [7, 8, 9, 10], 'left': [4, 5, 6]}\n",
    "# suffix = '_human_labeled_stereo'\n",
    "# recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence)\n",
    "\n",
    "# select images with dust on lens\n",
    "left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# selected = {'front': [1, 3, 5, 11, 14, 15], 'right': [15,], 'back': [], 'left': [6, 10]}  # all\n",
    "# selected = {'front': [1, 3, 14], 'right': [], 'back': [], 'left': [6]}  # with human\n",
    "selected = {'front': [5, 11], 'right': [15,], 'back': [], 'left': [10]}  # without human\n",
    "save_csv = '/data/jupiter/datasets/halo_human_in_dust_day_collection_may29/dust_on_lens_without_human.csv'\n",
    "select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_pass ['T09', 'T14', 'T13', 'T02']\n",
      "right_pass ['T10', 'T05', 'T06', 'T01']\n",
      "(13141, 1)\n",
      "(9893, 1)\n"
     ]
    }
   ],
   "source": [
    "# # load in labeled dataset\n",
    "# labeled_csv = '/data2/jupiter/datasets/halo_vehicles_driving_through_dust_images_nodust_reserved_labeled_maxfov_alleysson_depth0423/annotations.csv'\n",
    "# labeled_df = pd.read_csv(labeled_csv)\n",
    "# print(labeled_df.shape)\n",
    "# labeled_ids = set(labeled_df.id.to_list())\n",
    "# print(len(labeled_ids))\n",
    "\n",
    "# # for selection of images for missing partial vehicle labeling - halo_vehicles_in_dust_collection_march2024\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'left_pass': [2, 3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36], \n",
    "#             'right_pass': [3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 27, 37]}\n",
    "# selected_df = select_ids_for_label(seq_dfs, left_cameras, selected, save_csv='')\n",
    "# print(selected_df.shape)\n",
    "# selected_df = selected_df[~selected_df.id.isin(labeled_ids)]\n",
    "# print(selected_df.shape)\n",
    "# selected_df.to_csv('/data/jupiter/datasets/halo_vehicles_in_dust_collection_march2024/selected_for_missing_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front ['T01', 'T02']\n",
      "right ['T05', 'T06']\n",
      "back ['T09', 'T10']\n",
      "left ['T13', 'T14']\n",
      "(674, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial human labeling - halo_human_in_dust_night_collection_june03\n",
    "# left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "# selected = {'front': [25, 26, 27, 30]}\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv='')\n",
    "\n",
    "# # for selection of images for missing partial human labeling - halo_human_in_dust_night_collection_june03_2\n",
    "# left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# selected = {'front': [0, 1, 2, 3, 15, 16, 17], 'right': [18,], 'back': [7, 8, 9, 10, 11], 'left': [4, 5, 6, 12, 13, 14]}\n",
    "# save_csv = '/data/jupiter/datasets/halo_human_in_dust_night_collection_june03_2/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)\n",
    "\n",
    "# # recover skipped human labels in heavy dust, by images in the same sequence\n",
    "# same_human_sequence = {'front': [15, 17], 'right': [18], 'back': [7, 8, 9, 10], 'left': [5, 6]}\n",
    "# suffix = '_human_labeled_stereo'\n",
    "# recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence)\n",
    "\n",
    "# select images with dust on lens\n",
    "left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# selected = {'front': [], 'right': [], 'back': [], 'left': [12, 13, 14]}  # with human\n",
    "selected = {'front': [16], 'right': [], 'back': [], 'left': []}  # without human\n",
    "save_csv = '/data/jupiter/datasets/halo_human_in_dust_night_collection_june03_2/dust_on_lens_without_human.csv'\n",
    "select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-64-9e5b735fb503>:5: DtypeWarning: Columns (25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  recovered_df, labeled_ms_df = recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence)\n",
      "/home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8740, 153) (3511, 277)\n",
      "back 0 752 562 184 ['T09_T11' 'T10_T12' 'T10_T11'] ['T09_T11']\n",
      "back 1 1216 911 114 ['T09_T11' 'T10_T12' 'T10_T11'] ['T09_T11']\n",
      "back 2 248 186 11 ['T09_T11' 'T10_T12' 'T10_T11'] ['T09_T11']\n",
      "back 3 1476 1102 196 ['T09_T11' 'T10_T12' 'T10_T11'] ['T09_T11']\n",
      "back 5 1688 1262 576 ['T09_T11' 'T10_T12' 'T10_T11'] ['T10_T12' 'T10_T11']\n",
      "back 6 2176 1631 967 ['T09_T11' 'T10_T12' 'T10_T11'] ['T10_T11' 'T10_T12']\n",
      "back 7 1380 1034 687 ['T09_T11' 'T10_T12' 'T10_T11'] ['T10_T12' 'T10_T11']\n",
      "(3538, 153) (3511, 277)\n",
      "(4314, 278) (3511, 277)\n"
     ]
    }
   ],
   "source": [
    "# for selection of images for missing partial human labeling - halo_human_in_dust_day_collection_back_june05\n",
    "# recover skipped human labels in heavy dust, by images in the same sequence\n",
    "same_human_sequence = {'back': [0, 1, 2, 3, 5, 6, 7]}\n",
    "suffix = '_human_labeled_stereo'\n",
    "recover_skipped_human_label(data_dir, seq_dfs, suffix, same_human_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front ['T01', 'T02']\n",
      "right ['T05', 'T06']\n",
      "back ['T09', 'T10']\n",
      "left ['T13', 'T14']\n",
      "(3354, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial human labeling - halo_human_in_dust_dusk_collection_front_june07\n",
    "# left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# selected = {'front': [5], 'right': [], 'back': [], 'left': []}\n",
    "# save_csv = '/data/jupiter/datasets/halo_human_in_dust_dusk_collection_front_june07/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_pass ['T09', 'T14', 'T13', 'T02']\n",
      "right_pass ['T10', 'T05', 'T06', 'T01']\n",
      "(4513, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial vehicle labeling - halo_vehicles_in_dust_collection_june06\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'left_pass': [11, 12, 15], \n",
    "#             'right_pass': [10, 13, 14]}\n",
    "# save_csv = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june06/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_pass ['T09', 'T14', 'T13', 'T02']\n",
      "right_pass ['T10', 'T05', 'T06', 'T01']\n",
      "(14354, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial vehicle labeling - halo_vehicles_in_dust_collection_june07\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'left_pass': [2, 6, 7, 10], \n",
    "#             'right_pass': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]}\n",
    "# save_csv = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june07/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_pass ['T09', 'T14', 'T13', 'T02']\n",
      "right_pass ['T10', 'T05', 'T06', 'T01']\n",
      "(26470, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for missing partial vehicle labeling - halo_vehicles_in_dust_collection_june04\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'left_pass': [1, 2, 3, 4, 5, 6, 7, 8, 9], \n",
    "#             'right_pass': [9]}\n",
    "# save_csv = '/data/jupiter/datasets/halo_vehicles_in_dust_collection_june04/selected_for_label.csv'\n",
    "# select_ids_for_label(seq_dfs, left_cameras, selected, save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ids_for_label_v2(seq_dfs, selected, save_csv):\n",
    "    selected_ids = []\n",
    "    for i,seq_df in enumerate(seq_dfs):\n",
    "        for camera, slices in selected.items():\n",
    "            cam_df = seq_df[seq_df.camera_location == camera]\n",
    "            for slice in slices:\n",
    "                if isinstance(slice, list):\n",
    "                    if slice[0] != i:\n",
    "                        continue\n",
    "                    cam_df = cam_df.sort_values('collected_on')\n",
    "                    begin = end = ''\n",
    "                    if slice[1] == 'begin':\n",
    "                        begin = cam_df.iloc[0].collected_on\n",
    "                    elif slice[1] == 'middle':\n",
    "                        begin = cam_df.iloc[len(cam_df)//2].collected_on\n",
    "                    else:\n",
    "                        begin = slice[1]\n",
    "                    if slice[2] == 'middle':\n",
    "                        end = cam_df.iloc[len(cam_df)//2].collected_on\n",
    "                    elif slice[2] == 'end':\n",
    "                        end = cam_df.iloc[-1].collected_on\n",
    "                    else:\n",
    "                        end = slice[2]\n",
    "                    sub_df = cam_df[(cam_df.collected_on >= begin) & (cam_df.collected_on <= end)]\n",
    "                    selected_ids += sub_df.id.to_list()\n",
    "                    print(camera, i, len(sub_df))\n",
    "                else:\n",
    "                    if slice != i:\n",
    "                        continue\n",
    "                    selected_ids += cam_df.id.to_list()\n",
    "                    print(camera, i, len(cam_df))\n",
    "    selected_ids = list(set(selected_ids))\n",
    "    selected_df = pd.DataFrame(data={'id': selected_ids})\n",
    "    print(selected_df.shape)\n",
    "    if save_csv:\n",
    "        selected_df.to_csv(save_csv, index=False)\n",
    "        return None\n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T02 4 645\n",
      "T02 9 3\n",
      "(648, 1)\n"
     ]
    }
   ],
   "source": [
    "# # for selection of images for running PP and model inference - Jupiter_bedrock_40013_20240617_dust_sequences\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "# selected = {'front': [0, 1, 4, 8, 9], 'right': [], 'back': [], 'left': []}\n",
    "# save_csv = '/data/jupiter/datasets/dust_datasets/Jupiter_bedrock_40013_20240617_dust_sequences/selected_for_pp.csv'\n",
    "# select_ids_for_label(seq_dfs, all_cameras, selected, save_csv)\n",
    "# selected_ids_df = pd.read_csv(save_csv)\n",
    "# selected_ann_df = df[df.id.isin(selected_ids_df.id)]\n",
    "# print(selected_ann_df.shape)\n",
    "# selected_ann_df.to_csv('/data/jupiter/datasets/dust_datasets/Jupiter_bedrock_40013_20240617_dust_sequences/selected_for.csv', index=False)\n",
    "\n",
    "# select dust on lens only (no dust in air) sequences:\n",
    "selected_box = {'T02': [[1, '2024-06-17T21:24:51.901000', 'end'], 2, 3]}\n",
    "selected_human = {'T01': [[10, 'begin', '2024-06-17T21:53:49:495000']], \n",
    "            'T02': [[4, 'begin', '2024-06-17T21:32:18.787000'], [9, 'middle', 'end'], [10, 'begin', '2024-06-17T21:53:49:495000']]}\n",
    "selected_human_v2 = {'T02': [[4, '2024-06-17T21:28:44.335000', '2024-06-17T21:32:18.787000'], [9, '2024-06-17T21:45:47.644000', 'end']]}\n",
    "selected_box_csv = os.path.join(data_dir, 'dust_on_lens_with_box.csv')\n",
    "selected_human_csv = os.path.join(data_dir, 'dust_on_lens_with_human.csv')\n",
    "selected_human_v2_csv = os.path.join(data_dir, 'dust_on_lens_with_human_v3.csv')\n",
    "# select_ids_for_label_v2(seq_dfs, selected_box, selected_box_csv)\n",
    "# select_ids_for_label_v2(seq_dfs, selected_human, selected_human_csv)\n",
    "select_ids_for_label_v2(seq_dfs, selected_human_v2, selected_human_v2_csv)\n",
    "\n",
    "# # select dust on lens and dust in air with manny sequences\n",
    "# selected_human = {'T02': [[9, 'begin', 'middle']]}\n",
    "# selected_human_csv = os.path.join(data_dir, 'mixed_dust_with_human.csv')\n",
    "# select_ids_for_label_v2(seq_dfs, selected_human, selected_human_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1085, 1)\n",
      "(19813, 149) (8534, 150)\n"
     ]
    }
   ],
   "source": [
    "# for selection and triaging of dust on lens IQ test set - halo_dust_on_lens_blur_dataset_v3_20240807\n",
    "all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "dedup = {'front': {0:[1, 3], 1: [1, 3], 8: [1, 3, 4], 9: [1,2,3,4], 10: [1,2,3,4], 17:[1, 3], 18:[1, 3], 19:[1, 3], 20:[1, 3], 21:[1, 3], 22:[1, 3], 23:[1, 3], \n",
    "                   24:[1, 3], 25:[1, 3], 26:[1, 3], 32:[1, 3], 33:[1, 3], 36:[1,2,3,4], 37:[1,2,3,4], 38:[1,2,3,4], 39:[1,2,3,4], 40:[1,2,3,4], 41:[1,2], 43:[1,2]}, \n",
    "         'right': {2:[5,7], 3:[5,7], 4:[5,7], 11:[5,6,7,8], 12:[5,6,7,8], 28:[7], 29:[7], 36:[5,6,7,8], 37:[5,6,7,8], 38:[5,6,7,8], 39:[5,6,7,8], 40:[5,6,7,8]}, \n",
    "         'back': {13:[9,10,11,12], 14:[9,10,11,12], 36:[9,10,11,12], 37:[9,10,11,12], 38:[9,10,11,12], 39:[9,10,11,12], 40:[9,10,11,12]}, \n",
    "         'left': {5:[13,15], 8:[16], 9:[16], 10:[16], 11:[16], 12:[16], 13:[16], 14:[16], 15:[13,14,15,16], 16:[13,14,15,16], 27:[14,16], 36:[13,14,15,16], 37:[13,14,15,16], \n",
    "                  38:[13,14,15,16], 39:[13,14,15,16], 40:[13,14,15,16], 42:[13,14,15,16]}}\n",
    "remove = {'front': [4, 6, 14, 15, 45], 'right': [6, 13, 14, 15, 16, 34, 44], 'back': [8, 11, 15, 16, 26, 27, 30, 31, 32, 33, 34, 35], 'left': [6, 7, 24, 28, 31]}\n",
    "# load already triaged ids\n",
    "triage_df = pd.read_csv(os.path.join(data_dir, 'to_triage.csv'))\n",
    "print(triage_df.shape)\n",
    "# dedup images from each sequence, such that there is at most 30 images per minute per camera\n",
    "pods = ['front', 'left', 'right', 'back']\n",
    "limit = 30\n",
    "selected_dfs = []\n",
    "for i, seq_df in enumerate(seq_dfs):\n",
    "    for pod in pods:\n",
    "        # check for remove list\n",
    "        if i in remove[pod]:\n",
    "            continue\n",
    "        # dedup\n",
    "        if i in dedup[pod]:\n",
    "            cameras = [f'T{str(seq_i).zfill(2)}' for seq_i in dedup[pod][i]]\n",
    "            for cam in cameras:\n",
    "                cam_df = seq_df[seq_df.camera_location == cam]\n",
    "                cam_df = cam_df[~cam_df.id.isin(triage_df.id)]\n",
    "                if len(cam_df) == 0:\n",
    "                    continue\n",
    "                cam_df = cam_df.sort_values('collected_on')\n",
    "                time_span = (cam_df.iloc[-1].datetime - cam_df.iloc[0].datetime).total_seconds()\n",
    "                limit_ids = int(time_span / 60 * limit)\n",
    "                selected_dfs.append(cam_df.sample(min(len(cam_df), limit_ids)))\n",
    "                # print(i, pod, cam, time_span, len(cam_df), limit_ids)\n",
    "        # else:\n",
    "        #     pod_df = seq_df[seq_df.camera_location.isin(all_cameras[pod])]\n",
    "        #     selected_dfs.append(pod_df)\n",
    "        #     print(i, pod, cam, len(pod_df))\n",
    "selected_df = pd.concat(selected_dfs, ignore_index=True)\n",
    "print(df.shape, selected_df.shape)\n",
    "# save ids to csv\n",
    "selected_df[['id']].to_csv(os.path.join(data_dir, 'v4_dedup_triaged.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### create video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csvs(pred_root_dir, model, labeled_dataset):\n",
    "    pred_df = pd.read_csv(os.path.join(pred_root_dir, model, labeled_dataset, 'output.csv'))\n",
    "    if not 'state' in pred_df:\n",
    "        pred_df['state'] = pred_df['result_state']\n",
    "    dust_df = pd.read_csv(os.path.join(pred_root_dir, model, labeled_dataset, 'dust_ratio.csv'))\n",
    "    print(labeled_dataset, pred_df.shape, dust_df.shape)\n",
    "    df = pred_df[['unique_id', 'state', 'camera_location', 'operation_time']].merge(dust_df, on='unique_id')\n",
    "    all_cameras = {'Front Pod': ['T01', 'T02', 'T03', 'T04'], 'Right Pod': ['T05', 'T06', 'T07', 'T08'], 'Rear Pod': ['T09', 'T10', 'T11', 'T12'], 'Left Pod': ['T13', 'T14', 'T15', 'T16']}\n",
    "    all_cameras = {c: pod for pod, cameras in all_cameras.items() for c in cameras}\n",
    "    df['pod'] = df.camera_location.apply(lambda c: all_cameras[c])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupiter_bedrock_40013_20240617_dust_sequences (6207, 24) (1552, 7)\n",
      "(1552, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>state</th>\n",
       "      <th>camera_location</th>\n",
       "      <th>operation_time</th>\n",
       "      <th>id</th>\n",
       "      <th>gt_dust_ratio</th>\n",
       "      <th>total_averaged_dust_conf</th>\n",
       "      <th>total_thresholded_dust_ratio</th>\n",
       "      <th>masked_avg_dust_conf</th>\n",
       "      <th>masked_dust_ratio</th>\n",
       "      <th>pod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667cb90b71111a991df8b4a3_T02_T03</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>T02</td>\n",
       "      <td>daytime</td>\n",
       "      <td>667cb90b71111a991df8b4a3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Front Pod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>667cb6533ba692c3dd8db0b4_T02_T03</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>T02</td>\n",
       "      <td>daytime</td>\n",
       "      <td>667cb6533ba692c3dd8db0b4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Front Pod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          unique_id          state camera_location  \\\n",
       "0  667cb90b71111a991df8b4a3_T02_T03  true_negative             T02   \n",
       "1  667cb6533ba692c3dd8db0b4_T02_T03  true_negative             T02   \n",
       "\n",
       "  operation_time                        id  gt_dust_ratio  \\\n",
       "0        daytime  667cb90b71111a991df8b4a3            0.0   \n",
       "1        daytime  667cb6533ba692c3dd8db0b4            0.0   \n",
       "\n",
       "   total_averaged_dust_conf  total_thresholded_dust_ratio  \\\n",
       "0                  0.000408                           0.0   \n",
       "1                  0.000568                           0.0   \n",
       "\n",
       "   masked_avg_dust_conf  masked_dust_ratio        pod  \n",
       "0              0.000002                0.0  Front Pod  \n",
       "1              0.000002                0.0  Front Pod  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model predictions\n",
    "pred_root_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "model = '9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_10_tr_br_dr_p2_v_p1_m_p1_u_dust_0624'\n",
    "# model = '9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_5_tr_br_dr_p2_v_p1_m_p05_u_2_dust_0626'\n",
    "# unlabeled pred\n",
    "pred_df = read_csvs(pred_root_dir, model, os.path.basename(data_dir))\n",
    "print(pred_df.shape)\n",
    "# # labeled pred\n",
    "# suffix = '_human_labeled_stereo'\n",
    "# labeled_pred_df = read_csvs(pred_root_dir, model, os.path.basename(data_dir)+suffix)\n",
    "# print(labeled_pred_df.shape)\n",
    "# # put labeled rows to raw, unlabeled df\n",
    "# pred_df.loc[pred_df.unique_id.isin(labeled_pred_df.unique_id), ['total_averaged_dust_conf', 'state']] = labeled_pred_df[['total_averaged_dust_conf', 'state']].values\n",
    "pred_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4308, 109) (3218, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state\n",
       "false_negative       1\n",
       "false_positive    1171\n",
       "true_negative     1672\n",
       "true_positive      374\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_df = seq_dfs[6]\n",
    "pred_seq_df = pred_df[pred_df.id.isin(seq_df.id)]\n",
    "print(seq_df.shape, pred_seq_df.shape)\n",
    "pred_seq_df.groupby('state').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "front ['T01', 'T02']\n",
      "0 [128, 128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 128/128 [00:17<00:00,  7.27it/s]\n",
      "  1%|          | 1/100 [00:00<00:12,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:13<00:00,  7.26it/s]\n",
      "  1%|          | 1/112 [00:00<00:14,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [112, 112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 112/112 [00:15<00:00,  7.12it/s]\n",
      "  1%|          | 1/105 [00:00<00:13,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [105, 105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 105/105 [00:14<00:00,  7.42it/s]\n",
      "  0%|          | 1/219 [00:00<00:27,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [219, 219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 219/219 [00:29<00:00,  7.44it/s]\n",
      "  1%|          | 1/119 [00:00<00:14,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [119, 119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 119/119 [00:16<00:00,  7.42it/s]\n",
      "  0%|          | 1/381 [00:00<00:47,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [381, 381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 381/381 [00:54<00:00,  7.05it/s]\n",
      "  0%|          | 0/603 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [0, 0]\n",
      "8 [0, 0]\n",
      "9 [0, 0]\n",
      "10 [0, 0]\n",
      "11 [0, 0]\n",
      "12 [0, 0]\n",
      "13 [0, 0]\n",
      "14 [0, 0]\n",
      "right ['T05', 'T06']\n",
      "0 [0, 0]\n",
      "1 [0, 0]\n",
      "2 [0, 0]\n",
      "3 [0, 0]\n",
      "4 [0, 0]\n",
      "5 [0, 0]\n",
      "6 [0, 0]\n",
      "7 [0, 0]\n",
      "8 [0, 0]\n",
      "9 [0, 0]\n",
      "10 [0, 0]\n",
      "11 [0, 0]\n",
      "12 [0, 0]\n",
      "13 [0, 0]\n",
      "14 [0, 0]\n",
      "back ['T09', 'T10']\n",
      "0 [0, 0]\n",
      "1 [0, 0]\n",
      "2 [0, 0]\n",
      "3 [0, 0]\n",
      "4 [0, 0]\n",
      "5 [0, 0]\n",
      "6 [0, 0]\n",
      "7 [0, 0]\n",
      "8 [0, 0]\n",
      "9 [0, 0]\n",
      "10 [0, 0]\n",
      "11 [603, 603]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 603/603 [01:27<00:00,  6.92it/s]\n",
      "  1%|          | 1/98 [00:00<00:14,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 [98, 98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 98/98 [00:15<00:00,  6.36it/s]\n",
      "  1%|          | 1/102 [00:00<00:14,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 [102, 102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 102/102 [00:16<00:00,  6.33it/s]\n",
      "  0%|          | 0/720 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 [720, 721]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 720/720 [01:40<00:00,  7.13it/s]\n",
      "  0%|          | 1/245 [00:00<00:31,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left ['T13', 'T14']\n",
      "0 [0, 0]\n",
      "1 [0, 0]\n",
      "2 [0, 0]\n",
      "3 [0, 0]\n",
      "4 [0, 0]\n",
      "5 [0, 0]\n",
      "6 [0, 0]\n",
      "7 [245, 245]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 245/245 [00:33<00:00,  7.28it/s]\n",
      "  0%|          | 1/220 [00:00<00:26,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [220, 220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 220/220 [00:29<00:00,  7.56it/s]\n",
      "  0%|          | 1/211 [00:00<00:25,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [212, 211]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 211/211 [00:27<00:00,  7.67it/s]\n",
      "  0%|          | 1/614 [00:00<01:16,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [614, 614]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 614/614 [01:20<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 [0, 0]\n",
      "12 [0, 0]\n",
      "13 [0, 0]\n",
      "14 [0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read from multiple cameras and put in once frame\n",
    "# left_pass_pairs = ['T09_T11', 'T14_T16', 'T14_T15', 'T13_T15']\n",
    "# right_pass_pairs = ['T05_T07', 'T10_T12', 'T06_T08', 'T06_T07']\n",
    "# cameras = [f'T{str(i+1).zfill(2)}' for i in range(16)][12:]\n",
    "# cameras = ['T16', 'T15', 'T14', 'T13', 'T11', 'T09']\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "all_left_cameras = {'front': ['T01', 'T02'], 'right': ['T05', 'T06'], 'back': ['T09', 'T10'], 'left': ['T13', 'T14']}\n",
    "# left_cameras = ['T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14']\n",
    "# back_left_cameras = ['T09', 'T10']\n",
    "# left_cameras = {'left_pass': ['T09', 'T14', 'T13', 'T02'], 'right_pass': ['T10', 'T05', 'T06', 'T01']}\n",
    "# selected = {'front': [1, 3, 5, 11, 14, 15], 'right': [15,], 'back': [], 'left': [6, 10]}\n",
    "for pod, cameras in all_left_cameras.items():\n",
    "    # pod = 'all_left'\n",
    "    # cameras = left_cameras\n",
    "    print(pod, cameras)\n",
    "    H = 1  # number of camera rows\n",
    "    W = 2  # number of camera cols\n",
    "    for i,seq_df in enumerate(seq_dfs):\n",
    "        # # select sequence to create video\n",
    "        # if not i in selected[pod]:\n",
    "        #     continue\n",
    "        # # check model prediction and filter by dust/seg outputs\n",
    "        # pred_seq_df = pred_df[pred_df.id.isin(seq_df.id)]\n",
    "        # labeled_ids = pred_seq_df.id.to_list()\n",
    "\n",
    "        cam_dfs = [seq_df[seq_df.camera_location == c] for c in cameras]\n",
    "        print(i, [len(cdf) for cdf in cam_dfs])\n",
    "        min_len = min(len(cdf) for cdf in cam_dfs)\n",
    "        cam_dfs = [cdf.sort_values('collected_on').iloc[:min_len] for cdf in cam_dfs]\n",
    "        if min_len < 2:\n",
    "            continue\n",
    "        # print(i, [cdf.iloc[0].collected_on for cdf in cam_dfs])\n",
    "\n",
    "        frame = read_raw_image_by_row(data_dir, seq_df.iloc[0])\n",
    "        height, width, layers = frame.shape\n",
    "        # print(height, width, layers)\n",
    "\n",
    "        # .avi MJPG,  .mp4 MP4V\n",
    "        video_dir = os.path.join(data_dir, f'videos_{len(cameras)}cams')\n",
    "        os.makedirs(video_dir, exist_ok=True)\n",
    "        video_name = os.path.join(video_dir, f'{pod}_seq{str(i).zfill(2)}.mp4')\n",
    "        video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), 3, (width*W,height*H), isColor=True)\n",
    "\n",
    "        for ii in tqdm(range(min_len)):\n",
    "            try:\n",
    "                canvas = np.zeros((height*H, width*W, 3), dtype=np.uint8)\n",
    "                for ci in range(len(cam_dfs)):\n",
    "                    cam_df_row = cam_dfs[ci].iloc[ii]\n",
    "                    frame = read_raw_image_by_row(data_dir, cam_df_row)\n",
    "                    c = (255,0,0)\n",
    "                    s = f'{cam_df_row.camera_location} {cam_df_row.collected_on}'\n",
    "                    # if cam_df_row.id in labeled_ids:\n",
    "                    #     pred_row = pred_seq_df[pred_seq_df.id == cam_df_row.id].iloc[0]\n",
    "                    #     s += f' pred: {pred_row.state}, dust: {pred_row.total_averaged_dust_conf:.4f}'\n",
    "                    #     if pred_row.state == 'true_positive' or pred_row.state == 'false_positive':\n",
    "                    #         c = (0,0,255)\n",
    "                    frame = cv2.putText(frame, s, \n",
    "                            (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, c, 2, cv2.LINE_AA)\n",
    "                    fi, fj = ci // W, ci % W\n",
    "                    canvas[height*fi:height*(fi+1), width*fj:width*(fj+1)] = frame\n",
    "                video.write(canvas)\n",
    "            except:\n",
    "                print(f'{ii}th image read failed')\n",
    "\n",
    "        # cv2.destroyAllWindows()\n",
    "        video.release()\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2652, 149)\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/data/jupiter/datasets/'\n",
    "dataset = 'halo_dust_on_lens_blur_dataset_v3_20240807'\n",
    "sample_csv = os.path.join(root_dir, dataset, 'iq_fn_depth_smudge_halo_dust_on_lens_blur_dataset_v3_20240807.csv')\n",
    "sdf = pd.read_csv(sample_csv)\n",
    "sdf['id'] = sdf['unique_id'].apply(lambda s: s[:-8])\n",
    "df = df[df.id.isin(sdf.id)]\n",
    "print(f'{df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "back ['T09', 'T10', 'T11', 'T12']\n",
      "0 [0, 0, 0, 0]\n",
      "1 [0, 0, 0, 0]\n",
      "2 [0, 0, 0, 0]\n",
      "3 [0, 0, 0, 0]\n",
      "4 [0, 0, 0, 0]\n",
      "5 [0, 0, 0, 0]\n",
      "6 [0, 0, 0, 0]\n",
      "7 [0, 0, 0, 0]\n",
      "8 [1, 2, 0, 0]\n",
      "9 [0, 0, 0, 0]\n",
      "10 [0, 0, 0, 0]\n",
      "11 [6, 6, 0, 0]\n",
      "12 [0, 0, 0, 0]\n",
      "13 [0, 0, 0, 0]\n",
      "14 [0, 3, 0, 0]\n",
      "15 [2, 7, 0, 0]\n",
      "16 [0, 3, 0, 0]\n",
      "17 [0, 0, 0, 0]\n",
      "18 [0, 0, 0, 0]\n",
      "19 [0, 0, 0, 0]\n",
      "20 [0, 0, 0, 0]\n",
      "21 [0, 0, 0, 0]\n",
      "22 [0, 0, 0, 0]\n",
      "23 [0, 0, 0, 0]\n",
      "24 [0, 0, 0, 0]\n",
      "25 [0, 0, 0, 0]\n",
      "26 [0, 0, 0, 0]\n",
      "27 [0, 1, 0, 0]\n",
      "28 [0, 0, 0, 0]\n",
      "29 [0, 0, 0, 0]\n",
      "30 [0, 0, 0, 0]\n",
      "31 [0, 2, 0, 0]\n",
      "32 [0, 0, 0, 0]\n",
      "33 [0, 0, 0, 0]\n",
      "34 [0, 0, 0, 0]\n",
      "35 [0, 1, 0, 0]\n",
      "36 [78, 73, 0, 0]\n",
      "37 [94, 82, 0, 0]\n",
      "38 [0, 0, 0, 0]\n",
      "39 [6, 59, 0, 0]\n",
      "40 [36, 73, 0, 0]\n",
      "41 [0, 0, 0, 0]\n",
      "42 [0, 0, 0, 0]\n",
      "43 [0, 0, 0, 0]\n",
      "44 [0, 0, 0, 0]\n",
      "45 [0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(root_dir, dataset, 'fns')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# all_cameras = {'front': ['T01', 'T02', 'T03', 'T04'], 'right': ['T05', 'T06', 'T07', 'T08'], 'back': ['T09', 'T10', 'T11', 'T12'], 'left': ['T13', 'T14', 'T15', 'T16']}\n",
    "all_cameras = {'back': ['T09', 'T10', 'T11', 'T12']}\n",
    "for pod, cameras in all_cameras.items():\n",
    "    print(pod, cameras)\n",
    "    for i,seq_df in enumerate(seq_dfs):\n",
    "        seq_df_pod = seq_df[(seq_df.id.isin(sdf.id)) & (seq_df.camera_location.isin(cameras))]\n",
    "        cam_dfs = [seq_df_pod[seq_df_pod.camera_location == c] for c in cameras]\n",
    "        print(i, [len(cdf) for cdf in cam_dfs])\n",
    "        max_len = max(len(cdf) for cdf in cam_dfs)\n",
    "        if max_len == 0:\n",
    "            continue\n",
    "        \n",
    "        save_dir_pod_seq = os.path.join(save_dir, f'{pod}_{i}')\n",
    "        os.makedirs(save_dir_pod_seq, exist_ok=True)\n",
    "        for _, row in seq_df_pod.iterrows():\n",
    "            img_path = os.path.join(root_dir, dataset, row.artifact_debayeredrgb_0_save_path)\n",
    "            img = cv2.imread(img_path)\n",
    "            cv2.imwrite(os.path.join(save_dir_pod_seq, f'{row.id}.jpg'), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create video from saved pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(ids, pred_dir, video_name, read_func=read_saved_frame, fps=2, txt_df=None):\n",
    "    frame = read_func(pred_dir, ids[0])\n",
    "    height, width, layers = frame.shape\n",
    "    print(height, width, layers)\n",
    "\n",
    "    # .avi MJPG,  .mp4 MP4V\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), fps, (width,height), isColor=True)\n",
    "    \n",
    "    good = 0\n",
    "    for _id in tqdm(ids):\n",
    "        frame = read_func(pred_dir, _id)\n",
    "        if frame is not None:\n",
    "            if txt_df is not None:\n",
    "                txt_row = txt_df[txt_df.unique_id == _id].iloc[0]\n",
    "                c = (255,0,0)\n",
    "                s = f'{txt_row.collected_on} dust ratio: {txt_row.total_averaged_dust_conf:.4f}'\n",
    "                frame = cv2.putText(frame, s, \n",
    "                        (600,60), cv2.FONT_HERSHEY_SIMPLEX, 1, c, 2, cv2.LINE_AA)\n",
    "            video.write(frame)\n",
    "            good += 1\n",
    "    print('total', len(ids), 'used', good)\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    537.000000\n",
       "mean       0.000291\n",
       "std        0.000210\n",
       "min        0.000004\n",
       "25%        0.000129\n",
       "50%        0.000247\n",
       "75%        0.000431\n",
       "max        0.001360\n",
       "Name: total_averaged_dust_conf, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dust_df.total_averaged_dust_conf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>collected_on</th>\n",
       "      <th>id</th>\n",
       "      <th>gt_dust_ratio</th>\n",
       "      <th>total_averaged_dust_conf</th>\n",
       "      <th>total_thresholded_dust_ratio</th>\n",
       "      <th>masked_avg_dust_conf</th>\n",
       "      <th>masked_dust_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>667c621f79de73c09b0e71ab_T02_T04</td>\n",
       "      <td>2024-06-17T21:44:49.036000</td>\n",
       "      <td>667c621f79de73c09b0e71ab</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.366287e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>667c621b1280b4ae671bcdcc_T01_T03</td>\n",
       "      <td>2024-06-17T21:44:49.036000</td>\n",
       "      <td>667c621b1280b4ae671bcdcc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.814136e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>667c621f79de73c09b0e71ab_T02_T03</td>\n",
       "      <td>2024-06-17T21:44:49.036000</td>\n",
       "      <td>667c621f79de73c09b0e71ab</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.475281e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            unique_id                collected_on  \\\n",
       "261  667c621f79de73c09b0e71ab_T02_T04  2024-06-17T21:44:49.036000   \n",
       "262  667c621b1280b4ae671bcdcc_T01_T03  2024-06-17T21:44:49.036000   \n",
       "263  667c621f79de73c09b0e71ab_T02_T03  2024-06-17T21:44:49.036000   \n",
       "\n",
       "                           id  gt_dust_ratio  total_averaged_dust_conf  \\\n",
       "261  667c621f79de73c09b0e71ab            0.0                  0.000144   \n",
       "262  667c621b1280b4ae671bcdcc            0.0                  0.000279   \n",
       "263  667c621f79de73c09b0e71ab            0.0                  0.000864   \n",
       "\n",
       "     total_thresholded_dust_ratio  masked_avg_dust_conf  masked_dust_ratio  \n",
       "261                           0.0          2.366287e-06                0.0  \n",
       "262                           0.0          2.814136e-07                0.0  \n",
       "263                           0.0          1.475281e-07                0.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dust_df[dust_df.collected_on == '2024-06-17T21:44:49.036000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['T02', 'T01'], dtype=object), array(['T03', 'T04'], dtype=object))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.camera_location.unique(), master_df.camera_location_right.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.yu/code/notebooks/utils.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk_df['camera_pair'] = chunk_df['unique_id'].apply(lambda s: s[-7:])\n",
      "  2%|         | 3/195 [00:00<00:06, 28.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585 3\n",
      "0 2024-06-17T21:44:20.065000 T01_T03 195\n",
      "402 3136 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 195/195 [00:06<00:00, 30.47it/s]\n",
      "  1%|          | 2/195 [00:00<00:09, 19.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 195 used 195\n",
      "1 2024-06-17T21:44:20.065000 T02_T03 195\n",
      "580 3137 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 195/195 [00:09<00:00, 20.45it/s]\n",
      "  2%|         | 3/195 [00:00<00:06, 28.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 195 used 195\n",
      "2 2024-06-17T21:44:20.065000 T02_T04 195\n",
      "402 3136 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 195/195 [00:06<00:00, 30.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 195 used 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/data/jupiter/datasets/dust_datasets/'\n",
    "# dataset = 'Jupiter_bedrock_40013_20240617_dust_sequences'\n",
    "dataset = 'Jupiter_bedrock_40013_20240617_214449_lying_manny_in_dust_seq'\n",
    "master_df = pd.read_csv(os.path.join(data_dir, dataset, 'master_annotations.csv'))\n",
    "master_df = master_df.sort_values('collected_on')\n",
    "\n",
    "pred_root_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "model = '9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_10_tr_br_dr_p2_v_p1_m_p1_u_dust_0624'\n",
    "pred_dir = os.path.join(pred_root_dir, model, dataset)\n",
    "dust_df = pd.read_csv(os.path.join(pred_dir, 'dust_ratio.csv'))\n",
    "dust_df = master_df[['unique_id', 'collected_on']].merge(dust_df, on='unique_id')\n",
    "save_dir = pred_dir\n",
    "\n",
    "# # save as a single video\n",
    "# print(master_df.shape)\n",
    "# video_name = os.path.join(save_dir, 'pred.mp4')\n",
    "# ids = master_df.image_id.to_list()\n",
    "# create_video(ids, pred_dir, video_name, fps=3)\n",
    "\n",
    "# break into sequences\n",
    "seq_dfs = get_sequences(master_df, interval=60, per_camera=False, per_camera_pair=True)\n",
    "print(len(master_df), len(seq_dfs))\n",
    "video_dir = os.path.join(pred_dir, 'videos')\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "# cut_off = {1: [0.93, 1.0], 3: [0.5, 1.0], 5: [0.25, 0.75], 9: [0, 1]}\n",
    "# cut_off = {7: [0.93, 1.0]}\n",
    "for si, seq_df in enumerate(seq_dfs):\n",
    "    if len(seq_df) < 10:\n",
    "        continue\n",
    "    # if si in cut_off:\n",
    "    #     cut1, cut2 = cut_off[si]\n",
    "    #     n = len(seq_df)\n",
    "    #     seq_df = seq_df.iloc[int(n*cut1): int(n*cut2)]\n",
    "    # else:\n",
    "    #     continue\n",
    "        \n",
    "    name = seq_df.iloc[0].collected_on\n",
    "    camera = seq_df.iloc[0].unique_id[-7:]\n",
    "    print(si, name, camera, len(seq_df))\n",
    "    \n",
    "    # create video\n",
    "    # video_name = os.path.join(video_dir, str(si).zfill(3)+'.mp4')\n",
    "    video_name = os.path.join(video_dir, f'{camera}_{si}.mp4')\n",
    "    ids = seq_df.unique_id.to_list()\n",
    "    create_video(ids, pred_dir, video_name, fps=3, txt_df=dust_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create video from PP artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pp_artifacts(data_dir, df_row):\n",
    "    data_path = os.path.join(data_dir, df_row.stereo_pipeline_npz_save_path)\n",
    "    img = np.load(data_path)['left']\n",
    "    img_norm = normalize_image(img, df_row.hdr_mode if 'hdr_mode' in df_row else True)\n",
    "    return cv2.cvtColor((img_norm * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# def add_text(frame, txt_row):\n",
    "#     frame = cv2.putText(frame, f'Collected on: {txt_row.collected_on}', \n",
    "#                         (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "#     return frame\n",
    "\n",
    "def add_text(frame, txt):\n",
    "    frame = cv2.putText(frame, txt, \n",
    "                        (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    return frame\n",
    "\n",
    "def add_texts(frame, txts: list):\n",
    "    txt_pw, txt_ph = 10, 25\n",
    "    for i, txt in enumerate(txts):\n",
    "        if 'false_positive' in txt:\n",
    "            frame = cv2.putText(frame, txt, \n",
    "                                (txt_pw, txt_ph+i*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            frame = cv2.putText(frame, txt, \n",
    "                                (txt_pw, txt_ph+i*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (37,46,58,60,74,86,101,103,106,116,118) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23023, 150) 432\n"
     ]
    }
   ],
   "source": [
    "# data_root_dir = '/data/jupiter/li.yu/data'\n",
    "data_root_dir = '/data/jupiter/datasets/'\n",
    "# dataset = 'mannequin_in_dust_v1'\n",
    "# dataset = 'Jupiter_human_on_path_3_fn_sequence'\n",
    "dataset = 'halo_missed_lo_rock_0509_stereo'\n",
    "data_dir = os.path.join(data_root_dir, dataset)\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, 'master_annotations.csv'))\n",
    "seq_dfs = get_sequences(df, interval=5, per_camera=True)\n",
    "print(df.shape, len(seq_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18:16:02', '18:17:02'] 606\n",
      "['18:17:01', '18:18:01'] 750\n",
      "['18:17:48', '18:18:48'] 498\n",
      "['18:18:45', '18:19:45'] 354\n",
      "['18:21:31', '18:22:31'] 732\n",
      "['18:22:26', '18:23:26'] 900\n",
      "['18:23:12', '18:24:12'] 426\n",
      "['18:24:15', '18:25:15'] 432\n",
      "['20:16:20', '20:17:20'] 930\n",
      "['20:18:38', '20:19:38'] 850\n",
      "['20:20:28', '20:21:28'] 1200\n",
      "(6568, 151)\n",
      "(6568, 151) 2\n"
     ]
    }
   ],
   "source": [
    "bags = [\n",
    "[\"05_09_2024_18_16_02\", \"05_09_2024_18_17_02\"],\n",
    "[\"05_09_2024_18_17_01\", \"05_09_2024_18_18_01\"],\n",
    "[\"05_09_2024_18_17_48\", \"05_09_2024_18_18_48\"],\n",
    "[\"05_09_2024_18_18_45\", \"05_09_2024_18_19_45\"],\n",
    "[\"05_09_2024_18_21_31\", \"05_09_2024_18_22_31\"],\n",
    "[\"05_09_2024_18_22_26\", \"05_09_2024_18_23_26\"],\n",
    "[\"05_09_2024_18_23_12\", \"05_09_2024_18_24_12\"],\n",
    "[\"05_09_2024_18_24_15\", \"05_09_2024_18_25_15\"],\n",
    "[\"05_09_2024_20_16_20\", \"05_09_2024_20_17_20\"],\n",
    "[\"05_09_2024_20_18_38\", \"05_09_2024_20_19_38\"],\n",
    "[\"05_09_2024_20_20_28\", \"05_09_2024_20_21_28\"],\n",
    "]\n",
    "bags = [[bag[0][11:].replace('_', ':'), bag[1][11:].replace('_', ':')] for bag in bags]\n",
    "df['collected_hms'] = df['collected_on'].apply(lambda t: t[11:])\n",
    "df_oi = []\n",
    "for bag in bags:\n",
    "    sub_df = df[(df.collected_hms >= bag[0]) & (df.collected_hms < bag[1])]\n",
    "    print(bag, len(sub_df))\n",
    "    df_oi.append(sub_df)\n",
    "df_oi = pd.concat(df_oi, ignore_index=True).drop_duplicates()\n",
    "print(df_oi.shape)\n",
    "\n",
    "seq_dfs = get_sequences(df_oi)\n",
    "print(df_oi.shape, len(seq_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>id</th>\n",
       "      <th>camera_location</th>\n",
       "      <th>operation_time</th>\n",
       "      <th>special_notes</th>\n",
       "      <th>jdb_s3_path</th>\n",
       "      <th>result_state</th>\n",
       "      <th>result_human_state</th>\n",
       "      <th>result_vehicle_state</th>\n",
       "      <th>min_pixels_threshold</th>\n",
       "      <th>features</th>\n",
       "      <th>n_gt_human_pixels</th>\n",
       "      <th>gt_human_depth</th>\n",
       "      <th>n_pred_human_pixels</th>\n",
       "      <th>pred_human_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663ec898321f043ed7ad8a62_T02_T03</td>\n",
       "      <td>663ec898321f043ed7ad8a62</td>\n",
       "      <td>T02</td>\n",
       "      <td>daytime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>true_negative</td>\n",
       "      <td>108</td>\n",
       "      <td>{\"large_object_pixels\": 688, \"large_object_min...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          unique_id                        id camera_location  \\\n",
       "0  663ec898321f043ed7ad8a62_T02_T03  663ec898321f043ed7ad8a62             T02   \n",
       "\n",
       "  operation_time special_notes  jdb_s3_path   result_state result_human_state  \\\n",
       "0        daytime           NaN          NaN  true_negative      true_negative   \n",
       "\n",
       "  result_vehicle_state  min_pixels_threshold  \\\n",
       "0        true_negative                   108   \n",
       "\n",
       "                                            features  n_gt_human_pixels  \\\n",
       "0  {\"large_object_pixels\": 688, \"large_object_min...                  0   \n",
       "\n",
       "   gt_human_depth  n_pred_human_pixels  pred_human_depth  \n",
       "0            1000                    0              1000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model'\n",
    "models = [\n",
    "    'ds_v8_1_nextvit_small_openimages_with_rev1_train_human_test_using_random_val_mhc_20_epochs_finetune_rev1_lr',\n",
    "    'v81_80k_maxfov_wn_ft_kore_0430'\n",
    "]\n",
    "suffix_list = ['_mhc_depth0125', '']\n",
    "pred_dfs = [pd.read_csv(os.path.join(pred_dir, model, dataset+suffix, 'output.csv')) for model,suffix in zip(models, suffix_list)]\n",
    "pred_dfs[0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/248 [00:00<00:29,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[248, 248, 248]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 248/248 [00:30<00:00,  8.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_pred_texts(pred_dfs, unique_id, text_prefix):\n",
    "    texts = []\n",
    "    for pred_df, prefix in zip(pred_dfs, text_prefix):\n",
    "        pred_row = pred_df[pred_df.unique_id == unique_id].iloc[0]\n",
    "        texts.append(f'{prefix}: {pred_row.result_state}')\n",
    "    return texts\n",
    "\n",
    "def create_video_from_pp_add_text(seq_df, camera_pairs, pred_dfs, H, W, data_dir, video_dir_name):\n",
    "    cam_dfs = [seq_df[seq_df.unique_id.str.endswith(c)] for c in camera_pairs]\n",
    "    cam_dfs = [cdf.sort_values('collected_on', ignore_index=True) for cdf in cam_dfs]\n",
    "    min_len = min(len(cdf) for cdf in cam_dfs)\n",
    "    cam_dfs = [cdf.iloc[:min_len] for cdf in cam_dfs]\n",
    "    print([len(cdf) for cdf in cam_dfs])\n",
    "\n",
    "    # .avi MJPG,  .mp4 MP4V\n",
    "    os.makedirs(os.path.join(data_dir, video_dir_name), exist_ok=True)\n",
    "    video_name = os.path.join(data_dir, f'{video_dir_name}/{seq_df.iloc[0].collected_on}.mp4')\n",
    "\n",
    "    # print(f'{H} rows, {W} cols out of {len(camera_pairs)} camera_pairs')\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'MP4V'), 3, (768*W,512*H), isColor=True)\n",
    "\n",
    "    for ii in tqdm(range(min_len)):\n",
    "        # try:\n",
    "        canvas = np.zeros((512*H, 768*W, 3), dtype=np.uint8)\n",
    "        for ci in range(len(cam_dfs)):\n",
    "            row = cam_dfs[ci].iloc[ii]\n",
    "            frame = read_from_pp_artifacts(data_dir, row)\n",
    "            texts = [f'{row.collected_on}'] + get_pred_texts(pred_dfs, row.unique_id, ['MHC pred', 'MAXFOV pred'])\n",
    "            # print(texts)\n",
    "            frame = add_texts(frame, texts)\n",
    "            fi, fj = ci // W, ci % W\n",
    "            canvas[512*fi:512*(fi+1), 768*fj:768*fj+frame.shape[1]] = frame\n",
    "        video.write(canvas)\n",
    "        # except:\n",
    "        #     print(f'{ii}th image read failed')\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "front_pairs = ['T02_T04', 'T02_T03', 'T01_T03']\n",
    "left_pass_pairs = ['T02_T04', 'T02_T03', 'T01_T03', 'T13_T15', 'T14_T15', 'T14_T16']\n",
    "right_pass_pairs = ['T02_T04', 'T02_T03', 'T01_T03', 'T06_T08', 'T05_T07', 'T06_T07']\n",
    "# left_pass_pairs = ['T09_T11', 'T14_T16', 'T14_T15', 'T13_T15']\n",
    "# right_pass_pairs = ['T05_T07', 'T10_T12', 'T06_T08', 'T06_T07']\n",
    "H = 1  # number of image rows\n",
    "W = 3  # number of image cols\n",
    "create_video_from_pp_add_text(seq_dfs[1], front_pairs, pred_dfs, H, W, data_dir, 'videos_front_pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T01_T03', 'T02_T03', 'T02_T04', 'T05_T07', 'T06_T07', 'T06_T08',\n",
       "       'T09_T11', 'T10_T12', 'T10_T11', 'T13_T15', 'T14_T16', 'T14_T15'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"camera_pair\"] = df[\"unique_id\"].apply(lambda t: t[-7:])\n",
    "df[\"camera_pair\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Read frame and add prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 11)\n"
     ]
    }
   ],
   "source": [
    "# compare BRT model pred and CenterTrack pred\n",
    "# pred_csv = '/data/jupiter/li.yu/exps/driveable_terrain_model/v188_58d_rak_local_fine_tversky11_sum_image_normT_prod5_airdyn_r3a8_s30/mannequin_in_dust_v1/output.csv'\n",
    "pred_csv = '/data/jupiter/li.yu/exps/driveable_terrain_model/v188_58d_rak_local_fine_tversky11_sum_image_normT_prod5_airdyn_r3a8_s30/Jupiter_human_on_path_3_fn_sequence/output.csv'\n",
    "pred_df = pd.read_csv(pred_csv)\n",
    "print(pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 2023-07-08T01:37:09.798000 153\n"
     ]
    }
   ],
   "source": [
    "video_with_pred_dir = os.path.join(data_root_dir, dataset, 'videos_with_pred')\n",
    "# pred_sequence_dir = '/home/li.yu/code/CenterTrack/results/2023-07-08T01:37:09.798000_front-center_15'\n",
    "pred_sequence_dir = '/home/li.yu/code/CenterTrack/results/brt50000/nopreimg_noprehm/2023-07-08T01:37:09.798000_front-center_15'\n",
    "os.makedirs(video_with_pred_dir, exist_ok=True)\n",
    "height, width = 512, 1024\n",
    "\n",
    "for si, seq_df in enumerate(seq_dfs):\n",
    "    if len(seq_df) < 10 or si != 15:\n",
    "        continue\n",
    "    name = seq_df.iloc[0].collected_on\n",
    "    camera = seq_df.iloc[0].camera_location[:-5]\n",
    "    print(si, name, len(seq_df))\n",
    "    \n",
    "    # merge pred from BRT model\n",
    "    seq_df = seq_df.drop(columns=['state']).merge(pred_df[['id', 'state', 'human_state']], on='id')\n",
    "\n",
    "    # create video\n",
    "    video_name = os.path.join(video_with_pred_dir, f'{name}_{camera}_{si}_nopreimg_noprehm.mp4')\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), 3, (width,height), isColor=True)\n",
    "    fi = 0\n",
    "    for _, df_row in seq_df.iterrows():\n",
    "        frame = cv2.imread(os.path.join(pred_sequence_dir, str(fi).zfill(3)+'_'+df_row.id+'.png'))\n",
    "        frame = cv2.putText(frame, f'BRT Seg Pred: {df_row.state}, Strict: {df_row.human_state}', \n",
    "                            (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "        video.write(frame)\n",
    "        fi += 1\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### read from video and prediction results to each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2022-11-10T23:19:10.901000 88\n"
     ]
    }
   ],
   "source": [
    "video_dir = '/home/li.yu/code/CenterTrack/results/'\n",
    "old_video_name = 'brt50000_2022-11-10T23:19:10.901000_side-right_2_preimg.mp4'\n",
    "new_video_name = 'brt50000_2022-11-10T23:19:10.901000_side-right_2_preimg_withbrtpred.mp4'\n",
    "height, width = 512, 1024\n",
    "\n",
    "for si, seq_df in enumerate(seq_dfs):\n",
    "    if len(seq_df) < 10 or si != 2:\n",
    "        continue\n",
    "    name = seq_df.iloc[0].collected_on\n",
    "    camera = seq_df.iloc[0].camera_location[:-5]\n",
    "    print(si, name, len(seq_df))\n",
    "    \n",
    "    # merge pred from BRT model\n",
    "    seq_df = seq_df.drop(columns=['state']).merge(pred_df[['id', 'state', 'human_state']], on='id')\n",
    "\n",
    "    # read video\n",
    "    cam = cv2.VideoCapture(os.path.join(video_dir, old_video_name))\n",
    "\n",
    "    # create video\n",
    "    video_name = os.path.join(video_dir, new_video_name)\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), 3, (width,height), isColor=True)\n",
    "    for _, df_row in seq_df.iterrows():\n",
    "        _, frame = cam.read()\n",
    "        frame = cv2.putText(frame, f'BRT Seg Pred: {df_row.state}, Strict: {df_row.human_state}', \n",
    "                            (40,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "        video.write(frame)\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 64-bit ('brtdevkit': conda)",
   "language": "python",
   "name": "python3918jvsc74a57bd0c8cced58dbff2798e473c5ca6eca1100bfa72eead58bcdfb1b17e02c86ac111a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
