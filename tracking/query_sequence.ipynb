{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Internal AWS credentials have been removed from brt-devkit.\n",
      "To setup AWS credentials, Please follow instructions at : https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.4.3\n"
     ]
    }
   ],
   "source": [
    "# need to use updated master JupiterCVML code\n",
    "import sys\n",
    "sys.path.append('/home/li.yu/code/JupiterCVML/europa/base/src/europa')\n",
    "\n",
    "import os\n",
    "os.environ[\"BRT_ENV\"] = 'prod'\n",
    "import json\n",
    "import ndjson\n",
    "import random\n",
    "import brtdevkit\n",
    "print(brtdevkit.__version__)\n",
    "brtdevkit.log = 'info'\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = 'default'\n",
    "\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "from brtdevkit.core.db.athena import AthenaClient, Table\n",
    "from brtdevkit.data import Image, Dataset\n",
    "\n",
    "from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import *\n",
    "from aletheia_dataset_creator.config.dataset_config import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['front-center-left', 'front-left-left', 'front-right-left', 'side-left-left', 'side-right-left', 'rear-left', 'T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14', 'I01', 'I03', 'I05', 'I07']\n",
      "[{'front-center-left': 'front-center-right', 'front-left-left': 'front-left-right', 'front-right-left': 'front-right-right', 'side-left-left': 'side-left-right', 'side-right-left': 'side-right-right', 'rear-left': 'rear-right', 'front-center-right': 'front-center-left', 'front-left-right': 'front-left-left', 'front-right-right': 'front-right-left', 'side-left-right': 'side-left-left', 'side-right-right': 'side-right-left', 'rear-right': 'rear-left'}, {'T01': 'T03', 'T02': 'T04', 'T05': 'T07', 'T06': 'T08', 'T09': 'T11', 'T10': 'T12', 'T13': 'T15', 'T14': 'T16'}, {'T02': 'T03', 'T06': 'T07', 'T10': 'T11', 'T14': 'T15'}, {'I01': 'I02', 'I03': 'I04', 'I05': 'I06', 'I07': 'I08'}]\n"
     ]
    }
   ],
   "source": [
    "print(LEFT_CAMERAS)\n",
    "print(ALL_CAMERA_PAIRS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all groups contain left and right images\n",
    "def filter_single_cameras(df):\n",
    "    incomplete_group_ids = df['group_id'].value_counts()[lambda x: x % 2 != 0].index.tolist()\n",
    "    df = df[~df.group_id.isin(incomplete_group_ids)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6554529d956f45c46b94ac64\n"
     ]
    },
    {
     "data": {
      "text/plain": "(153985, 647)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Dataset.retrieve(id='6554529d956f45c46b94ac64')\n",
    "# test_dataset = Dataset.retrieve(name='dynamic_manny_in_dust_raw')\n",
    "print(test_dataset.id)\n",
    "test_df = test_dataset.to_dataframe()\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653a81a98d90e240199d31c0\n"
     ]
    },
    {
     "data": {
      "text/plain": "(416, 122)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset = Dataset.retrieve(id='6554529d956f45c46b94ac64')\n",
    "test_dataset2 = Dataset.retrieve(name='Jupiter_human_on_path_3_fn_sequence')\n",
    "print(test_dataset2.id)\n",
    "test_df2 = test_dataset2.to_dataframe()\n",
    "test_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "121"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_df.columns).intersection(set(test_df2.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMERA_LOCATION = 'camera_location'\n",
    "LEFT = 'left'\n",
    "RIGHT = 'right'\n",
    "GROUP_ID = 'group_id'\n",
    "LEFT_SUFFIX: str = f\"_{LEFT}\"\n",
    "RIGHT_SUFFIX: str = f\"_{RIGHT}\"\n",
    "\n",
    "def remove_lr_suffix(\n",
    "    in_str: str, left_suffix: str = LEFT_SUFFIX, right_suffix: str = RIGHT_SUFFIX\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Remove the left_suffix or the right_suffix from in_str.\n",
    "    If neither is a suffix, return the `in_str`\n",
    "    \"\"\"\n",
    "    out_str = in_str\n",
    "    for suffix in [left_suffix, right_suffix]:\n",
    "        if out_str.endswith(suffix):\n",
    "            out_str = out_str[: -len(suffix)]\n",
    "            return out_str\n",
    "    return in_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = test_df\n",
    "stereo_camera_location_col = \"stereo_camera_location\"\n",
    "\n",
    "# Add a temporary column to identify the stereo camera which produced the stereo image\n",
    "dataframe.loc[:, stereo_camera_location_col] = dataframe.loc[:, CAMERA_LOCATION].apply(\n",
    "    lambda x: remove_lr_suffix(x, f\"-{LEFT}\", f\"-{RIGHT}\")\n",
    ")\n",
    "\n",
    "# # Filter (by camera location)\n",
    "# dataframe = dataframe[\n",
    "#     dataframe.loc[:, stereo_camera_location_col].isin(self.camera_location)\n",
    "# ]\n",
    "\n",
    "# Left-Right split\n",
    "left_camera_df = dataframe[\n",
    "    dataframe.loc[:, CAMERA_LOCATION].apply(lambda x: x.endswith(LEFT))\n",
    "]\n",
    "right_camera_df = dataframe[\n",
    "    dataframe.loc[:, CAMERA_LOCATION].apply(lambda x: x.endswith(RIGHT))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((54733, 676), (54733, 676))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_camera_df.shape, right_camera_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(54733, 676)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = left_camera_df.merge(\n",
    "    right_camera_df[[GROUP_ID, stereo_camera_location_col]],\n",
    "    how=\"inner\",\n",
    "    on=[GROUP_ID, stereo_camera_location_col],\n",
    "    suffixes=[LEFT_SUFFIX, RIGHT_SUFFIX],\n",
    ")\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "676"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(left_camera_df.columns)).intersection(set(list(right_camera_df.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(53301, 53301)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(left_camera_df.group_id.to_list())), len(set(left_camera_df.group_id.to_list()).intersection(set(right_camera_df.group_id.to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((155900, 4), (153985, 647))"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n    <tr>\n      <th>camera_location</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>front-center-left</th>\n      <td>31212</td>\n    </tr>\n    <tr>\n      <th>front-center-right</th>\n      <td>31212</td>\n    </tr>\n    <tr>\n      <th>front-left-left</th>\n      <td>8641</td>\n    </tr>\n    <tr>\n      <th>front-left-right</th>\n      <td>8641</td>\n    </tr>\n    <tr>\n      <th>front-right-left</th>\n      <td>7468</td>\n    </tr>\n    <tr>\n      <th>front-right-right</th>\n      <td>7468</td>\n    </tr>\n    <tr>\n      <th>rear-left</th>\n      <td>11638</td>\n    </tr>\n    <tr>\n      <th>rear-right</th>\n      <td>11638</td>\n    </tr>\n    <tr>\n      <th>side-left-left</th>\n      <td>9672</td>\n    </tr>\n    <tr>\n      <th>side-left-right</th>\n      <td>9672</td>\n    </tr>\n    <tr>\n      <th>side-right-left</th>\n      <td>8177</td>\n    </tr>\n    <tr>\n      <th>side-right-right</th>\n      <td>8177</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                       id\ncamera_location          \nfront-center-left   31212\nfront-center-right  31212\nfront-left-left      8641\nfront-left-right     8641\nfront-right-left     7468\nfront-right-right    7468\nrear-left           11638\nrear-right          11638\nside-left-left       9672\nside-left-right      9672\nside-right-left      8177\nside-right-right     8177"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df2[['id', 'camera_location']].groupby('camera_location').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_column(row):\n",
    "    row['Humans'] = row[\"label_counts\"].get(\"Humans\", 0)\n",
    "    row['Vehicles'] = row[\"label_counts\"].get(\"Tractors or Vehicles\", 0)\n",
    "    row['Dust'] = row[\"label_counts\"].get(\"Heavy Dust\", 0)\n",
    "    return row\n",
    "\n",
    "def get_object_location(object_mask):\n",
    "    rows, cols = np.where(object_mask)\n",
    "    return np.min(rows), np.max(rows), np.min(cols), np.max(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (6,7,39,223,225,227,230,247,251,254,267,308,324,327,337,338,346,354,370,371,373,376,377) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317956, 434)\n",
      "(317956, 437)\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/data2/jupiter/datasets/Jupiter_train_v6_2'\n",
    "csv = '/data/jupiter/li.yu/data/Jupiter_train_v6_1/epoch0_5_30_focal05_master_annotations.csv'\n",
    "converters = {\"label_map\": ast.literal_eval, \"label_counts\": ast.literal_eval}\n",
    "df = pd.read_csv(csv, converters=converters)\n",
    "print(df.shape)\n",
    "# get human and vehicle counts in images\n",
    "df = df.apply(lambda row: convert_label_column(row), axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n    <tr>\n      <th>is_multi_human</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>46646</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>11129</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                   id\nis_multi_human       \nFalse           46646\nTrue            11129"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['id', 'is_multi_human']].groupby('is_multi_human').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38299, 437) (12407, 437)\n",
      "(50485, 437) (240883, 437)\n"
     ]
    }
   ],
   "source": [
    "# sort out subsets to save\n",
    "human_df = df[(df.Humans > 100) & (df.Humans < 50000) & (df.is_multi_human != True) & (df.occluded_humans != True)]\n",
    "vehicle_df = df[(df.Vehicles > 100) & (df.Vehicles < 80000)]\n",
    "dust_df = df[(df.Dust > 100) & (df.Dust < 50000) & (df.is_multi_human != True) & (df.occluded_humans != True)]\n",
    "# ioi_df = pd.concat([human_df, vehicle_df, dust_df], ignore_index=True)  # image of interest\n",
    "ioi_df = pd.concat([human_df, dust_df], ignore_index=True).drop_duplicates(subset='id')  # image of interest\n",
    "ofs_df = df[(df.Humans == 0) & (df.Vehicles == 0)]  # out of scope\n",
    "# print(human_df.shape, vehicle_df.shape, dust_df.shape)\n",
    "print(human_df.shape, dust_df.shape)\n",
    "print(ioi_df.shape, ofs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_df[['id', 'collected_on', 'camera_location', 'robot_name', 'bag_name']].to_csv('/data/jupiter/li.yu/data/Jupiter_train_v6_1/v61_single_humans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-d7931274cc6e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  human_df['datetime'] = human_df.collected_on.apply(datetime.fromisoformat)\n"
     ]
    }
   ],
   "source": [
    "human_df['datetime'] = human_df.collected_on.apply(datetime.fromisoformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(Timestamp('2021-09-20 21:06:34.333000'), 'side-right', 'peaty_03')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_dt = human_df.iloc[0].datetime\n",
    "camera_location = human_df.iloc[0].camera_location[:-5]\n",
    "robot_name = human_df.iloc[0].robot_name\n",
    "collected_dt, camera_location, robot_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "('2021-09-20 21:06:24', '2021-09-20 21:06:44')"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = timedelta(seconds=10)\n",
    "start_datetime = str(collected_dt - delta)[:-7]\n",
    "end_datetime = str(collected_dt + delta)[:-7]\n",
    "start_datetime, end_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run query on Databricks Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks import sql\n",
    "\n",
    "connection = sql.connect(\n",
    "                        server_hostname = \"dbc-67a19da0-a8c7.cloud.databricks.com\",\n",
    "                        http_path = \"/sql/1.0/warehouses/681fe1612a5b9f96\",\n",
    "                        access_token = \"dapi34534145f146299defded345693f0784\")\n",
    "\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(df_row, cursor):\n",
    "    # get key words\n",
    "    collected_dt = df_row.datetime\n",
    "    camera_location = df_row.camera_location[:-5]\n",
    "    robot_name = df_row.robot_name\n",
    "    delta = timedelta(seconds=10)\n",
    "    start_datetime = str(collected_dt - delta)[:-7]\n",
    "    end_datetime = str(collected_dt + delta)[:-7]\n",
    "    # get query statement\n",
    "    stmt = \\\n",
    "    f\"\"\"\n",
    "    SELECT id, group_id, camera_location, collected_on\n",
    "    FROM mesa_prod.mesa_lake_prod.image_jupiter T\n",
    "    WHERE \n",
    "        T.collected_on > TIMESTAMP '{start_datetime}'\n",
    "        AND T.collected_on < TIMESTAMP '{end_datetime}'\n",
    "        AND T.robot_name = '{robot_name}'\n",
    "        AND T.camera_location LIKE '{camera_location}%'\n",
    "    \"\"\"\n",
    "    # run query\n",
    "    cursor.execute(stmt)\n",
    "    res = cursor.fetchall()\n",
    "    # convert to df\n",
    "    if len(res) > 0:\n",
    "        df = pd.DataFrame(columns=list(res[0].asDict().keys()))\n",
    "        df = pd.DataFrame.from_dict([r.asDict() for r in res])\n",
    "        return df\n",
    "    print(f'failed for {df_row.id}')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 280)\n"
     ]
    }
   ],
   "source": [
    "df = run_query(human_df.iloc[1], cursor)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_human_df = human_df.sample(1000)\n",
    "save_dir = '/data/jupiter/li.yu/data/Jupiter_train_v6_1/v61_single_human_sequence_csvs'\n",
    "os.makedirs(save_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(972, 438)\n"
     ]
    }
   ],
   "source": [
    "# check finished ones\n",
    "finished_ids = [f[:-4] for f in os.listdir(save_dir)]\n",
    "sub_human_df = sub_human_df[~sub_human_df.id.isin(finished_ids)]\n",
    "print(sub_human_df.shape)\n",
    "for i,row in tqdm(sub_human_df.iterrows(), total=len(sub_human_df)):\n",
    "    df = run_query(row, cursor)\n",
    "    if df is not None:\n",
    "        csv_path = os.path.join(save_dir, row.id+'.csv')\n",
    "        df[['id', 'group_id', 'camera_location', 'collected_on']].to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(155900, 4)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all dfs\n",
    "finished_ids = [f[:-4] for f in os.listdir(save_dir)]\n",
    "dfs = []\n",
    "for id in finished_ids:\n",
    "    df = pd.read_csv(os.path.join(save_dir, id+'.csv'))\n",
    "    df = filter_single_cameras(df)\n",
    "    if len(df) >= 10:\n",
    "        dfs.append(df)\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1784, (155900, 4))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs), df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run query on Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.60246181488037 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "((58, 254), 29)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hard_drive_name = 'JUPD-048_2022-09-27'\n",
    "# start_datetime  = datetime(2021, 12, 16, hour=22, minute=14, second=0) #, tzinfo=timezone.utc)\n",
    "# end_datetime  = datetime(2021, 12, 16, hour=22, minute=14, second=35) #, tzinfo=timezone.utc)\n",
    "# start_datetime  = datetime(2022, 9, 28, tzinfo=timezone.utc) #, hour=3, minute=33, second=33) #, tzinfo=timezone.utc)\n",
    "# start_datetime  = datetime(2023, 8, 28, hour=0, minute=0)   #, tzinfo=timezone.utc)\n",
    "# end_datetime    = datetime(2023, 8, 30, hour=23, minute=59)  # this is EXclusive\n",
    "\n",
    "database = \"mesa-data-catalog-prod\"\n",
    "table = \"image_jupiter\"\n",
    "\n",
    "query = \\\n",
    "f\"\"\"\n",
    "SELECT *\n",
    "FROM {table} T\n",
    "WHERE \n",
    "    T.collected_on > TIMESTAMP '{start_datetime}'\n",
    "    AND T.collected_on < TIMESTAMP '{end_datetime}'\n",
    "    AND T.robot_name = '{robot_name}'\n",
    "    AND T.camera_location LIKE '{camera_location}%'\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SELECT\n",
    "        *\n",
    "    FROM annotation_jupiter\n",
    "    WHERE\n",
    "     annotation_jupiter.image IN ('642607df1620247e2285d6ac')\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SELECT id, camera_location, operation_time, collected_on, state, county, operating_field_name, hdr_mode, robot_name, special_notes\n",
    "T.collected_on >= cast('{start_datetime}' as timestamp)\n",
    "    AND T.collected_on < cast('{end_datetime}' as timestamp)\n",
    "    AND T.camera_location LIKE 'front-%'\n",
    "    AND T.camera_location LIKE '%-left'\n",
    "    AND T.hard_drive_name = 'JUPD-154_2023-01-14'\n",
    "    AND T.robot_name LIKE 'loamy%'\n",
    "    AND T.operation_time != 'daytime'\n",
    "    AND T.has_nearby_stop_event = true\n",
    "ORDER BY RAND()\n",
    "LIMIT 40000\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "athena = AthenaClient()\n",
    "df = athena.get_df(query)\n",
    "end = time.time()\n",
    "print(end - start, 's')\n",
    "df.shape, len(df) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(180, 2)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('./dust_threshold/human_vehicle_in_dust_for_train_total.csv')\n",
    "# df = pd.read_csv('./dust_threshold/dust_productivity.csv')\n",
    "# df = pd.read_csv('/data/jupiter/datasets/Jupiter_train_v5_11/driveable_not_labeled.csv')\n",
    "# df = pd.read_csv('/data/jupiter/datasets/Jupiter_train_v5_11/less_than_half_labeled.csv')\n",
    "# df = pd.read_csv('/data/jupiter/datasets/Jupiter_train_v5_11/less_than_half_or_driveable_not_labeled_for_relabeling.csv')\n",
    "df = pd.read_csv('/data/jupiter/li.yu/exps/driveable_terrain_model/rgb_baseline_sample_a_v3_2/20230925_halo_rgb_stereo_train_v3_epoch0/pruned_ids.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unlabeled dataset\n",
    "Dataset.create(\n",
    "    name=\"Jupiter_rev1_train_1784_human_sequences_stereo\",\n",
    "    description=\"1784 20s sequences for 1784 images in train set v6.1, 153616 images\",\n",
    "    kind='image',\n",
    "    image_ids=test_df2.id.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Filtered 308 annotations.\n",
      "Sending 12166 annotated_ids for creating dataset\n",
      "Time taken to prepare data for dataset creation job: 2.07 mins\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Filtered 0 annotations.\n",
      "Sending 12166 annotated_ids for creating dataset\n",
      "Time taken to prepare data for dataset creation job: 2.15 mins\n"
     ]
    }
   ],
   "source": [
    "imageids_to_dataset(\n",
    "    image_ids=test_df[test_df.camera_location.str.endswith('left')].id.to_list(),\n",
    "    dataset_name=\"20230823_labeled_right_images_12k_left_images_labels\",\n",
    "    dataset_description=\"left images and labels of 20230823_labeled_right_images_12k\",\n",
    "    dataset_kind='annotation',  # annotation or image\n",
    "    mode='mono',  # stereo or mono\n",
    "    camera_location=CORE_LEFT_CAMERAS,  # CORE_LEFT_CAMERAS or CORE_RIGHT_CAMERAS or ALL_CORE_CAMERAS\n",
    ")\n",
    "imageids_to_dataset(\n",
    "    image_ids=test_df[test_df.camera_location.str.endswith('right')].id.to_list(),\n",
    "    dataset_name=\"20230823_labeled_right_images_12k_right_images_labels\",\n",
    "    dataset_description=\"right images and labels of 20230823_labeled_right_images_12k\",\n",
    "    dataset_kind='annotation',  # annotation or image\n",
    "    mode='mono',  # stereo or mono\n",
    "    camera_location=CORE_RIGHT_CAMERAS,  # CORE_LEFT_CAMERAS or CORE_RIGHT_CAMERAS or ALL_CORE_CAMERAS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Filtered 4 annotations.\n",
      "Warning 38 images do not have a corresponding annotation.\n",
      "Preparing stereo dataframe...\n",
      "Size of left dataframe: 129\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Size of stereo dataframe: 129\n",
      "Preparing stereo dataframe...\n",
      "Size of left dataframe: 90\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Size of stereo dataframe: 90\n",
      "Preparing stereo dataframe...\n",
      "Size of left dataframe: 13\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Size of stereo dataframe: 13\n",
      "Sending 142 annotated_ids for creating dataset\n",
      "Time taken to prepare data for dataset creation job: 2.46 mins\n"
     ]
    }
   ],
   "source": [
    "# # in master branch halo datasets\n",
    "# annotations = imageids_to_annotation_df(\n",
    "#     image_ids=df.id.to_list(),\n",
    "# )\n",
    "\n",
    "imageids_to_dataset(\n",
    "    image_ids=df.id.to_list(),\n",
    "    dataset_name=\"20230925_halo_rgb_stereo_train_v3_high_focal_loss\",\n",
    "    dataset_description=\"180 images with >0.5 focal loss from dataset 20230925_halo_rgb_stereo_train_v3\",\n",
    "    dataset_kind='annotation',  # annotation or image\n",
    "    mode='stereo',  # stereo or mono\n",
    ")\n",
    "# Dataset.create(\n",
    "#     name=\"20230925_halo_rgb_stereo_train_v3_pruned\",\n",
    "#     description=\"180 images with >0.5 focal loss from dataset 20230925_halo_rgb_stereo_train_v3\",\n",
    "#     kind=Dataset.KIND_ANNOTATION,\n",
    "#     image_ids=df.id.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34;1m2023-11-16 11:58:48,945 - Dataset - INFO - start downloading dataset: 6554529d956f45c46b94ac64 into /data/jupiter/li.yu/data/Jupiter_rev1_train_1784_human_sequences\n",
      "\u001b[0m/home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/pandas/core/frame.py:3641: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[k1] = value[k2]\n",
      "100%|██████████| 378854/378854 [10:08<00:00, 622.90it/s]\n",
      "\u001b[34;1m2023-11-16 12:11:48,769 - Dataset - INFO - finished downloading dataset: 6554529d956f45c46b94ac64\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "dataset_name = 'Jupiter_rev1_train_1784_human_sequences'\n",
    "# dataset_dir = os.path.join('/data/jupiter/datasets', dataset_name)\n",
    "dataset_dir = os.path.join('/data/jupiter/li.yu/data', dataset_name)\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "test_dataset = Dataset.retrieve(name=dataset_name)\n",
    "test_df = test_dataset.to_dataframe()\n",
    "test_dataset.download(dataset_dir, df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.yu/anaconda3/envs/pytorchlightning/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (0,2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,19,20,21,22,24,25,26,27,28,29,30,31,32,33,34,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,53,54,55,56,58,59,60,61,62,63,64,65,66,67,68,70,71,72,73,75,76,78,79,81,82,83,84,85,87,88,89,90,92,93,95,96,98,99,100,101,102,104,105,106,107,109,110,112,113,115,116,117,118,119,121,122,123,124,126,127,128,129,130,132,133,134,135,136,138,139,140,141,143,144,145,146,147,149,150,151,152,153,155,156,157,158,160,161,162,163,164,165,166,167,168,172,173,174,175,177,178,179,180,181,182,183,184,185,189,190,191,192,194,195,196,197,198,199,200,201,202,206,207,208,209,211,212,213,214,215,216,217,218,219,223,224,225,226,228,229,231,232,234,235,236,240,241,242,243,245,246,248,249,251,252,253,257,258,259,260,262,263,265,266,268,269,270,274,275,276,277,279,280,281,282,283,285,286,287,288,289,291,292,293,294,296,297,298,299,300,301,302,303,304,305,306,308,309,310,311,313,314,315,316,317,318,319,320,321,322,323,325,326,327,328,330,331,332,333,334,335,336,337,338,339,340,342,343,344,345,347,348,349,350,351,352,353,354,355,356,357,359,360,361,362,364,365,366,367,368,369,370,371,372,373,374,376,377,378,379,381,382,383,384,385,386,387,388,389,390,391,393,394,395,396,398,399,401,402,404,405,406,407,408,410,411,412,413,415,416,418,419,421,422,423,424,425,427,428,429,430,432,433,434,435,436,438,439,440,441,442,444,445,446,447,449,450,451,452,453,455,456,457,458,459,461,462,463,464,466,467,468,469,470,472,473,474,475,476,479,480,482,483,484,488,489,492,493,496,499,501,502,503,504,505,506,507,510,511,512,515,516,519,520,523,524,526,527,528,529,530,532,533,534,535,536,537,538,539,541,542,543,544,545,547,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,581,582,583,584,585,586,587,588,589,591,593,596,597,598,599,600,602,604,606,607,608,609,610,612,613,614,615,616,617,619,621,623,625,626,628,629,630,631,632,633,634,635,636,637,639,642,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(153985, 675)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(dataset_dir, 'annotations.csv.old'))\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(109466, 675)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop_duplicates(subset=['id', 'group_id'], inplace=True)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(dataset_dir, 'annotations.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 64-bit ('pytorchlightning': conda)",
   "name": "python388jvsc74a57bd01eceddbeeb55f686303d64ef8e05e300429be7c506c9f9cad24a6dfe5f27b555"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "1eceddbeeb55f686303d64ef8e05e300429be7c506c9f9cad24a6dfe5f27b555"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}