{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.11.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "from utils import get_sequences\n",
    "\n",
    "import os\n",
    "os.environ[\"BRT_ENV\"] = 'prod'\n",
    "import json\n",
    "import random\n",
    "import brtdevkit\n",
    "print(brtdevkit.__version__)\n",
    "brtdevkit.log = 'info'\n",
    "import os\n",
    "os.environ['AWS_PROFILE'] = 'default'\n",
    "USERNAME = 'li.yu'\n",
    "\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# from brtdevkit.core.db.athena import AthenaClient, Table\n",
    "# from brtdevkit.data import Image, Dataset\n",
    "# from aletheia_dataset_creator.dataset_tools.aletheia_dataset_helpers import *\n",
    "# from aletheia_dataset_creator.config.dataset_config import *\n",
    "\n",
    "# from jupiterdata.utils.dataset import query_db\n",
    "from jupiterdata.config.dataset_config import *\n",
    "from jupiterdata.utils.dataset import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'brtdevkit.data.dataset' from '/home/li.yu/anaconda3/envs/query/lib/python3.10/site-packages/brtdevkit/data/dataset.py'>\n",
      "['front-center-left', 'front-left-left', 'front-right-left', 'side-left-left', 'side-right-left', 'rear-left', 'T01', 'T02', 'T05', 'T06', 'T09', 'T10', 'T13', 'T14', 'I01', 'I02']\n",
      "[{'front-center-left': 'front-center-right', 'front-left-left': 'front-left-right', 'front-right-left': 'front-right-right', 'side-left-left': 'side-left-right', 'side-right-left': 'side-right-right', 'rear-left': 'rear-right', 'front-center-right': 'front-center-left', 'front-left-right': 'front-left-left', 'front-right-right': 'front-right-left', 'side-left-right': 'side-left-left', 'side-right-right': 'side-right-left', 'rear-right': 'rear-left'}, {'T01': 'T03', 'T02': 'T04', 'T05': 'T07', 'T06': 'T08', 'T09': 'T11', 'T10': 'T12', 'T13': 'T15', 'T14': 'T16', 'I01': 'I03', 'I02': 'I04'}, {'T02': 'T03', 'T06': 'T07', 'T10': 'T11', 'T14': 'T15', 'I02': 'I03'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # run this on cmd to activate aws sso: \n",
    "eval \"$(/home/li.yu/anaconda3/bin/conda shell.bash hook)\"\n",
    "conda activate query\n",
    "brt-devkit-auth\n",
    "aws sso login --profile jupiter_prod_engineer-425642425116\n",
    "\"\"\"\n",
    "import inspect\n",
    "print(inspect.getmodule(Dataset))\n",
    "print(LEFT_CAMERAS)\n",
    "print(ALL_CAMERA_PAIRS_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66df7905429da12e01ab2fe8\n",
      "(2295, 221)\n",
      "2024-07-29T19:08:51.517000 2024-08-27T02:56:48.911000\n"
     ]
    }
   ],
   "source": [
    "# test_dataset = Dataset.retrieve(id='64ed2657926aefcd654e8269')\n",
    "test_dataset = Dataset.retrieve(name='halo_buildup_dust_gilroy_low_dust_human_labeled_v4')\n",
    "print(test_dataset.id)\n",
    "test_df = test_dataset.to_dataframe()\n",
    "print(test_df.shape)\n",
    "if len(test_df) < 100000:\n",
    "    test_df = test_df.sort_values('collected_on')\n",
    "    print(test_df.iloc[0].collected_on, test_df.iloc[-1].collected_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camera_location\n",
       "I02     1\n",
       "T01    13\n",
       "T02    20\n",
       "T05     2\n",
       "T06     8\n",
       "T09    39\n",
       "T10    40\n",
       "T13    20\n",
       "T14    23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['id', 'camera_location']].groupby('camera_location').size()\n",
    "# test_df[['id', 'operation_time']].groupby('operation_time').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['frodo2411'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.robot_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Databricks Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477200, 11) 238600\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "  IMJ.id,\n",
    "  IMJ.operation_time,\n",
    "  IMJ.camera_location,\n",
    "  IMJ.robot_name,\n",
    "  IMJ.collected_on,\n",
    "  IMJ.special_notes,\n",
    "  IMJ.hard_drive_name,\n",
    "  IMJ.spark_request__json,\n",
    "  IMJ.teleop_request__json,\n",
    "  IMJ.gps_can_data__json,\n",
    "  IMJ.geohash,\n",
    "  IMJ.autonomy_state__json\n",
    "FROM\n",
    "  mesa_prod.mesa_lake_prod.image_jupiter AS IMJ\n",
    "WHERE\n",
    "  IMJ.robot_name = '1RW8410DTPK808012'\n",
    "  AND IMJ.collected_on > date('2024-10-01')\n",
    "  AND IMJ.collected_on <= date('2024-10-31')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = query_db(query)\n",
    "if len(df) > 0:\n",
    "    print(df.shape, len(df)//2)\n",
    "    if len(df) < 100000:\n",
    "        df = df.sort_values('collected_on')\n",
    "        df['collected_on_str'] = df['collected_on'].apply(lambda c: str(c)[:-13])\n",
    "        print(df.iloc[0].collected_on_str, df.iloc[-1].collected_on_str)\n",
    "        print(df.iloc[0].id, df.iloc[-1].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 'jason zaman high voltage lines',\n",
       " 'Soy Stubble + Light Cattle Manure',\n",
       " 'Soy stubble + cattle manure',\n",
       " 'irrigation hut + water tank',\n",
       " 'irrigation pivot headland',\n",
       " 'Jason Zaman High voltage Lines',\n",
       " 'pivot headland pass',\n",
       " 'pivot headlands',\n",
       " 'Pivot House',\n",
       " 'Road Culvert left of tractor',\n",
       " 'weed spark said was human (8012 on 10/21 @3:53PM)',\n",
       " 'JF-183 human capture',\n",
       " 'Continuous capture tall stalks',\n",
       " 'tall talks / high debris / high dust / hazy / sundown',\n",
       " 'JF-183 human capture sundown / haze',\n",
       " 'soy stubble at night',\n",
       " 'JF-183',\n",
       " 'tall stalks with blowing residue',\n",
       " 'JF-183 Human Capture',\n",
       " 'soy stubble + cattle manure']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_notes = df.special_notes.unique()\n",
    "print(len(special_notes))\n",
    "list(special_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-17 18:58:27.482000+00:00 672581e7d97833442ce4e49b tall stalks with blowing residue\n",
      "2024-10-17 18:59:50.066000+00:00 67257eab68e6173cadb4134f tall stalks with blowing residue\n",
      "2024-10-17 19:01:23.639000+00:00 67257d3b498de9072472aef0 tall stalks with blowing residue\n",
      "2024-10-17 19:02:46.223000+00:00 67258286c4b5acae4b72b827 tall stalks with blowing residue\n",
      "2024-10-17 19:06:15.680000+00:00 67257b8a424c398443dad179 tall stalks with blowing residue\n"
     ]
    }
   ],
   "source": [
    "def print_time(df):\n",
    "    df = df.sort_values('collected_on')\n",
    "    for i in range(0, len(df), len(df)//5):\n",
    "        print(df.iloc[i].collected_on, df.iloc[i].id, df.iloc[i].special_notes)\n",
    "print_time(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camera_location\n",
       "T01    175\n",
       "T02    355\n",
       "T05    176\n",
       "T06    351\n",
       "T09    156\n",
       "T10    329\n",
       "T13    155\n",
       "T14    307\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df2.groupby('special_notes').size()\n",
    "df.groupby('camera_location').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unlabeled dataset\n",
    "Dataset.create(\n",
    "    name=\"halo_corn_stubble_w_human_8012_oct_sampled\",\n",
    "    description=\"2004 images selected from halo_human_w_corn_stubble_0812_oct, viewed all sequences\",\n",
    "    kind='image',  # annotation or image\n",
    "    image_ids=df.id.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning 5267 images do not have a corresponding annotation.\n",
      "Preparing stereo dataframe for {'T01': 'T03', 'T02': 'T04', 'T05': 'T07', 'T06': 'T08', 'T09': 'T11', 'T10': 'T12', 'T13': 'T15', 'T14': 'T16', 'I01': 'I03', 'I02': 'I04'}...\n",
      "Size of left dataframe: 10131\n",
      "Size of stereo dataframe: 10124\n",
      "Preparing stereo dataframe for {'T02': 'T03', 'T06': 'T07', 'T10': 'T11', 'T14': 'T15', 'I02': 'I03'}...\n",
      "Size of left dataframe: 6460\n",
      "Size of stereo dataframe: 6452\n",
      "Sending 10131 annotated_ids for creating dataset\n",
      "Time taken to prepare data for dataset creation job: 1.57 mins\n"
     ]
    }
   ],
   "source": [
    "# labeled, stereo dataset\n",
    "imageids_to_dataset(\n",
    "    image_ids=df2.id.to_list(),\n",
    "    dataset_name=\"halo_human_in_dust_test_negative_partition\",\n",
    "    dataset_description=\"15398 low dust level images sampled from 3 human in dust test sets, with thresholds at 20% day 20% dawn_dusk 10% night\",\n",
    "    dataset_kind='pixelwise_annotation',  # image or categorical_annotation or pixelwise_annotation\n",
    "    mode='stereo',  # stereo or mono\n",
    "    production_dataset=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running create dataset with many images, it will take some time, consider using         the Dataset.create API directly or the imageids_df_to_dataset_fast function\n",
      "Preparing stereo dataframe for {'T01': 'T03', 'T02': 'T04', 'T05': 'T07', 'T06': 'T08', 'T09': 'T11', 'T10': 'T12', 'T13': 'T15', 'T14': 'T16', 'I01': 'I03', 'I02': 'I04'}...\n",
      "Size of left dataframe: 36256\n",
      "Size of stereo dataframe: 36221\n",
      "Preparing stereo dataframe for {'T02': 'T03', 'T06': 'T07', 'T10': 'T11', 'T14': 'T15', 'I02': 'I03'}...\n",
      "Size of left dataframe: 18067\n",
      "Size of stereo dataframe: 18053\n",
      "Sending 75247 image ids for creating dataset\n",
      "Time taken to prepare data for dataset creation job: 1.22 mins\n"
     ]
    }
   ],
   "source": [
    "# unlabeled, stereo dataset\n",
    "imageids_to_dataset(\n",
    "    image_ids=df_sampled.id.to_list(),\n",
    "    dataset_name=\"halo_human_w_corn_stubble_0812_oct\",\n",
    "    dataset_description=\"36256 left images sampled from data collected by machine 8012 October\",\n",
    "    dataset_kind='image',  # image or categorical_annotation or pixelwise_annotation\n",
    "    mode='stereo',  # stereo or mono\n",
    "    production_dataset=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34;1m2024-11-04 06:41:29,961 - brtdevkit - INFO - start downloading dataset: 6728d9b6e038b66c0a00ef6c into /data3/jupiter/datasets/model_positive/halo_manure_data_candidate\n",
      "\u001b[0mINFO:brtdevkit:start downloading dataset: 6728d9b6e038b66c0a00ef6c into /data3/jupiter/datasets/model_positive/halo_manure_data_candidate\n",
      "/home/li.yu/anaconda3/envs/query/lib/python3.10/site-packages/brtdevkit/data/dataset.py:619: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  keys_with_save_path = keys_with_save_path.append(\n",
      "/home/li.yu/anaconda3/envs/query/lib/python3.10/site-packages/brtdevkit/data/dataset.py:619: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  keys_with_save_path = keys_with_save_path.append(\n",
      "100%|██████████| 64378/64378 [35:17<00:00, 30.41it/s]    \n",
      "\u001b[34;1m2024-11-04 07:17:19,250 - brtdevkit - INFO - finished downloading dataset: 6728d9b6e038b66c0a00ef6c\n",
      "\u001b[0mINFO:brtdevkit:finished downloading dataset: 6728d9b6e038b66c0a00ef6c\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'halo_manure_data_candidate'\n",
    "# dataset_dir = os.path.join('/data/jupiter/datasets/dust_datasets', dataset_name)\n",
    "# dataset_dir = os.path.join('/data2/jupiter/datasets', dataset_name)\n",
    "# dataset_dir = os.path.join('/data/jupiter/li.yu/data/dust_data_colletion_for_july_1st', dataset_name)\n",
    "# dataset_dir = os.path.join('/data/jupiter/datasets/image_quality_datasets', dataset_name)\n",
    "dataset_dir = os.path.join('/data3/jupiter/datasets/model_positive', dataset_name)\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "test_dataset = Dataset.retrieve(name=dataset_name)\n",
    "test_df = test_dataset.to_dataframe()\n",
    "test_dataset.download(dataset_dir, df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:query] *",
   "language": "python",
   "name": "conda-env-query-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
