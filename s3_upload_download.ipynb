{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## S3 upload and download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from brtdevkit.util.aws import s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = s3.S3()\n",
    "BRT_DEVKIT_WRITE_S3_BUCKET = 'mesa-states'\n",
    "MODEL_TRAINING_S3_KEY_PREFIX = f\"{os.environ.get('BRT_ENV', 'prod')}/jupiter/model_training\"\n",
    "PACK_PERCEPTION_S3_KEY_PREFIX = f\"{os.environ.get('BRT_ENV', 'prod')}/jupiter/pack_perception\"\n",
    "bucket_name=BRT_DEVKIT_WRITE_S3_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload file\n",
    "# key = f\"{MODEL_TRAINING_S3_KEY_PREFIX}/Jupiter_train_v4_53_missing_human_relabeled.tar\"\n",
    "key = f\"{PACK_PERCEPTION_S3_KEY_PREFIX}/Jupiter_train_v4_53_heavy_dust_relabeled.tar\"\n",
    "file_path = \"/home/bluerivertech/li.yu/data/Jupiter_train_v4_53_heavy_dust_relabeled/Jupiter_train_v4_53_heavy_dust_relabeled.tar\"\n",
    "s3_client.upload_file(\n",
    "    bucket_name=bucket_name, key=key, file_path=file_path)\n",
    "# Jupiter_2022_fn_bag1.tar\n",
    "# Jupiter_2022Jan15Feb15_rock_stops.tar\n",
    "# Jupiter_train_v4_53_missing_human_relabeled.tar\n",
    "# Jupiter_train_v4_53_heavy_dust_relabeled.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download file\n",
    "# run_id = '45_3_6class_ml_pp_seg_lite_cloud_v10_rotate_fix'\n",
    "# name = 'driveable_terrain_model_val_bestmodel.pth'\n",
    "# key = f\"{MODEL_TRAINING_S3_KEY_PREFIX}/{run_id}/{name}\"\n",
    "\n",
    "key = f\"{PACK_PERCEPTION_S3_KEY_PREFIX}/Jupiter_train_v4_53_heavy_dust_relabeled.tar\"\n",
    "\n",
    "target_path = '/data/jupiter/li.yu/data/Jupiter_train_v4_53/Jupiter_train_v4_53_heavy_dust_relabeled/Jupiter_train_v4_53_heavy_dust_relabeled.tar'\n",
    "s3_client.download_file(bucket_name, key, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Resave pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "# d = torch.load('/mnt/sandbox1/ben.cline/data/20240110/fpn_80k_nextvit_small_1n1k6m_pretrained.pth', map_location=lambda storage, loc: storage)\n",
    "# print(d.keys())\n",
    "# ori_keys = d['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['state_dict'])\n"
     ]
    }
   ],
   "source": [
    "# supervised pretraining lite12 model\n",
    "checkpoint_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "model = 'openimages_v7_brtlite12_0211'\n",
    "checkpoint = 'checkpoint_best'  # checkpoint or checkpoint_best\n",
    "input_dict = torch.load(os.path.join(checkpoint_dir, model, f'{checkpoint}.pth'), map_location=lambda storage, loc: storage)\n",
    "output_dict = OrderedDict()\n",
    "for k, v in input_dict['model'].items():\n",
    "    output_dict[k] = v\n",
    "output_dict = {'state_dict': output_dict}\n",
    "print(output_dict.keys())\n",
    "torch.save(output_dict, os.path.join(checkpoint_dir, model, f'{checkpoint}_brt_compatible.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['state_dict'])\n"
     ]
    }
   ],
   "source": [
    "# supervised pretraining\n",
    "checkpoint_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "model = 'openimages_v7_nextvit_small_structuralreparam_0311'\n",
    "checkpoint = 'checkpoint'  # checkpoint or checkpoint_best\n",
    "input_dict = torch.load(os.path.join(checkpoint_dir, model, f'{checkpoint}.pth'), map_location=lambda storage, loc: storage)\n",
    "output_dict = OrderedDict()\n",
    "for k, v in input_dict['model'].items():\n",
    "    output_dict['backbone.' + k] = v\n",
    "output_dict = {'state_dict': output_dict}\n",
    "print(output_dict.keys())\n",
    "\n",
    "# check difference between open source weights and OpenImages pretrained weights\n",
    "# print(set(output_dict['state_dict'].keys()) - set(ori_keys))\n",
    "\n",
    "torch.save(output_dict, os.path.join(checkpoint_dir, model, f'{checkpoint}_brt_compatible.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['state_dict'])\n"
     ]
    }
   ],
   "source": [
    "# self-supervised pretraining\n",
    "checkpoint_dir = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "# model = 'brt1m_spark_nextvit_small_0307'\n",
    "# model = 'openimages_v7_spark_nextvit_small_0226'\n",
    "model = 'train600k_spark_nextvit_small_0329'\n",
    "checkpoint = 'nextvit_small_pretrained_timm_style'  # checkpoint or checkpoint_best\n",
    "input_dict = torch.load(os.path.join(checkpoint_dir, model, f'{checkpoint}.pth'), map_location=lambda storage, loc: storage)\n",
    "output_dict = OrderedDict()\n",
    "for k, v in input_dict.items():\n",
    "    output_dict['backbone.' + k] = v\n",
    "output_dict = {'state_dict': output_dict}\n",
    "print(output_dict.keys())\n",
    "\n",
    "# # check difference between open source weights and OpenImages pretrained weights\n",
    "# print(set(output_dict['state_dict'].keys()) - set(ori_keys))\n",
    "\n",
    "torch.save(output_dict, os.path.join(checkpoint_dir, model, f'{checkpoint}_brt_compatible.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Resave trained weights for kore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'state_dict', 'optimizer', 'scheduler'])\n",
      "Number of classes in seg model: 11\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir1 = '/mnt/sandbox1/ben.cline/output/bc_sandbox_2024/'\n",
    "checkpoint_dir2 = '/data/jupiter/li.yu/exps/driveable_terrain_model/'\n",
    "# model = 'ds_v8_1_nextvit_small_openimages_with_rev1_train_human_test_using_random_val_mhc_20_epochs_finetune_rev1_lr'\n",
    "# model = 'ds_v8_1_nextvit_small_openimages_using_random_val_50k_rev1_rev2_lying_down_sitting_100_100'\n",
    "# model = 'ds_v8_1_nextvit_small_openimages_using_random_val_50k_rev1_rev2_lying_down_sitting_2x_lower_airborne_birds_lower_msl_d'\n",
    "# model = 'ds_v8_1_nextvit_small_openimages_using_random_val_50k_rev1_rev2_lying_down_sitting_2x_lower_airborne_birds_lower_msl_d_2h'\n",
    "# model = 'all_rev2_rev1_lying_down_sitting_headlights_round_2_25_ep_prod_weights_10_lo_10_tr'\n",
    "# model = '9_2_unofficial_50k_rev1_rev2_lying_down_sitting_headlights_25_ep_prod_weights_10_lo_100_tr_2'\n",
    "# model = '9_2_unofficial_50k_rev1_rev2_lying_down_sitting_headlights_50_ep_prod_weights_10_lo_30_tr_2_br_dr_p2_h_p2_v'\n",
    "# model = '9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_10_tr_br_dr_p2_v_p1_m_p1_u'\n",
    "model = '9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_5_tr_br_dr_p2_v_p1_m_p05_u_2'\n",
    "# checkpoint = 'bc_sandbox_2024_val_bestmodel_master_6'  \n",
    "checkpoint = 'bc_sandbox_2024_val_bestmodel'  \n",
    "input_dict = torch.load(os.path.join(checkpoint_dir1, model, f'{checkpoint}.pth'), map_location=lambda storage, loc: storage)\n",
    "print(input_dict.keys())\n",
    "\n",
    "# get number of classes in seg model\n",
    "print('Number of classes in seg model:', input_dict['state_dict']['model.decode_head.conv_seg.weight'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jupiter/li.yu/exps/driveable_terrain_model/9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_5_tr_br_dr_p2_v_p1_m_p05_u_2/bc_sandbox_2024_val_bestmodel_brtkore_compatible.pth\n"
     ]
    }
   ],
   "source": [
    "output_dict = OrderedDict()\n",
    "output_dict['epoch'] = input_dict['epoch']\n",
    "output_dict['state_dict'] = OrderedDict()\n",
    "for k,v in input_dict['state_dict'].items():\n",
    "    if k.startswith('scale_'):\n",
    "        output_dict['state_dict']['head.'+k] = v\n",
    "    else:\n",
    "        output_dict['state_dict'][k] = v\n",
    "\n",
    "os.makedirs(os.path.join(checkpoint_dir2, model), exist_ok=True)\n",
    "saved_path = os.path.join(checkpoint_dir2, model, f'{checkpoint}_brtkore_compatible.pth')\n",
    "torch.save(output_dict, saved_path)\n",
    "print(saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n",
      "Number of classes in seg model: 11\n"
     ]
    }
   ],
   "source": [
    "# trained dust head model\n",
    "# dust_head = '9_2_unofficial_50k_rev1_rev2_lying_down_sitting_headlights_50_ep_prod_weights_10_lo_30_tr_2_br_dr_p2_h_p2_v_dust_0617'\n",
    "dust_head = '9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_10_tr_br_dr_p2_v_p1_m_p1_u_finetune_dust_0623'\n",
    "dust_model = f'/data/jupiter/li.yu/exps/driveable_terrain_model/{dust_head}/checkpoints/best.ckpt'\n",
    "dust_dict = torch.load(dust_model, map_location=lambda storage, loc: storage)\n",
    "print(dust_dict.keys())\n",
    "# get number of classes in seg model\n",
    "print('Number of classes in seg model:', dust_dict['state_dict']['model.decode_head.conv_seg.weight'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dust_dict['state_dict']['model.decode_head.conv_seg.weight'] = input_dict['state_dict']['model.decode_head.conv_seg.weight']\n",
    "# dust_dict['state_dict']['model.decode_head.conv_seg.bias'] = input_dict['state_dict']['model.decode_head.conv_seg.bias']\n",
    "# torch.save(dust_dict, '/data/jupiter/li.yu/exps/driveable_terrain_model/9_2_unofficial_rev1_lying_down_sitting_25_ep_prod_weights_10_lo_10_tr_br_dr_p2_v_p1_m_p1_u_finetune_dust_0621/checkpoints/best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.backbone.stem.0.conv.weight tensor(0.7600)\n",
      "model.backbone.stem.0.norm.weight tensor(0.2920)\n",
      "model.backbone.stem.0.norm.bias tensor(0.2861)\n",
      "model.backbone.stem.0.norm.running_mean tensor(0.7333)\n",
      "model.backbone.stem.0.norm.running_var tensor(0.8848)\n",
      "model.backbone.stem.1.conv.weight tensor(0.8179)\n",
      "model.backbone.stem.1.norm.weight tensor(0.1383)\n",
      "model.backbone.stem.1.norm.bias tensor(0.2339)\n",
      "model.backbone.stem.1.norm.running_mean tensor(0.8409)\n",
      "model.backbone.stem.1.norm.running_var tensor(0.9614)\n",
      "model.backbone.stem.2.conv.weight tensor(0.8024)\n",
      "model.backbone.stem.2.norm.weight tensor(0.1301)\n",
      "model.backbone.stem.2.norm.bias tensor(0.4622)\n",
      "model.backbone.stem.2.norm.running_mean tensor(0.8245)\n",
      "model.backbone.stem.2.norm.running_var tensor(0.9350)\n",
      "model.backbone.stem.3.conv.weight tensor(0.8120)\n",
      "model.backbone.stem.3.norm.weight tensor(0.0856)\n",
      "model.backbone.stem.3.norm.bias tensor(0.3471)\n",
      "model.backbone.stem.3.norm.running_mean tensor(0.8007)\n",
      "model.backbone.stem.3.norm.running_var tensor(0.9370)\n",
      "model.backbone.features.0.patch_embed.conv.weight tensor(0.7791)\n",
      "model.backbone.features.0.patch_embed.norm.weight tensor(0.7310)\n",
      "model.backbone.features.0.patch_embed.norm.bias tensor(0.6788)\n",
      "model.backbone.features.0.patch_embed.norm.running_mean tensor(0.7798)\n",
      "model.backbone.features.0.patch_embed.norm.running_var tensor(0.9351)\n",
      "model.backbone.features.0.mhca.group_conv3x3.weight tensor(0.8109)\n",
      "model.backbone.features.0.mhca.norm.weight tensor(0.1098)\n",
      "model.backbone.features.0.mhca.norm.bias tensor(0.2526)\n",
      "model.backbone.features.0.mhca.norm.running_mean tensor(0.9337)\n",
      "model.backbone.features.0.mhca.norm.running_var tensor(0.9941)\n",
      "model.backbone.features.0.mhca.projection.weight tensor(0.8069)\n",
      "model.backbone.features.0.norm.weight tensor(2.1907)\n",
      "model.backbone.features.0.norm.bias tensor(1.9396)\n",
      "model.backbone.features.0.norm.running_mean tensor(0.7373)\n",
      "model.backbone.features.0.norm.running_var tensor(0.9239)\n",
      "model.backbone.features.0.mlp.conv1.weight tensor(0.8316)\n",
      "model.backbone.features.0.mlp.conv1.bias tensor(0.2753)\n",
      "model.backbone.features.0.mlp.conv2.weight tensor(0.8469)\n",
      "model.backbone.features.0.mlp.conv2.bias tensor(0.7006)\n",
      "model.backbone.features.1.mhca.group_conv3x3.weight tensor(0.8134)\n",
      "model.backbone.features.1.mhca.norm.weight tensor(0.0853)\n",
      "model.backbone.features.1.mhca.norm.bias tensor(0.1846)\n",
      "model.backbone.features.1.mhca.norm.running_mean tensor(0.9529)\n",
      "model.backbone.features.1.mhca.norm.running_var tensor(0.9940)\n",
      "model.backbone.features.1.mhca.projection.weight tensor(0.8027)\n",
      "model.backbone.features.1.norm.weight tensor(2.5626)\n",
      "model.backbone.features.1.norm.bias tensor(2.0636)\n",
      "model.backbone.features.1.norm.running_mean tensor(0.7767)\n",
      "model.backbone.features.1.norm.running_var tensor(0.9240)\n",
      "model.backbone.features.1.mlp.conv1.weight tensor(0.8415)\n",
      "model.backbone.features.1.mlp.conv1.bias tensor(0.2138)\n",
      "model.backbone.features.1.mlp.conv2.weight tensor(0.8585)\n",
      "model.backbone.features.1.mlp.conv2.bias tensor(0.8400)\n",
      "model.backbone.features.2.mhca.group_conv3x3.weight tensor(0.8182)\n",
      "model.backbone.features.2.mhca.norm.weight tensor(0.0789)\n",
      "model.backbone.features.2.mhca.norm.bias tensor(0.1037)\n",
      "model.backbone.features.2.mhca.norm.running_mean tensor(0.9384)\n",
      "model.backbone.features.2.mhca.norm.running_var tensor(0.9938)\n",
      "model.backbone.features.2.mhca.projection.weight tensor(0.8146)\n",
      "model.backbone.features.2.norm.weight tensor(2.6032)\n",
      "model.backbone.features.2.norm.bias tensor(1.6363)\n",
      "model.backbone.features.2.norm.running_mean tensor(0.7918)\n",
      "model.backbone.features.2.norm.running_var tensor(0.9262)\n",
      "model.backbone.features.2.mlp.conv1.weight tensor(0.8431)\n",
      "model.backbone.features.2.mlp.conv1.bias tensor(0.1776)\n",
      "model.backbone.features.2.mlp.conv2.weight tensor(0.8606)\n",
      "model.backbone.features.2.mlp.conv2.bias tensor(0.7838)\n",
      "model.backbone.features.3.patch_embed.conv.weight tensor(0.8028)\n",
      "model.backbone.features.3.patch_embed.norm.weight tensor(0.7058)\n",
      "model.backbone.features.3.patch_embed.norm.bias tensor(0.6497)\n",
      "model.backbone.features.3.patch_embed.norm.running_mean tensor(0.8250)\n",
      "model.backbone.features.3.patch_embed.norm.running_var tensor(0.9361)\n",
      "model.backbone.features.3.mhca.group_conv3x3.weight tensor(0.8366)\n",
      "model.backbone.features.3.mhca.norm.weight tensor(0.1166)\n",
      "model.backbone.features.3.mhca.norm.bias tensor(0.2655)\n",
      "model.backbone.features.3.mhca.norm.running_mean tensor(0.9308)\n",
      "model.backbone.features.3.mhca.norm.running_var tensor(0.9927)\n",
      "model.backbone.features.3.mhca.projection.weight tensor(0.8495)\n",
      "model.backbone.features.3.norm.weight tensor(1.5183)\n",
      "model.backbone.features.3.norm.bias tensor(0.8437)\n",
      "model.backbone.features.3.norm.running_mean tensor(0.7266)\n",
      "model.backbone.features.3.norm.running_var tensor(0.9221)\n",
      "model.backbone.features.3.mlp.conv1.weight tensor(0.8646)\n",
      "model.backbone.features.3.mlp.conv1.bias tensor(0.1672)\n",
      "model.backbone.features.3.mlp.conv2.weight tensor(0.8716)\n",
      "model.backbone.features.3.mlp.conv2.bias tensor(0.8666)\n",
      "model.backbone.features.4.mhca.group_conv3x3.weight tensor(0.8430)\n",
      "model.backbone.features.4.mhca.norm.weight tensor(0.1033)\n",
      "model.backbone.features.4.mhca.norm.bias tensor(0.2016)\n",
      "model.backbone.features.4.mhca.norm.running_mean tensor(0.9368)\n",
      "model.backbone.features.4.mhca.norm.running_var tensor(0.9941)\n",
      "model.backbone.features.4.mhca.projection.weight tensor(0.8518)\n",
      "model.backbone.features.4.norm.weight tensor(1.5593)\n",
      "model.backbone.features.4.norm.bias tensor(0.9809)\n",
      "model.backbone.features.4.norm.running_mean tensor(0.7689)\n",
      "model.backbone.features.4.norm.running_var tensor(0.9308)\n",
      "model.backbone.features.4.mlp.conv1.weight tensor(0.8662)\n",
      "model.backbone.features.4.mlp.conv1.bias tensor(0.1896)\n",
      "model.backbone.features.4.mlp.conv2.weight tensor(0.8814)\n",
      "model.backbone.features.4.mlp.conv2.bias tensor(0.8409)\n",
      "model.backbone.features.5.mhca.group_conv3x3.weight tensor(0.8396)\n",
      "model.backbone.features.5.mhca.norm.weight tensor(0.1068)\n",
      "model.backbone.features.5.mhca.norm.bias tensor(0.1485)\n",
      "model.backbone.features.5.mhca.norm.running_mean tensor(0.9375)\n",
      "model.backbone.features.5.mhca.norm.running_var tensor(0.9944)\n",
      "model.backbone.features.5.mhca.projection.weight tensor(0.8528)\n",
      "model.backbone.features.5.norm.weight tensor(1.7282)\n",
      "model.backbone.features.5.norm.bias tensor(1.0600)\n",
      "model.backbone.features.5.norm.running_mean tensor(0.7860)\n",
      "model.backbone.features.5.norm.running_var tensor(0.9349)\n",
      "model.backbone.features.5.mlp.conv1.weight tensor(0.8744)\n",
      "model.backbone.features.5.mlp.conv1.bias tensor(0.1625)\n",
      "model.backbone.features.5.mlp.conv2.weight tensor(0.8837)\n",
      "model.backbone.features.5.mlp.conv2.bias tensor(0.8051)\n",
      "model.backbone.features.6.norm1.weight tensor(6.5095)\n",
      "model.backbone.features.6.norm1.bias tensor(4.5863)\n",
      "model.backbone.features.6.norm1.running_mean tensor(0.7899)\n",
      "model.backbone.features.6.norm1.running_var tensor(0.9375)\n",
      "model.backbone.features.6.e_mhsa.q.weight tensor(0.9157)\n",
      "model.backbone.features.6.e_mhsa.q.bias tensor(0.3129)\n",
      "model.backbone.features.6.e_mhsa.k.weight tensor(0.9097)\n",
      "model.backbone.features.6.e_mhsa.k.bias tensor(0.7991)\n",
      "model.backbone.features.6.e_mhsa.v.weight tensor(0.9081)\n",
      "model.backbone.features.6.e_mhsa.v.bias tensor(0.8955)\n",
      "model.backbone.features.6.e_mhsa.proj.weight tensor(0.8722)\n",
      "model.backbone.features.6.e_mhsa.proj.bias tensor(0.7558)\n",
      "model.backbone.features.6.e_mhsa.norm.weight tensor(0.6726)\n",
      "model.backbone.features.6.e_mhsa.norm.bias tensor(1.6640)\n",
      "model.backbone.features.6.e_mhsa.norm.running_mean tensor(4.5851)\n",
      "model.backbone.features.6.e_mhsa.norm.running_var tensor(24.5842)\n",
      "model.backbone.features.6.projection.conv.weight tensor(0.8156)\n",
      "model.backbone.features.6.projection.norm.weight tensor(0.6534)\n",
      "model.backbone.features.6.projection.norm.bias tensor(0.7840)\n",
      "model.backbone.features.6.projection.norm.running_mean tensor(0.9642)\n",
      "model.backbone.features.6.projection.norm.running_var tensor(0.9950)\n",
      "model.backbone.features.6.mhca.group_conv3x3.weight tensor(0.8122)\n",
      "model.backbone.features.6.mhca.norm.weight tensor(0.0828)\n",
      "model.backbone.features.6.mhca.norm.bias tensor(0.1266)\n",
      "model.backbone.features.6.mhca.norm.running_mean tensor(0.9571)\n",
      "model.backbone.features.6.mhca.norm.running_var tensor(0.9903)\n",
      "model.backbone.features.6.mhca.projection.weight tensor(0.8079)\n",
      "model.backbone.features.6.norm2.weight tensor(1.6369)\n",
      "model.backbone.features.6.norm2.bias tensor(0.9570)\n",
      "model.backbone.features.6.norm2.running_mean tensor(0.8018)\n",
      "model.backbone.features.6.norm2.running_var tensor(0.9404)\n",
      "model.backbone.features.6.mlp.conv1.weight tensor(0.8797)\n",
      "model.backbone.features.6.mlp.conv1.bias tensor(0.1443)\n",
      "model.backbone.features.6.mlp.conv2.weight tensor(0.8822)\n",
      "model.backbone.features.6.mlp.conv2.bias tensor(0.8494)\n",
      "model.backbone.features.7.patch_embed.conv.weight tensor(0.8413)\n",
      "model.backbone.features.7.patch_embed.norm.weight tensor(0.6329)\n",
      "model.backbone.features.7.patch_embed.norm.bias tensor(0.5984)\n",
      "model.backbone.features.7.patch_embed.norm.running_mean tensor(0.8438)\n",
      "model.backbone.features.7.patch_embed.norm.running_var tensor(0.9196)\n",
      "model.backbone.features.7.mhca.group_conv3x3.weight tensor(0.8629)\n",
      "model.backbone.features.7.mhca.norm.weight tensor(0.1872)\n",
      "model.backbone.features.7.mhca.norm.bias tensor(0.1818)\n",
      "model.backbone.features.7.mhca.norm.running_mean tensor(0.9103)\n",
      "model.backbone.features.7.mhca.norm.running_var tensor(0.9866)\n",
      "model.backbone.features.7.mhca.projection.weight tensor(0.8930)\n",
      "model.backbone.features.7.norm.weight tensor(1.4527)\n",
      "model.backbone.features.7.norm.bias tensor(0.8309)\n",
      "model.backbone.features.7.norm.running_mean tensor(0.6926)\n",
      "model.backbone.features.7.norm.running_var tensor(0.8812)\n",
      "model.backbone.features.7.mlp.conv1.weight tensor(0.8378)\n",
      "model.backbone.features.7.mlp.conv1.bias tensor(0.1689)\n",
      "model.backbone.features.7.mlp.conv2.weight tensor(0.8368)\n",
      "model.backbone.features.7.mlp.conv2.bias tensor(0.9060)\n",
      "model.backbone.features.8.mhca.group_conv3x3.weight tensor(0.8628)\n",
      "model.backbone.features.8.mhca.norm.weight tensor(0.1606)\n",
      "model.backbone.features.8.mhca.norm.bias tensor(0.1902)\n",
      "model.backbone.features.8.mhca.norm.running_mean tensor(0.9146)\n",
      "model.backbone.features.8.mhca.norm.running_var tensor(0.9907)\n",
      "model.backbone.features.8.mhca.projection.weight tensor(0.8954)\n",
      "model.backbone.features.8.norm.weight tensor(1.2993)\n",
      "model.backbone.features.8.norm.bias tensor(0.7957)\n",
      "model.backbone.features.8.norm.running_mean tensor(0.7262)\n",
      "model.backbone.features.8.norm.running_var tensor(0.8971)\n",
      "model.backbone.features.8.mlp.conv1.weight tensor(0.6351)\n",
      "model.backbone.features.8.mlp.conv1.bias tensor(0.1860)\n",
      "model.backbone.features.8.mlp.conv2.weight tensor(0.6436)\n",
      "model.backbone.features.8.mlp.conv2.bias tensor(0.9866)\n",
      "model.backbone.features.9.mhca.group_conv3x3.weight tensor(0.8651)\n",
      "model.backbone.features.9.mhca.norm.weight tensor(0.1566)\n",
      "model.backbone.features.9.mhca.norm.bias tensor(0.1654)\n",
      "model.backbone.features.9.mhca.norm.running_mean tensor(0.9224)\n",
      "model.backbone.features.9.mhca.norm.running_var tensor(0.9915)\n",
      "model.backbone.features.9.mhca.projection.weight tensor(0.8948)\n",
      "model.backbone.features.9.norm.weight tensor(1.0430)\n",
      "model.backbone.features.9.norm.bias tensor(0.6700)\n",
      "model.backbone.features.9.norm.running_mean tensor(0.7646)\n",
      "model.backbone.features.9.norm.running_var tensor(0.9186)\n",
      "model.backbone.features.9.mlp.conv1.weight tensor(0.8685)\n",
      "model.backbone.features.9.mlp.conv1.bias tensor(0.1943)\n",
      "model.backbone.features.9.mlp.conv2.weight tensor(0.8729)\n",
      "model.backbone.features.9.mlp.conv2.bias tensor(0.8865)\n",
      "model.backbone.features.10.mhca.group_conv3x3.weight tensor(0.8715)\n",
      "model.backbone.features.10.mhca.norm.weight tensor(0.1656)\n",
      "model.backbone.features.10.mhca.norm.bias tensor(0.1630)\n",
      "model.backbone.features.10.mhca.norm.running_mean tensor(0.9336)\n",
      "model.backbone.features.10.mhca.norm.running_var tensor(0.9929)\n",
      "model.backbone.features.10.mhca.projection.weight tensor(0.8955)\n",
      "model.backbone.features.10.norm.weight tensor(0.9894)\n",
      "model.backbone.features.10.norm.bias tensor(0.6525)\n",
      "model.backbone.features.10.norm.running_mean tensor(0.7770)\n",
      "model.backbone.features.10.norm.running_var tensor(0.9376)\n",
      "model.backbone.features.10.mlp.conv1.weight tensor(0.8850)\n",
      "model.backbone.features.10.mlp.conv1.bias tensor(0.2043)\n",
      "model.backbone.features.10.mlp.conv2.weight tensor(0.8809)\n",
      "model.backbone.features.10.mlp.conv2.bias tensor(0.9068)\n",
      "model.backbone.features.11.norm1.weight tensor(4.1405)\n",
      "model.backbone.features.11.norm1.bias tensor(3.7373)\n",
      "model.backbone.features.11.norm1.running_mean tensor(0.7842)\n",
      "model.backbone.features.11.norm1.running_var tensor(0.9599)\n",
      "model.backbone.features.11.e_mhsa.q.weight tensor(0.9551)\n",
      "model.backbone.features.11.e_mhsa.q.bias tensor(0.4022)\n",
      "model.backbone.features.11.e_mhsa.k.weight tensor(0.9424)\n",
      "model.backbone.features.11.e_mhsa.k.bias tensor(0.8409)\n",
      "model.backbone.features.11.e_mhsa.v.weight tensor(0.9353)\n",
      "model.backbone.features.11.e_mhsa.v.bias tensor(0.8283)\n",
      "model.backbone.features.11.e_mhsa.proj.weight tensor(0.8844)\n",
      "model.backbone.features.11.e_mhsa.proj.bias tensor(0.7302)\n",
      "model.backbone.features.11.e_mhsa.norm.weight tensor(0.8383)\n",
      "model.backbone.features.11.e_mhsa.norm.bias tensor(1.2689)\n",
      "model.backbone.features.11.e_mhsa.norm.running_mean tensor(3.7565)\n",
      "model.backbone.features.11.e_mhsa.norm.running_var tensor(17.7250)\n",
      "model.backbone.features.11.projection.conv.weight tensor(0.8547)\n",
      "model.backbone.features.11.projection.norm.weight tensor(0.5881)\n",
      "model.backbone.features.11.projection.norm.bias tensor(0.6647)\n",
      "model.backbone.features.11.projection.norm.running_mean tensor(0.9595)\n",
      "model.backbone.features.11.projection.norm.running_var tensor(0.9961)\n",
      "model.backbone.features.11.mhca.group_conv3x3.weight tensor(0.8456)\n",
      "model.backbone.features.11.mhca.norm.weight tensor(0.1343)\n",
      "model.backbone.features.11.mhca.norm.bias tensor(0.1832)\n",
      "model.backbone.features.11.mhca.norm.running_mean tensor(0.9353)\n",
      "model.backbone.features.11.mhca.norm.running_var tensor(0.9861)\n",
      "model.backbone.features.11.mhca.projection.weight tensor(0.8412)\n",
      "model.backbone.features.11.norm2.weight tensor(0.6753)\n",
      "model.backbone.features.11.norm2.bias tensor(0.6502)\n",
      "model.backbone.features.11.norm2.running_mean tensor(0.7953)\n",
      "model.backbone.features.11.norm2.running_var tensor(0.9581)\n",
      "model.backbone.features.11.mlp.conv1.weight tensor(0.8947)\n",
      "model.backbone.features.11.mlp.conv1.bias tensor(0.1584)\n",
      "model.backbone.features.11.mlp.conv2.weight tensor(0.8813)\n",
      "model.backbone.features.11.mlp.conv2.bias tensor(0.8732)\n",
      "model.backbone.features.12.patch_embed.conv.weight tensor(0.8384)\n",
      "model.backbone.features.12.patch_embed.norm.weight tensor(0.7443)\n",
      "model.backbone.features.12.patch_embed.norm.bias tensor(0.6976)\n",
      "model.backbone.features.12.patch_embed.norm.running_mean tensor(0.9502)\n",
      "model.backbone.features.12.patch_embed.norm.running_var tensor(0.9945)\n",
      "model.backbone.features.12.mhca.group_conv3x3.weight tensor(0.8618)\n",
      "model.backbone.features.12.mhca.norm.weight tensor(0.1690)\n",
      "model.backbone.features.12.mhca.norm.bias tensor(0.1720)\n",
      "model.backbone.features.12.mhca.norm.running_mean tensor(0.9331)\n",
      "model.backbone.features.12.mhca.norm.running_var tensor(0.9947)\n",
      "model.backbone.features.12.mhca.projection.weight tensor(0.8921)\n",
      "model.backbone.features.12.norm.weight tensor(0.5562)\n",
      "model.backbone.features.12.norm.bias tensor(0.7455)\n",
      "model.backbone.features.12.norm.running_mean tensor(0.8090)\n",
      "model.backbone.features.12.norm.running_var tensor(0.9471)\n",
      "model.backbone.features.12.mlp.conv1.weight tensor(0.8897)\n",
      "model.backbone.features.12.mlp.conv1.bias tensor(0.1751)\n",
      "model.backbone.features.12.mlp.conv2.weight tensor(0.8948)\n",
      "model.backbone.features.12.mlp.conv2.bias tensor(0.8771)\n",
      "model.backbone.features.13.mhca.group_conv3x3.weight tensor(0.8634)\n",
      "model.backbone.features.13.mhca.norm.weight tensor(0.1834)\n",
      "model.backbone.features.13.mhca.norm.bias tensor(0.1842)\n",
      "model.backbone.features.13.mhca.norm.running_mean tensor(0.9486)\n",
      "model.backbone.features.13.mhca.norm.running_var tensor(0.9964)\n",
      "model.backbone.features.13.mhca.projection.weight tensor(0.8942)\n",
      "model.backbone.features.13.norm.weight tensor(0.6606)\n",
      "model.backbone.features.13.norm.bias tensor(0.5658)\n",
      "model.backbone.features.13.norm.running_mean tensor(0.8319)\n",
      "model.backbone.features.13.norm.running_var tensor(0.9641)\n",
      "model.backbone.features.13.mlp.conv1.weight tensor(0.8820)\n",
      "model.backbone.features.13.mlp.conv1.bias tensor(0.1962)\n",
      "model.backbone.features.13.mlp.conv2.weight tensor(0.8946)\n",
      "model.backbone.features.13.mlp.conv2.bias tensor(0.9058)\n",
      "model.backbone.features.14.mhca.group_conv3x3.weight tensor(0.8678)\n",
      "model.backbone.features.14.mhca.norm.weight tensor(0.2151)\n",
      "model.backbone.features.14.mhca.norm.bias tensor(0.2076)\n",
      "model.backbone.features.14.mhca.norm.running_mean tensor(0.9493)\n",
      "model.backbone.features.14.mhca.norm.running_var tensor(0.9972)\n",
      "model.backbone.features.14.mhca.projection.weight tensor(0.8970)\n",
      "model.backbone.features.14.norm.weight tensor(1.0627)\n",
      "model.backbone.features.14.norm.bias tensor(0.6333)\n",
      "model.backbone.features.14.norm.running_mean tensor(0.8480)\n",
      "model.backbone.features.14.norm.running_var tensor(0.9772)\n",
      "model.backbone.features.14.mlp.conv1.weight tensor(0.8756)\n",
      "model.backbone.features.14.mlp.conv1.bias tensor(0.2286)\n",
      "model.backbone.features.14.mlp.conv2.weight tensor(0.8911)\n",
      "model.backbone.features.14.mlp.conv2.bias tensor(0.9224)\n",
      "model.backbone.features.15.mhca.group_conv3x3.weight tensor(0.8724)\n",
      "model.backbone.features.15.mhca.norm.weight tensor(0.2246)\n",
      "model.backbone.features.15.mhca.norm.bias tensor(0.1987)\n",
      "model.backbone.features.15.mhca.norm.running_mean tensor(0.9522)\n",
      "model.backbone.features.15.mhca.norm.running_var tensor(0.9975)\n",
      "model.backbone.features.15.mhca.projection.weight tensor(0.8981)\n",
      "model.backbone.features.15.norm.weight tensor(1.2965)\n",
      "model.backbone.features.15.norm.bias tensor(1.0209)\n",
      "model.backbone.features.15.norm.running_mean tensor(0.8568)\n",
      "model.backbone.features.15.norm.running_var tensor(0.9829)\n",
      "model.backbone.features.15.mlp.conv1.weight tensor(0.8549)\n",
      "model.backbone.features.15.mlp.conv1.bias tensor(0.2318)\n",
      "model.backbone.features.15.mlp.conv2.weight tensor(0.8691)\n",
      "model.backbone.features.15.mlp.conv2.bias tensor(0.8957)\n",
      "model.backbone.features.16.norm1.weight tensor(0.7951)\n",
      "model.backbone.features.16.norm1.bias tensor(0.8510)\n",
      "model.backbone.features.16.norm1.running_mean tensor(0.8570)\n",
      "model.backbone.features.16.norm1.running_var tensor(0.9828)\n",
      "model.backbone.features.16.e_mhsa.q.weight tensor(0.9075)\n",
      "model.backbone.features.16.e_mhsa.q.bias tensor(0.3000)\n",
      "model.backbone.features.16.e_mhsa.k.weight tensor(0.9153)\n",
      "model.backbone.features.16.e_mhsa.k.bias tensor(0.8576)\n",
      "model.backbone.features.16.e_mhsa.v.weight tensor(0.9324)\n",
      "model.backbone.features.16.e_mhsa.v.bias tensor(0.8482)\n",
      "model.backbone.features.16.e_mhsa.proj.weight tensor(0.8944)\n",
      "model.backbone.features.16.e_mhsa.proj.bias tensor(0.8002)\n",
      "model.backbone.features.16.e_mhsa.norm.weight tensor(0.5407)\n",
      "model.backbone.features.16.e_mhsa.norm.bias tensor(0.8844)\n",
      "model.backbone.features.16.e_mhsa.norm.running_mean tensor(0.8513)\n",
      "model.backbone.features.16.e_mhsa.norm.running_var tensor(1.8372)\n",
      "model.backbone.features.16.projection.conv.weight tensor(0.8537)\n",
      "model.backbone.features.16.projection.norm.weight tensor(0.7164)\n",
      "model.backbone.features.16.projection.norm.bias tensor(0.7671)\n",
      "model.backbone.features.16.projection.norm.running_mean tensor(0.9762)\n",
      "model.backbone.features.16.projection.norm.running_var tensor(0.9992)\n",
      "model.backbone.features.16.mhca.group_conv3x3.weight tensor(0.8471)\n",
      "model.backbone.features.16.mhca.norm.weight tensor(0.2020)\n",
      "model.backbone.features.16.mhca.norm.bias tensor(0.2148)\n",
      "model.backbone.features.16.mhca.norm.running_mean tensor(0.9468)\n",
      "model.backbone.features.16.mhca.norm.running_var tensor(0.9935)\n",
      "model.backbone.features.16.mhca.projection.weight tensor(0.8386)\n",
      "model.backbone.features.16.norm2.weight tensor(1.2450)\n",
      "model.backbone.features.16.norm2.bias tensor(0.8594)\n",
      "model.backbone.features.16.norm2.running_mean tensor(0.8667)\n",
      "model.backbone.features.16.norm2.running_var tensor(0.9823)\n",
      "model.backbone.features.16.mlp.conv1.weight tensor(0.8619)\n",
      "model.backbone.features.16.mlp.conv1.bias tensor(0.2124)\n",
      "model.backbone.features.16.mlp.conv2.weight tensor(0.8704)\n",
      "model.backbone.features.16.mlp.conv2.bias tensor(0.9024)\n",
      "model.backbone.features.17.patch_embed.conv.weight tensor(0.8732)\n",
      "model.backbone.features.17.patch_embed.norm.weight tensor(0.5079)\n",
      "model.backbone.features.17.patch_embed.norm.bias tensor(0.5405)\n",
      "model.backbone.features.17.patch_embed.norm.running_mean tensor(0.8474)\n",
      "model.backbone.features.17.patch_embed.norm.running_var tensor(0.8888)\n",
      "model.backbone.features.17.mhca.group_conv3x3.weight tensor(0.8730)\n",
      "model.backbone.features.17.mhca.norm.weight tensor(0.1493)\n",
      "model.backbone.features.17.mhca.norm.bias tensor(0.1946)\n",
      "model.backbone.features.17.mhca.norm.running_mean tensor(0.8978)\n",
      "model.backbone.features.17.mhca.norm.running_var tensor(0.9840)\n",
      "model.backbone.features.17.mhca.projection.weight tensor(0.9127)\n",
      "model.backbone.features.17.norm.weight tensor(2.4727)\n",
      "model.backbone.features.17.norm.bias tensor(1.6635)\n",
      "model.backbone.features.17.norm.running_mean tensor(0.7269)\n",
      "model.backbone.features.17.norm.running_var tensor(0.9028)\n",
      "model.backbone.features.17.mlp.conv1.weight tensor(0.7753)\n",
      "model.backbone.features.17.mlp.conv1.bias tensor(0.1775)\n",
      "model.backbone.features.17.mlp.conv2.weight tensor(0.7989)\n",
      "model.backbone.features.17.mlp.conv2.bias tensor(0.8946)\n",
      "model.backbone.features.18.mhca.group_conv3x3.weight tensor(0.8813)\n",
      "model.backbone.features.18.mhca.norm.weight tensor(0.2122)\n",
      "model.backbone.features.18.mhca.norm.bias tensor(0.2240)\n",
      "model.backbone.features.18.mhca.norm.running_mean tensor(0.9057)\n",
      "model.backbone.features.18.mhca.norm.running_var tensor(0.9920)\n",
      "model.backbone.features.18.mhca.projection.weight tensor(0.9054)\n",
      "model.backbone.features.18.norm.weight tensor(2.7972)\n",
      "model.backbone.features.18.norm.bias tensor(2.6112)\n",
      "model.backbone.features.18.norm.running_mean tensor(0.7639)\n",
      "model.backbone.features.18.norm.running_var tensor(0.9634)\n",
      "model.backbone.features.18.mlp.conv1.weight tensor(0.7915)\n",
      "model.backbone.features.18.mlp.conv1.bias tensor(0.1811)\n",
      "model.backbone.features.18.mlp.conv2.weight tensor(0.7878)\n",
      "model.backbone.features.18.mlp.conv2.bias tensor(0.8626)\n",
      "model.backbone.features.19.norm1.weight tensor(1.1521)\n",
      "model.backbone.features.19.norm1.bias tensor(1.4610)\n",
      "model.backbone.features.19.norm1.running_mean tensor(0.7627)\n",
      "model.backbone.features.19.norm1.running_var tensor(0.9622)\n",
      "model.backbone.features.19.e_mhsa.q.weight tensor(0.9699)\n",
      "model.backbone.features.19.e_mhsa.q.bias tensor(0.5281)\n",
      "model.backbone.features.19.e_mhsa.k.weight tensor(0.9360)\n",
      "model.backbone.features.19.e_mhsa.k.bias tensor(0.8790)\n",
      "model.backbone.features.19.e_mhsa.v.weight tensor(0.9780)\n",
      "model.backbone.features.19.e_mhsa.v.bias tensor(0.8625)\n",
      "model.backbone.features.19.e_mhsa.proj.weight tensor(0.9531)\n",
      "model.backbone.features.19.e_mhsa.proj.bias tensor(0.6663)\n",
      "model.backbone.features.19.projection.conv.weight tensor(0.8883)\n",
      "model.backbone.features.19.projection.norm.weight tensor(0.4924)\n",
      "model.backbone.features.19.projection.norm.bias tensor(0.5232)\n",
      "model.backbone.features.19.projection.norm.running_mean tensor(0.9557)\n",
      "model.backbone.features.19.projection.norm.running_var tensor(0.9963)\n",
      "model.backbone.features.19.mhca.group_conv3x3.weight tensor(0.8719)\n",
      "model.backbone.features.19.mhca.norm.weight tensor(0.2474)\n",
      "model.backbone.features.19.mhca.norm.bias tensor(0.3477)\n",
      "model.backbone.features.19.mhca.norm.running_mean tensor(0.8590)\n",
      "model.backbone.features.19.mhca.norm.running_var tensor(0.9640)\n",
      "model.backbone.features.19.mhca.projection.weight tensor(0.8793)\n",
      "model.backbone.features.19.norm2.weight tensor(1.1194)\n",
      "model.backbone.features.19.norm2.bias tensor(0.8615)\n",
      "model.backbone.features.19.norm2.running_mean tensor(0.8098)\n",
      "model.backbone.features.19.norm2.running_var tensor(0.9618)\n",
      "model.backbone.features.19.mlp.conv1.weight tensor(0.8407)\n",
      "model.backbone.features.19.mlp.conv1.bias tensor(0.1998)\n",
      "model.backbone.features.19.mlp.conv2.weight tensor(0.8066)\n",
      "model.backbone.features.19.mlp.conv2.bias tensor(0.9400)\n",
      "model.backbone.extra_norm_list.0.weight tensor(0.0520)\n",
      "model.backbone.extra_norm_list.0.bias tensor(0.4010)\n",
      "model.backbone.extra_norm_list.0.running_mean tensor(0.7939)\n",
      "model.backbone.extra_norm_list.0.running_var tensor(0.9263)\n",
      "model.backbone.extra_norm_list.1.weight tensor(0.1229)\n",
      "model.backbone.extra_norm_list.1.bias tensor(0.2429)\n",
      "model.backbone.extra_norm_list.1.running_mean tensor(0.7964)\n",
      "model.backbone.extra_norm_list.1.running_var tensor(0.9394)\n",
      "model.backbone.extra_norm_list.2.weight tensor(0.2525)\n",
      "model.backbone.extra_norm_list.2.bias tensor(0.3694)\n",
      "model.backbone.extra_norm_list.2.running_mean tensor(0.8634)\n",
      "model.backbone.extra_norm_list.2.running_var tensor(0.9818)\n",
      "model.backbone.norm.weight tensor(0.6548)\n",
      "model.backbone.norm.bias tensor(1.1805)\n",
      "model.backbone.norm.running_mean tensor(0.8078)\n",
      "model.backbone.norm.running_var tensor(0.9489)\n",
      "model.neck.lateral_convs.0.conv.weight tensor(0.2990)\n",
      "model.neck.lateral_convs.0.conv.bias tensor(0.3632)\n",
      "model.neck.lateral_convs.1.conv.weight tensor(0.3923)\n",
      "model.neck.lateral_convs.1.conv.bias tensor(0.3313)\n",
      "model.neck.lateral_convs.2.conv.weight tensor(0.4329)\n",
      "model.neck.lateral_convs.2.conv.bias tensor(0.2141)\n",
      "model.neck.lateral_convs.3.conv.weight tensor(0.6098)\n",
      "model.neck.lateral_convs.3.conv.bias tensor(0.2669)\n",
      "model.neck.fpn_convs.0.conv.weight tensor(0.3977)\n",
      "model.neck.fpn_convs.0.conv.bias tensor(0.2869)\n",
      "model.neck.fpn_convs.1.conv.weight tensor(0.4046)\n",
      "model.neck.fpn_convs.1.conv.bias tensor(0.2266)\n",
      "model.neck.fpn_convs.2.conv.weight tensor(0.3791)\n",
      "model.neck.fpn_convs.2.conv.bias tensor(0.2190)\n",
      "model.neck.fpn_convs.3.conv.weight tensor(0.3677)\n",
      "model.neck.fpn_convs.3.conv.bias tensor(0.3232)\n",
      "model.decode_head.conv_seg.weight tensor(0.4866)\n",
      "model.decode_head.conv_seg.bias tensor(0.6596)\n",
      "model.decode_head.scale_heads.0.0.conv.weight tensor(0.4186)\n",
      "model.decode_head.scale_heads.0.0.bn.weight tensor(0.1668)\n",
      "model.decode_head.scale_heads.0.0.bn.bias tensor(0.1846)\n",
      "model.decode_head.scale_heads.0.0.bn.running_mean tensor(0.3829)\n",
      "model.decode_head.scale_heads.0.0.bn.running_var tensor(0.3958)\n",
      "model.decode_head.scale_heads.1.0.conv.weight tensor(0.4556)\n",
      "model.decode_head.scale_heads.1.0.bn.weight tensor(0.2592)\n",
      "model.decode_head.scale_heads.1.0.bn.bias tensor(0.4170)\n",
      "model.decode_head.scale_heads.1.0.bn.running_mean tensor(0.4516)\n",
      "model.decode_head.scale_heads.1.0.bn.running_var tensor(0.2209)\n",
      "model.decode_head.scale_heads.2.0.conv.weight tensor(0.4236)\n",
      "model.decode_head.scale_heads.2.0.bn.weight tensor(0.0650)\n",
      "model.decode_head.scale_heads.2.0.bn.bias tensor(0.1900)\n",
      "model.decode_head.scale_heads.2.0.bn.running_mean tensor(0.3401)\n",
      "model.decode_head.scale_heads.2.0.bn.running_var tensor(0.2047)\n",
      "model.decode_head.scale_heads.2.2.conv.weight tensor(0.4708)\n",
      "model.decode_head.scale_heads.2.2.bn.weight tensor(0.2018)\n",
      "model.decode_head.scale_heads.2.2.bn.bias tensor(0.3158)\n",
      "model.decode_head.scale_heads.2.2.bn.running_mean tensor(0.3554)\n",
      "model.decode_head.scale_heads.2.2.bn.running_var tensor(0.2266)\n",
      "model.decode_head.scale_heads.3.0.conv.weight tensor(0.4360)\n",
      "model.decode_head.scale_heads.3.0.bn.weight tensor(0.0922)\n",
      "model.decode_head.scale_heads.3.0.bn.bias tensor(0.3140)\n",
      "model.decode_head.scale_heads.3.0.bn.running_mean tensor(0.4810)\n",
      "model.decode_head.scale_heads.3.0.bn.running_var tensor(0.2376)\n",
      "model.decode_head.scale_heads.3.2.conv.weight tensor(0.4354)\n",
      "model.decode_head.scale_heads.3.2.bn.weight tensor(0.0724)\n",
      "model.decode_head.scale_heads.3.2.bn.bias tensor(0.3041)\n",
      "model.decode_head.scale_heads.3.2.bn.running_mean tensor(0.3850)\n",
      "model.decode_head.scale_heads.3.2.bn.running_var tensor(0.2347)\n",
      "model.decode_head.scale_heads.3.4.conv.weight tensor(0.4528)\n",
      "model.decode_head.scale_heads.3.4.bn.weight tensor(0.2212)\n",
      "model.decode_head.scale_heads.3.4.bn.bias tensor(0.2668)\n",
      "model.decode_head.scale_heads.3.4.bn.running_mean tensor(0.4299)\n",
      "model.decode_head.scale_heads.3.4.bn.running_var tensor(0.2373)\n"
     ]
    }
   ],
   "source": [
    "keys = dust_dict['state_dict'].keys()\n",
    "for key in keys:\n",
    "    if key in input_dict['state_dict'] and key in dust_dict['state_dict']:\n",
    "        ori_val = input_dict['state_dict'][key]\n",
    "        dust_val = dust_dict['state_dict'][key]\n",
    "        diff = torch.sum(torch.abs(ori_val - dust_val)) / torch.sum(torch.abs(ori_val))\n",
    "        if diff > 1e-5:\n",
    "            print(key, diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check output shape after conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "sys.path.append('/home/li.yu/code/JupiterCVML/')\n",
    "sys.path.append('/home/li.yu/code/JupiterCVML/europa/base/src/europa')\n",
    "\n",
    "from dl.depth_model.models.modules.convs import Conv2dBlock, ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Conv2dBlock(\n",
    "    in_channels=128,\n",
    "    out_channels=64,\n",
    "    kernel_size=3,\n",
    "    stride=2,\n",
    "    padding=1,\n",
    "    dilation=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 16, 20])\n",
      "torch.Size([4, 64, 8, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4, 128, 16, 20)\n",
    "print(x.shape)\n",
    "y = layer(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 4, 5])\n",
      "torch.Size([4, 32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "pool = torch.nn.AvgPool2d(kernel_size=[4, 5], stride=[1, 1])\n",
    "x = torch.rand(4, 32, 4, 5)\n",
    "print(x.shape)\n",
    "y = pool(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 4, 5])\n",
      "torch.Size([4, 32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# x = torch.rand(4, 32, 4, 5)\n",
    "print(x.shape)\n",
    "y2 = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8781e-08)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.abs(y - y2)) / torch.sum(torch.abs(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check lightly train API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "import lightly_train\n",
    "from lightly_train import train\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Args: { 'checkpoint': '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.ckpt',\n",
      "  'format': 'torch_state_dict',\n",
      "  'out': '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth',\n",
      "  'overwrite': False,\n",
      "  'part': 'model'}\u001b[0m\n",
      "INFO:lightly_train._commands.export:Args: { 'checkpoint': '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.ckpt',\n",
      "  'format': 'torch_state_dict',\n",
      "  'out': '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth',\n",
      "  'overwrite': False,\n",
      "  'part': 'model'}\n",
      "Exporting 'model' as 'torch_state_dict'.\u001b[0m\n",
      "INFO:lightly_train._commands.export:Exporting 'model' as 'torch_state_dict'.\n",
      "DEBUG:lightly_train._commands.export:Getting model part for 'model'.\n",
      "DEBUG:lightly_train._commands.export:Getting model format for 'torch_state_dict'.\n",
      "DEBUG:lightly_train._commands.common_helpers:Checking if output path '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth' exists.\n",
      "DEBUG:lightly_train._commands.common_helpers:Making sure checkpoint '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.ckpt' exists.\n",
      "Loading checkpoint from '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.ckpt'\u001b[0m\n",
      "INFO:lightly_train._commands.export:Loading checkpoint from '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.ckpt'\n",
      "DEBUG:lightly_train._checkpoint:Loading checkpoint from '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.ckpt' with map_location 'cpu' and weights_only False\n",
      "DEBUG:lightly_train._commands.export:Getting model part: 'ModelPart.MODEL' from checkpoint.\n",
      "Exporting model to '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth'\u001b[0m\n",
      "INFO:lightly_train._commands.export:Exporting model to '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth'\n",
      "DEBUG:lightly_train._commands.export:Exporting model to '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth' in format 'ModelFormat.TORCH_STATE_DICT'.\n"
     ]
    }
   ],
   "source": [
    "# save lightly checkpoint to plain checkpoint\n",
    "lightly_ckpt = '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.ckpt'\n",
    "plain_pth = '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth'\n",
    "lightly_train.export(\n",
    "    checkpoint=lightly_ckpt,   # Path the the last checkpoint from training.\n",
    "    out=plain_pth,            # Path where the state dict of your model will be saved.\n",
    "    part=\"model\",                                       # Which part of the model to export. This should usually be set to \"model\".\n",
    "    format=\"torch_state_dict\",                          # The format in which you want to export the model.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save plain checkpoint to brt compatible checkpoint\n",
    "# plain_pth = '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth'\n",
    "# brt_pth = '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last_brt_compatible.pth'\n",
    "# input_dict = torch.load(plain_pth, map_location=lambda storage, loc: storage)\n",
    "# output_dict = OrderedDict()\n",
    "# for k, v in input_dict.items():\n",
    "#     output_dict['backbone.' + k] = v\n",
    "# output_dict = {'state_dict': output_dict}\n",
    "# print(output_dict.keys())\n",
    "\n",
    "# torch.save(output_dict, brt_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": "30741443"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "from timm.models import create_model\n",
    "print(timm.__version__)\n",
    "model = create_model(\n",
    "    'nextvit_small',\n",
    "    num_classes=3,\n",
    ")\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "30740096"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import functional\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/li.yu/code/JupiterCVML/europa/base/src/europa')\n",
    "from dl.network.nextvit_brt import _get_nextvit\n",
    "\n",
    "class NextVitSmall(torch.nn.Module):\n",
    "    \"\"\"BRT Segmentation model with extra methods to make it a custom model supported\n",
    "    by LightlyTrain.\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # define backbone\n",
    "        self.backbone = _get_nextvit(\n",
    "            model_size=\"small\",\n",
    "            frozen_stages=-1,\n",
    "            norm_eval=False,\n",
    "            with_extra_norm=True,\n",
    "            norm_cfg=dict(type=\"SyncBN\", requires_grad=True),\n",
    "            in_channels=3,\n",
    "        )\n",
    "\n",
    "    def forward_features(self, x: Tensor) -> Tensor:\n",
    "        y = self.backbone(x)\n",
    "        return y[-1]\n",
    "\n",
    "    def forward_pool(self, x: Tensor) -> Tensor:\n",
    "        return functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "\n",
    "    def num_features(self) -> int:\n",
    "        return 1024\n",
    "\n",
    "model = NextVitSmall()\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['state_dict'])\n",
      "12 2\n",
      "485 472\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = '/data/jupiter/li.yu/exps/driveable_terrain_model/openimages_v7_0131/checkpoint_brt_compatible.pth'\n",
    "# ckpt_path = '/data/jupiter/li.yu/exps/driveable_terrain_model/lightly_densecldino_0927/checkpoints/last.pth'\n",
    "# ckpt_path = '/mnt/sandbox1/ben.cline/logs/bc_sandbox_2024_q4/11_1_rev1_train_human_test_dean_multires/checkpoints/best.ckpt'\n",
    "\n",
    "input_dict = torch.load(ckpt_path, map_location=lambda storage, loc: storage, weights_only=False)\n",
    "if len(input_dict.keys()) < 10:  # when contain other states like from optimizer, epoch number etc\n",
    "    print(input_dict.keys())\n",
    "\n",
    "if 'model' in input_dict:\n",
    "    state_dict = input_dict['model']\n",
    "elif 'state_dict' in input_dict:\n",
    "    state_dict = input_dict['state_dict']\n",
    "else:\n",
    "    state_dict = input_dict\n",
    "if 'model.backbone.stem.0.conv.weight' in state_dict:\n",
    "    new_state_dict = {}\n",
    "    for k,v in state_dict.items():\n",
    "        if k.startswith('model.backbone'):\n",
    "            new_state_dict[k[6:]] = v\n",
    "    state_dict = new_state_dict\n",
    "missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "print(len(missing_keys), len(unexpected_keys))\n",
    "print(len(model.state_dict()), len(state_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['backbone.extra_norm_list.0.weight',\n 'backbone.extra_norm_list.0.bias',\n 'backbone.extra_norm_list.0.running_mean',\n 'backbone.extra_norm_list.0.running_var',\n 'backbone.extra_norm_list.1.weight',\n 'backbone.extra_norm_list.1.bias',\n 'backbone.extra_norm_list.1.running_mean',\n 'backbone.extra_norm_list.1.running_var',\n 'backbone.extra_norm_list.2.weight',\n 'backbone.extra_norm_list.2.bias',\n 'backbone.extra_norm_list.2.running_mean',\n 'backbone.extra_norm_list.2.running_var']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['backbone.proj_head.0.weight', 'backbone.proj_head.0.bias']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unexpected_keys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 64-bit (conda)",
   "name": "python31014jvsc74a57bd07908f314adaeb21f01436b5bca17ddd446b1e04b10c62e4bb4775de29aac5c6d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}